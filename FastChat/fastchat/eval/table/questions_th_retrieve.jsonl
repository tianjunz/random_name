{"question_id": 1, "text": "I need an API that can estimate the relative depth of objects from a single image. The output should be an inverse depth map. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Hybrid', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Hybrid')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 2, "text": "I need an API to detect different types of vehicles, people, and lanes in an image captured from a camera mounted on a self-driving car. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'YOLOP', 'api_call': \"torch.hub.load(repo_or_dir='hustvl/yolop', model='yolop', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'pip install -qr https://github.com/hustvl/YOLOP/blob/main/requirements.txt', 'example_code': \"import torch\\nmodel = torch.hub.load('hustvl/yolop', 'yolop', pretrained=True)\\nimg = torch.randn(1,3,640,640)\\ndet_out, da_seg_out,ll_seg_out = model(img)\", 'performance': {'dataset': 'BDD100K', 'accuracy': {'Object Detection': {'Recall(%)': 89.2, 'mAP50(%)': 76.5, 'Speed(fps)': 41}, 'Drivable Area Segmentation': {'mIOU(%)': 91.5, 'Speed(fps)': 41}, 'Lane Detection': {'mIOU(%)': 70.5, 'IOU(%)': 26.2}}}, 'description': 'YOLOP is an efficient multi-task network that can jointly handle three crucial tasks in autonomous driving: object detection, drivable area segmentation and lane detection. And it is also the first to reach real-time on embedded devices while maintaining state-of-the-art level performance on the BDD100K dataset.'}", "category": "generic"}
{"question_id": 3, "text": "\"I need to calculate the single-image depth map of a captured image. Present an API that can perform this complex task.\" \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Large', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Large')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 4, "text": "Imagine an advertisement company wants to analyze various video streams for the presence of specific activities or actions. Provide them with an API that can perform this video classification task. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorch', 'functionality': '3D ResNet', 'api_name': 'slow_r50', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slow_r50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'json', 'urllib', 'pytorchvideo', 'torchvision', 'torchaudio', 'torchtext', 'torcharrow', 'TorchData', 'TorchRec', 'TorchServe', 'PyTorch on XLA Devices'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top_1': 74.58, 'top_5': 91.63}, 'Flops (G)': 54.52, 'Params (M)': 32.45}, 'description': \"The 3D ResNet model is a Resnet-style video classification network pretrained on the Kinetics 400 dataset. It is based on the architecture from the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al.\"}", "category": "generic"}
{"question_id": 5, "text": "Recommend an API for estimating relative depth from a single image for a self-driving vehicle startup. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='MiDaS_small', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 6, "text": "I work for Tesla, and I need a ready-to-use model for detecting and classifying cars, pedestrians, lanes, and drivable area in an image. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Traffic Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'HybridNets', 'api_call': \"torch.hub.load(repo_or_dir='datvuthanh/hybridnets', model='hybridnets', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'Python>=3.7, PyTorch>=1.10', 'example_code': \"import torch\\nmodel = torch.hub.load('datvuthanh/hybridnets', 'hybridnets', pretrained=True)\\nimg = torch.randn(1,3,640,384)\\nfeatures, regression, classification, anchors, segmentation = model(img)\", 'performance': {'dataset': [{'name': 'BDD100K', 'accuracy': {'Traffic Object Detection': {'Recall (%)': 92.8, 'mAP@0.5 (%)': 77.3}, 'Drivable Area Segmentation': {'Drivable mIoU (%)': 90.5}, 'Lane Line Detection': {'Accuracy (%)': 85.4, 'Lane Line IoU (%)': 31.6}}}]}, 'description': 'HybridNets is an end2end perception network for multi-tasks. Our work focused on traffic object detection, drivable area segmentation and lane detection. HybridNets can run real-time on embedded systems, and obtains SOTA Object Detection, Lane Detection on BDD100K Dataset.'}", "category": "generic"}
{"question_id": 7, "text": "A student needs to classify bird species for their science project. Write an API to help identify the bird species given a photo of a bird. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Fine-grained image classifier', 'api_name': 'ntsnet', 'api_call': \"torch.hub.load(repo_or_dir='nicolalandro/ntsnet-cub200', model='ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\", 'api_arguments': {'pretrained': 'True', 'topN': '6', 'device': 'cpu', 'num_classes': '200'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': \"from torchvision import transforms\\nimport torch\\nimport urllib\\nfrom PIL import Image\\n\\ntransform_test = transforms.Compose([\\n transforms.Resize((600, 600), Image.BILINEAR),\\n transforms.CenterCrop((448, 448)),\\n transforms.ToTensor(),\\n transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\\n])\\n\\nmodel = torch.hub.load('nicolalandro/ntsnet-cub200', 'ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\\nmodel.eval()\\n\\nurl = 'https://raw.githubusercontent.com/nicolalandro/ntsnet-cub200/master/images/nts-net.png'\\nimg = Image.open(urllib.request.urlopen(url))\\nscaled_img = transform_test(img)\\ntorch_images = scaled_img.unsqueeze(0)\\n\\nwith torch.no_grad():\\n top_n_coordinates, concat_out, raw_logits, concat_logits, part_logits, top_n_index, top_n_prob = model(torch_images)\\n\\n_, predict = torch.max(concat_logits, 1)\\npred_id = predict.item()\\nprint('bird class:', model.bird_classes[pred_id])\", 'performance': {'dataset': 'CUB200 2011', 'accuracy': 'Not provided'}, 'description': 'This is an nts-net pretrained with CUB200 2011 dataset, which is a fine-grained dataset of birds species.'}", "category": "generic"}
{"question_id": 8, "text": "Help me find an API to convert spoken language in a recorded audio file into text. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Speech-To-Text', 'api_name': 'Silero Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_stt', 'language': ['en', 'de', 'es'], 'device': 'device'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf soundfile'], 'example_code': ['import torch', 'import zipfile', 'import torchaudio', 'from glob import glob', \"device = torch.device('cpu')\", \"model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', language='en', device=device)\", '(read_batch, split_into_batches, read_audio, prepare_model_input) = utils', \"torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav', dst ='speech_orig.wav', progress=True)\", \"test_files = glob('speech_orig.wav')\", 'batches = split_into_batches(test_files, batch_size=10)', 'input = prepare_model_input(read_batch(batches[0]), device=device)', 'output = model(input)', 'for example in output:', ' print(decoder(example.cpu()))'], 'performance': {'dataset': 'Open-STT', 'accuracy': 'See the wiki for quality and performance benchmarks'}, 'description': 'Silero Speech-To-Text models provide enterprise grade STT in a compact form-factor for several commonly spoken languages. The models are robust to a variety of dialects, codecs, domains, noises, and lower sampling rates. They consume a normalized audio in the form of samples and output frames with token probabilities. A decoder utility is provided for simplicity.'}", "category": "generic"}
{"question_id": 9, "text": "We want to convert text to audio for one of our applications. What API can provide that functionality? \n Use this API documentation for reference: {'domain': 'Text-To-Speech', 'framework': 'PyTorch', 'functionality': 'Text-To-Speech', 'api_name': 'Silero Text-To-Speech Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_tts', 'language': 'language', 'speaker': 'speaker'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf'], 'example_code': \"import torch\\nlanguage = 'en'\\nspeaker = 'lj_16khz'\\ndevice = torch.device('cpu')\\nmodel, symbols, sample_rate, example_text, apply_tts = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', language=language, speaker=speaker)\\nmodel = model.to(device)\\naudio = apply_tts(texts=[example_text], model=model, sample_rate=sample_rate, symbols=symbols, device=device)\", 'performance': {'dataset': [{'language': 'Russian', 'speakers': 6}, {'language': 'English', 'speakers': 1}, {'language': 'German', 'speakers': 1}, {'language': 'Spanish', 'speakers': 1}, {'language': 'French', 'speakers': 1}], 'accuracy': 'High throughput on slow hardware. Decent performance on one CPU thread'}, 'description': 'Silero Text-To-Speech models provide enterprise grade TTS in a compact form-factor for several commonly spoken languages. They offer one-line usage, naturally sounding speech, no GPU or training required, minimalism and lack of dependencies, a library of voices in many languages, support for 16kHz and 8kHz out of the box.'}", "category": "generic"}
{"question_id": 10, "text": "Devise an API used to separate objects from the background in an image. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet50', 'Mean IOU': 66.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 11, "text": "Please suggest a powerful API to carry out semantic segmentation in a given image. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_mobilenet_v3_large', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_mobilenet_v3_large', 'Mean IOU': 60.3, 'Global Pixelwise Accuracy': 91.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 12, "text": "We are developing a voice assistant that needs to detect when a human is speaking. Suggest an API to detect human speech in an audio file. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Voice Activity Detection', 'api_name': 'Silero Voice Activity Detector', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-vad', 'model': 'silero_vad', 'force_reload': 'True'}, 'python_environment_requirements': {'torchaudio': 'pip install -q torchaudio'}, 'example_code': {'import': ['import torch', 'torch.set_num_threads(1)', 'from IPython.display import Audio', 'from pprint import pprint'], 'download_example': \"torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\", 'load_model': \"model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'load_utils': '(get_speech_timestamps, _, read_audio, _) = utils', 'set_sampling_rate': 'sampling_rate = 16000', 'read_audio': \"wav = read_audio('en_example.wav', sampling_rate=sampling_rate)\", 'get_speech_timestamps': 'speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sampling_rate)', 'print_speech_timestamps': 'pprint(speech_timestamps)'}, 'performance': {'dataset': '', 'accuracy': ''}, 'description': 'Silero VAD is a pre-trained enterprise-grade Voice Activity Detector (VAD) that aims to provide a high-quality and modern alternative to the WebRTC Voice Activity Detector. The model is optimized for performance on 1 CPU thread and is quantized.'}", "category": "generic"}
{"question_id": 13, "text": "Design an API for segmenting the objects in an image with the highest accuracy. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet101', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet101', 'Mean IOU': 67.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 14, "text": "We need an API for a security system that can detect objects in real-time. Recommend a solution. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'YOLOv5', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='ultralytics/yolov5', model='yolov5s', pretrained=True)\", 'api_arguments': [\"'ultralytics/yolov5'\", \"'yolov5s'\", 'pretrained=True'], 'python_environment_requirements': 'Python>=3.8, PyTorch>=1.7', 'example_code': ['import torch', \"model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\", \"imgs = ['https://ultralytics.com/images/zidane.jpg']\", 'results = model(imgs)', 'results.print()', 'results.save()', 'results.xyxy[0]', 'results.pandas().xyxy[0]'], 'performance': {'dataset': 'COCO', 'accuracy': {'YOLOv5s6': {'mAPval0.5:0.95': 43.3, 'mAPtest0.5:0.95': 43.3, 'mAPval0.5': 61.9}, 'YOLOv5m6': {'mAPval0.5:0.95': 50.5, 'mAPtest0.5:0.95': 50.5, 'mAPval0.5': 68.7}, 'YOLOv5l6': {'mAPval0.5:0.95': 53.4, 'mAPtest0.5:0.95': 53.4, 'mAPval0.5': 71.1}, 'YOLOv5x6': {'mAPval0.5:0.95': 54.4, 'mAPtest0.5:0.95': 54.4, 'mAPval0.5': 72.0}, 'YOLOv5x6 TTA': {'mAPval0.5:0.95': 55.0, 'mAPtest0.5:0.95': 55.0, 'mAPval0.5': 72.0}}}, 'description': 'YOLOv5 is a family of compound-scaled object detection models trained on the COCO dataset, and includes simple functionality for Test Time Augmentation (TTA), model ensembling, hyperparameter evolution, and export to ONNX, CoreML and TFLite.'}", "category": "generic"}
{"question_id": 15, "text": "NASA is looking to classify celestial images. They need a machine learning API that can identify objects in images. Recommend one. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x8d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x8d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x8d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x8d': {'Top-1 Acc.': '82.2', 'Top-5 Acc.': '96.4'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 16, "text": "I want to determine what objects are in an image file. Find me a model API that can classify the objects in the image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x32d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x32d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x32d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x32d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x32d': {'Top-1 Acc.': '85.1', 'Top-5 Acc.': '97.5'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 17, "text": "Find me an API for classifying different objects in images with high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x16d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x16d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x16d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x16d': {'Top-1 Acc.': '84.2', 'Top-5 Acc.': '97.2'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 18, "text": "I need an API that can create random images of clothes, like shirts, pants or dresses, any ideas? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks', 'api_name': 'DCGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='DCGAN', pretrained=True, useGPU=use_gpu)\", 'api_arguments': {'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': ['import torch', 'import matplotlib.pyplot as plt', 'import torchvision'], 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'generate_images': 'with torch.no_grad(): generated_images = model.test(noise)', 'plot_images': ['plt.imshow(torchvision.utils.make_grid(generated_images).permute(1, 2, 0).cpu().numpy())', 'plt.show()']}, 'performance': {'dataset': 'FashionGen', 'accuracy': 'N/A'}, 'description': 'DCGAN is a model designed in 2015 by Radford et. al. in the paper Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. It is a GAN architecture both very simple and efficient for low resolution image generation (up to 64x64).'}", "category": "generic"}
{"question_id": 19, "text": "I am a researcher working on a computer vision project and need a cutting-edge pre-trained image classification API. What do you suggest? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x48d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x48d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x48d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x48d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x48d': {'Top-1 Acc.': '85.4', 'Top-5 Acc.': '97.6'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 20, "text": "Develop an art piece using a GAN that can generate high quality celebrity images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks (GANs)', 'api_name': 'PGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='PGAN', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'facebookresearch/pytorch_GAN_zoo:hub', 'model': 'PGAN', 'model_name': 'celebAHQ-512', 'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': 'import torch', 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'PGAN', model_name='celebAHQ-512', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'test': 'generated_images = model.test(noise)', 'plot_images': {'import_matplotlib': 'import matplotlib.pyplot as plt', 'import_torchvision': 'import torchvision', 'make_grid': 'grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1), scale_each=True, normalize=True)', 'imshow': 'plt.imshow(grid.permute(1, 2, 0).cpu().numpy())', 'show': 'plt.show()'}}, 'performance': {'dataset': 'celebA', 'accuracy': 'High-quality celebrity faces'}, 'description': \"Progressive Growing of GANs (PGAN) is a method for generating high-resolution images using generative adversarial networks. The model is trained progressively, starting with low-resolution images and gradually increasing the resolution until the desired output is achieved. This implementation is based on the paper by Tero Karras et al., 'Progressive Growing of GANs for Improved Quality, Stability, and Variation'.\"}", "category": "generic"}
{"question_id": 21, "text": "A professional radiologist is looking to process an MRI dataset to isolate abnormalities. Help me find an API that can segment the abnormal regions within brain MRI images. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Biomedical Image Segmentation', 'api_name': 'U-Net for brain MRI', 'api_call': \"torch.hub.load(repo_or_dir='mateuszbuda/brain-segmentation-pytorch', model='unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'api_arguments': {'in_channels': 3, 'out_channels': 1, 'init_features': 32, 'pretrained': True}, 'python_environment_requirements': ['torch', 'torchvision', 'numpy', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'import numpy as np', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'm, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))', 'preprocess = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=m, std=s)])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model = model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.round(output[0]))'], 'performance': {'dataset': 'kaggle.com/mateuszbuda/lgg-mri-segmentation'}, 'description': 'U-Net with batch normalization for biomedical image segmentation with pretrained weights for abnormality segmentation in brain MRI. The model comprises four levels of blocks containing two convolutional layers with batch normalization and ReLU activation function, and one max pooling layer in the encoding part and up-convolutional layers instead in the decoding part. The number of convolutional filters in each block is 32, 64, 128, and 256. The bottleneck layer has 512 convolutional filters. From the encoding layers, skip connections are used to the corresponding layers in the decoding part. Input image is a 3-channel brain MRI slice from pre-contrast, FLAIR, and post-contrast sequences, respectively. Output is a one-channel probability map of abnormality regions with the same size as the input image.'}", "category": "generic"}
{"question_id": 22, "text": "Recommend me an API to classify images with top-notch accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNet50', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['pip install validators matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", \"print(f'Using {device} for inference')\", \"resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resnet50.eval().to(device)', 'uris = [...]', 'batch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resnet50(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'ImageNet', 'accuracy': '~0.5% top1 improvement over ResNet50 v1'}, 'description': 'The ResNet50 v1.5 model is a modified version of the original ResNet50 v1 model. The difference between v1 and v1.5 is that, in the bottleneck blocks which requires downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate (~0.5% top1) than v1, but comes with a small performance drawback (~5% imgs/sec). The model is initialized as described in Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures.'}", "category": "generic"}
{"question_id": 23, "text": "Help me classify images of cats and dogs, by recommending an API to do that. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeXt101-32x4d', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resneXt', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'validators', 'matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', 'device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")', \"print(f'Using {device} for inference')\", \"resneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resneXt')\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resneXt.eval().to(device)', 'uris = [', \" 'http://images.cocodataset.org/test-stuff2017/000000024309.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000028117.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000006149.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000004954.jpg',\", ']', 'batch = torch.cat(', ' [utils.prepare_input_from_uri(uri) for uri in uris]', ').to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resneXt(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'IMAGENET', 'accuracy': 'Not provided'}, 'description': 'ResNeXt101-32x4d is a model introduced in the Aggregated Residual Transformations for Deep Neural Networks paper. It is based on regular ResNet model, substituting 3x3 convolutions inside the bottleneck block for 3x3 grouped convolutions. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures. It can be deployed for inference on the NVIDIA Triton Inference Server using TorchScript, ONNX Runtime or TensorRT as an execution backend.'}", "category": "generic"}
{"question_id": 24, "text": "I need an API that can be used for image classification tasks with a model trained on ImageNet dataset. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'AlexNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='alexnet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 43.45, 'top-5_error': 20.91}}, 'description': 'AlexNet is a deep convolutional neural network that achieved a top-5 error of 15.3% in the 2012 ImageNet Large Scale Visual Recognition Challenge. The main contribution of the original paper was the depth of the model, which was computationally expensive but made feasible through the use of GPUs during training. The pretrained AlexNet model in PyTorch can be used for image classification tasks.'}", "category": "generic"}
{"question_id": 25, "text": "An app developer from San Francisco wants to classify images based on their content. Tell me an API that can classify images into different categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SE-ResNeXt101', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_se_resnext101_32x4d', pretrained=True)\", 'api_arguments': 'N/A', 'python_environment_requirements': 'validators, matplotlib', 'example_code': \"import torch\\nfrom PIL import Image\\nimport torchvision.transforms as transforms\\nimport numpy as np\\nimport json\\nimport requests\\nimport matplotlib.pyplot as plt\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n%matplotlib inline\\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\nprint(f'Using {device} for inference')\\nresneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_se_resnext101_32x4d')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\nresneXt.eval().to(device)\\nuris = ['http://images.cocodataset.org/test-stuff2017/000000024309.jpg','http://images.cocodataset.org/test-stuff2017/000000028117.jpg','http://images.cocodataset.org/test-stuff2017/000000006149.jpg','http://images.cocodataset.org/test-stuff2017/000000004954.jpg']\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(resneXt(batch), dim=1)\\nresults = utils.pick_n_best(predictions=output, n=5)\\nfor uri, result in zip(uris, results):\\n img = Image.open(requests.get(uri, stream=True).raw)\\n img.thumbnail((256,256), Image.ANTIALIAS)\\n plt.imshow(img)\\n plt.show()\\n print(result)\", 'performance': {'dataset': 'IMAGENET', 'accuracy': 'N/A'}, 'description': 'The SE-ResNeXt101-32x4d is a ResNeXt101-32x4d model with added Squeeze-and-Excitation module. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures, which allows researchers to get results 3x faster than training without Tensor Cores while experiencing the benefits of mixed precision training.'}", "category": "generic"}
{"question_id": 26, "text": "Identify the objects in an image using a dense convolutional network. Recommend an API for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet121', pretrained=True)\", 'api_arguments': [{'name': 'densenet121', 'type': 'str', 'description': 'Densenet-121 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet121': {'Top-1 error': 25.35, 'Top-5 error': 7.83}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 27, "text": "I'm the founder of Dobble, an AI company. We are building a virtual assistant and looking for an API to convert text to speech. Can you provide one? \n Use this API documentation for reference: {'domain': 'Text-to-Speech', 'framework': 'PyTorch', 'functionality': 'Speech Synthesis', 'api_name': 'WaveGlow', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_waveglow', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_waveglow', 'model_math': 'fp32'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': {'load_waveglow_model': \"waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp32')\", 'prepare_waveglow_model': ['waveglow = waveglow.remove_weightnorm(waveglow)', \"waveglow = waveglow.to('cuda')\", 'waveglow.eval()'], 'load_tacotron2_model': \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp32')\", 'prepare_tacotron2_model': [\"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()'], 'synthesize_speech': ['text = \"hello world, I missed you so much\"', \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'save_audio': 'write(\"audio.wav\", rate, audio_numpy)', 'play_audio': 'Audio(audio_numpy, rate=rate)'}, 'performance': {'dataset': 'LJ Speech', 'accuracy': None}, 'description': 'The Tacotron 2 and WaveGlow model form a text-to-speech system that enables users to synthesize natural-sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 28, "text": "Show me an API that can handle textual classification like sentiment analysis, emotion recognition or sarcasm detection. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'RoBERTa', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq', model='roberta.large', pretrained=True)\", 'api_arguments': [\"'pytorch/fairseq'\", \"'roberta.large'\"], 'python_environment_requirements': ['regex', 'requests', 'hydra-core', 'omegaconf'], 'example_code': ['import torch', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\", 'roberta.eval()', \"tokens = roberta.encode('Hello world!')\", 'last_layer_features = roberta.extract_features(tokens)', 'all_layers = roberta.extract_features(tokens, return_all_hiddens=True)', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\", 'roberta.eval()', \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is not very optimized.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is based on BERT.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"roberta.register_classification_head('new_task', num_classes=3)\", \"logprobs = roberta.predict('new_task', tokens)\"], 'performance': {'dataset': 'MNLI', 'accuracy': 'N/A'}, 'description': \"RoBERTa is a robustly optimized version of BERT, a revolutionary self-supervised pretraining technique that learns to predict intentionally hidden (masked) sections of text. RoBERTa builds on BERT's language masking strategy and modifies key hyperparameters, including removing BERT's next-sentence pretraining objective, and training with much larger mini-batches and learning rates. RoBERTa was also trained on an order of magnitude more data than BERT, for a longer amount of time, allowing it to generalize even better to downstream tasks.\"}", "category": "generic"}
{"question_id": 29, "text": "Recommend a Python API to perform semantic segmentation on an image. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet101', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet101': {'Mean IOU': 63.7, 'Global Pixelwise Accuracy': 91.9}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 30, "text": "I am a computer vision researcher and I'm trying to figure out which CNN model to use for image classification. Can you provide me with an API for a Dense Convolutional Network? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet169', pretrained=True)\", 'api_arguments': [{'name': 'densenet169', 'type': 'str', 'description': 'Densenet-169 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet169': {'Top-1 error': 24.0, 'Top-5 error': 7.0}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 31, "text": "I am working on a computer vision app and I need to classify objects in the images. Which API can help me classify objects with high accuracy? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet201', pretrained=True)\", 'api_arguments': [{'name': 'densenet201', 'type': 'str', 'description': 'Densenet-201 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet201': {'Top-1 error': 22.8, 'Top-5 error': 6.43}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 32, "text": "Imagine that you are working on an autonomous vehicle project and you need to process images from a camera to recognize objects in real time. Tell me about an API suitable for this purpose. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet50', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet50': {'Mean IOU': 60.5, 'Global Pixelwise Accuracy': 91.4}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 33, "text": "We need an API that can be used to create an efficient image classifier for differentiating among various dog breeds in a mobile app. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet39ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet39ds', 'type': 'str', 'description': 'HarDNet-39DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet39ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet39ds': {'Top-1 error': 27.92, 'Top-5 error': 9.57}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 34, "text": "Recommend an image classification API that requires low memory and runs faster on GPUs to classify user-uploaded photos. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68', 'type': 'str', 'description': 'HarDNet-68 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68': {'Top-1 error': 23.52, 'Top-5 error': 6.99}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory trafficCNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 35, "text": "Identify an API for a clothing e-commerce website that classifies an image into different categories such as tops, shoes, dresses, etc. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68ds', 'type': 'str', 'description': 'HarDNet-68DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68ds': {'Top-1 error': 25.71, 'Top-5 error': 8.13}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 36, "text": "Please provide me with an image classification API to identify objects in an image for a surveillance company. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'GoogLeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='googlenet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.0.0', 'torchvision': '>=0.2.2'}, 'example_code': {'import': ['import torch', 'import urllib', 'from PIL import Image', 'from torchvision import transforms'], 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\", 'model_eval': 'model.eval()', 'image_preprocessing': ['input_image = Image.open(filename)', 'preprocess = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'model_execution': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'output_processing': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'top5_prob, top5_catid = torch.topk(probabilities, 5)']}, 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 error': '30.22', 'Top-5 error': '10.47'}}, 'description': \"GoogLeNet is based on a deep convolutional neural network architecture codenamed 'Inception', which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014).\"}", "category": "generic"}
{"question_id": 37, "text": "I am working on a project that needs a lightweight image classification solution. Suggest me an API to use. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Efficient networks by generating more features from cheap operations', 'api_name': 'GhostNet', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/ghostnet', model='ghostnet_1x', pretrained=True)\", 'api_arguments': ['pretrained'], 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/ghostnet', 'ghostnet_1x', pretrained=True)\", 'model.eval()', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 acc': '73.98', 'Top-5 acc': '91.46'}}, 'description': 'The GhostNet architecture is based on an Ghost module structure which generates more features from cheap operations. Based on a set of intrinsic feature maps, a series of cheap operations are applied to generate many ghost feature maps that could fully reveal information underlying intrinsic features. Experiments conducted on benchmarks demonstrate the superiority of GhostNet in terms of speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 38, "text": "I am a computer science researcher interested in selecting an efficient image classification model. Can you recommend me an API that would be suitable for that purpose? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet85', pretrained=True)\", 'api_arguments': [{'name': 'hardnet85', 'type': 'str', 'description': 'HarDNet-85 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet85', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet85': {'Top-1 error': 21.96, 'Top-5 error': 6.11}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 39, "text": "A company is developing a machine-learning based software to categorize their products based on the photos they take. Provide an API that can help them classify their images and name the image types. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet50_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet50_ibn_a', 'type': 'str', 'description': 'ResNet-50-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet50_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet50_ibn_a': {'Top-1 acc': 77.46, 'Top-5 acc': 93.68}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 40, "text": "A machine learning engineer is working on generalization for classification tasks in different domains. Suggest an API that is suitable for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet101_ibn_a', 'type': 'str', 'description': 'ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet101_ibn_a': {'Top-1 acc': 78.61, 'Top-5 acc': 94.41}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 41, "text": "We want our AI powered traffic camera to classify different types of vehicles with high accuracy. Provide an API suggestion for this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnext101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_ibn_a', 'type': 'str', 'description': 'ResNeXt-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnext101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext101_ibn_a': {'Top-1 acc': 79.12, 'Top-5 acc': 94.58}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 42, "text": "I'm working on a project that needs a deep learning model to identify similar objects across different domains. Suggest me an API that can serve the purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='se_resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'se_resnet101_ibn_a', 'type': 'str', 'description': 'SE-ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'se_resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'se_resnet101_ibn_a': {'Top-1 acc': 78.75, 'Top-5 acc': 94.49}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 43, "text": "A new ecommerce store wants to automatically categorize images of products into different classes. Recommend an API that can perform image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest101', pretrained=True)\", 'api_arguments': 'resnest101', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-101': 82.83}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 44, "text": "An e-commerce company is building an AI to classify pictures of products into categories automatically. Recommend an API to help in classifying images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest50', pretrained=True)\", 'api_arguments': 'resnest50', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-50': 81.03}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 45, "text": "A developer is trying to build an image classifier. Provide an API capable of classifying images and telling what objects are present. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'Inception_v3', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='inception_v3', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '1.9.0', 'torchvision': '0.10.0'}, 'example_code': {'import_libraries': 'import torch', 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\", 'model_evaluation': 'model.eval()'}, 'performance': {'dataset': 'imagenet', 'accuracy': {'top-1_error': 22.55, 'top-5_error': 6.44}}, 'description': 'Inception v3, also called GoogleNetv3, is a famous Convolutional Neural Network trained on the ImageNet dataset from 2015. It is based on the exploration of ways to scale up networks to utilize the added computation as efficiently as possible by using suitably factorized convolutions and aggressive regularization. The model achieves a top-1 error of 22.55% and a top-5 error of 6.44% on the ImageNet dataset.'}", "category": "generic"}
{"question_id": 46, "text": "Is there an API to implement ResNeSt for image classification purposes? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest200', pretrained=True)\", 'api_arguments': 'resnest200', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest200', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-200': 83.84}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 47, "text": "In order to create classifiers for popular recipes from the internet, I would like to locate an API that can efficiently classify a given food image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest269', pretrained=True)\", 'api_arguments': 'resnest269', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest269', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-269': 84.54}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 48, "text": "Recommend me an API to classify images in a mobile app for users that sorts their images in predefined categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_cpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_cpu', 'type': 'str', 'description': 'ProxylessNAS optimized for CPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_cpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_cpu', 'accuracy': 75.3}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 49, "text": "I need to classify the content of an image using a pretrained model optimized for GPU. Show me an API that can do that. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_gpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_gpu', 'type': 'str', 'description': 'ProxylessNAS optimized for GPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_gpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_gpu', 'accuracy': 75.1}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 50, "text": "I need an API for classifying objects in mobile application. What is the best API for classifying objects with mobile devices? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_mobile', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_mobile', 'type': 'str', 'description': 'ProxylessNAS optimized for Mobile'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_mobile'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_mobile', 'accuracy': 74.6}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 51, "text": "I'm uploading my paintings to an online art gallery and I need to know what categories they might fit into. Find an API to recommend categories based on the images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet18', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet18', 'top-1_error': 30.24, 'top-5_error': 10.92}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 52, "text": "A photographer needs an AI-based solution to help classify a variety of images. Recommend an appropriate API that can classify an image into one of 1000 categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MobileNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='mobilenet_v2', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 28.12, 'top-5_error': 9.71}}, 'description': 'The MobileNet v2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input. MobileNet v2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, non-linearities in the narrow layers were removed in order to maintain representational power.'}", "category": "generic"}
{"question_id": 53, "text": "I have a large image dataset in need of image classification using deep residual networks. Can you recommend an API that can achieve this for me? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet34', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet34', 'top-1_error': 26.7, 'top-5_error': 8.58}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 54, "text": "I am developing an app that can recognize diverse objects in pictures. Identify an API that can help me achieve this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet101', 'top-1_error': 22.63, 'top-5_error': 6.44}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 55, "text": "I am having trouble with my tomato plants and want some help figuring out what's wrong with them. I need an AI that can spot diseases in plants given an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet50', 'top-1_error': 23.85, 'top-5_error': 7.13}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 56, "text": "Which API should I use to build a tomato classification app that detects diseases in tomato plant leaves? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet152', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet152', 'top-1_error': 21.69, 'top-5_error': 5.94}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 57, "text": "I want to categorize a given image into a certain class like animals or objects. Identify an API that can do that. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext50_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext50_32x4d': {'top-1': 22.38, 'top-5': 6.3}}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 58, "text": "I want to sort images of animals into appropriate categories. What API should I use? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext101_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext101_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'resnext101_32x8d': {'top-1': 20.69, 'top-5': 5.47}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 59, "text": "Provide an API for classifying the objects present in an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_b', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_b', 'type': 'str', 'description': 'SNNMLP Base model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_b', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Base', 'top-1': 85.59}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 60, "text": "I want an API that can classify images and tell me what the images are. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_s', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_s', 'type': 'str', 'description': 'SNNMLP Small model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_s', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Small', 'top-1': 83.3}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 61, "text": "Find me a pre-trained API to identify objects in real-time, taking into account a database of more than 100 classes from ImageNet. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_t', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_t', 'type': 'str', 'description': 'SNNMLP Tiny model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_t', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Tiny', 'top-1': 81.88}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 62, "text": "As a biologist, I need to identify the species in a photo. Which API should I use to classify images into different categories? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_0', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_0'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_0': {'Top-1 error': 41.9, 'Top-5 error': 19.58}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 63, "text": "I need a lightweight API to classify images based on a training set of images from my new mobile app. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ShuffleNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='shufflenet_v2_x1_0', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'torch', 'torchvision': 'torchvision', 'PIL': 'Image', 'urllib': 'urllib'}, 'example_code': {'import_libraries': ['import torch', 'from PIL import Image', 'from torchvision import transforms', 'import urllib'], 'load_model': [\"model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\", 'model.eval()'], 'load_image': [\"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'try: urllib.URLopener().retrieve(url, filename)', 'except: urllib.request.urlretrieve(url, filename)', 'input_image = Image.open(filename)'], 'preprocess_image': ['preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'run_inference': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'get_probabilities': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'top_categories': ['top5_prob, top5_catid = torch.topk(probabilities, 5)', 'for i in range(top5_prob.size(0)):', ' print(categories[top5_catid[i]], top5_prob[i].item())']}, 'performance': {'dataset': 'Imagenet', 'accuracy': {'top-1_error': 30.64, 'top-5_error': 11.68}}, 'description': 'ShuffleNet V2 is an efficient ConvNet optimized for speed and memory, pre-trained on Imagenet. It is designed based on practical guidelines for efficient network design, including speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 64, "text": "What is an efficient deep learning model for categorizing images into object classes with fewer parameters? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_1', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_1'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_1': {'Top-1 error': 41.81, 'Top-5 error': 19.38}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 65, "text": "Recommend a well-tested API to identify objects in a digital photograph for my photo gallery website. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11', pretrained=True)\", 'api_arguments': [{'name': 'vgg11', 'type': 'str', 'description': 'VGG11 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11': {'Top-1 error': 30.98, 'Top-5 error': 11.37}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 66, "text": "Recommend an image recognition API that I can use for classifying images of animals. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13', pretrained=True)\", 'api_arguments': [{'name': 'vgg13', 'type': 'str', 'description': 'VGG13 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13': {'Top-1 error': 30.07, 'Top-5 error': 10.75}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn,vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 67, "text": "I want an API that allows me to recognize and classify different breeds of dogs from images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg11_bn', 'type': 'str', 'description': 'VGG11 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11_bn': {'Top-1 error': 26.7, 'Top-5 error': 8.58}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 68, "text": "I am a software engineer and I am trying to create an image recognition system for my latest project. Find an API that can tell me the category of the objects in a provided image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg13_bn', 'type': 'str', 'description': 'VGG13 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13_bn': {'Top-1 error': 28.45, 'Top-5 error': 9.63}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 69, "text": "Propose an API to identify what is in a photo of a bird in order to label it with the correct species. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16', pretrained=True)\", 'api_arguments': [{'name': 'vgg16', 'type': 'str', 'description': 'VGG16 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16': {'Top-1 error': 28.41, 'Top-5 error': 9.62}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 70, "text": "Tell me the best API to be used on a security camera to classify vehicles and details about them given an image \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19', pretrained=True)\", 'api_arguments': [{'name': 'vgg19', 'type': 'str', 'description': 'VGG19 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19': {'Top-1 error': 27.62, 'Top-5 error': 9.12}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 71, "text": "An e-commerce website looking for APIs to create image classifiers for their products. Offer a solution based on the VGG model. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg16_bn', 'type': 'str', 'description': 'VGG16 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16_bn': {'Top-1 error': 26.63, 'Top-5 error': 8.5}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 72, "text": "Recommending the best machine learning models or APIs that is good for classifying a dataset of images with over 1000 categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg19_bn', 'type': 'str', 'description': 'VGG19 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19_bn': {'Top-1 error': 25.76, 'Top-5 error': 8.15}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 73, "text": "An e-commerce platform wants to categorize their items by image. Tell me an API that can do this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet50_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet50_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet50_2': {'Top-1 error': 21.49, 'Top-5 error': 5.91}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 74, "text": "Suggest a neural network that can effectively identify different types of birds in high-resolution images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet101_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet101_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet101_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet101_2': {'Top-1 error': 21.16, 'Top-5 error': 5.72}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 75, "text": "I want to build a video filter app that can separate video clips by different activities. Can you suggest an API that can classify videos into different categories based on the activities happening in the video? \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'SlowFast Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slowfast_r50', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'slowfast_r50', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 76.94, 'top5': 92.69}, 'flops': 65.71, 'params': 34.57}, 'description': \"Slow Fast model architectures are based on the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al. They are pretrained on the Kinetics 400 dataset using the 8x8 setting. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 76, "text": "What's the best API for automatically detecting sports or activities types in a video clip for an application? \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'X3D Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='x3d_s', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'x3d_s', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_s', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 73.33, 'top5': 91.27}, 'flops': 2.96, 'params': 3.79}, 'description': \"X3D model architectures are based on the paper 'X3D: Expanding Architectures for Efficient Video Recognition' by Christoph Feichtenhofer. They are pretrained on the Kinetics 400 dataset. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 77, "text": "A mobile app company wants to build an object classification solution for their Android app. Give me an API that can classify objects in images with low latency and high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Once-for-all (OFA) Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/once-for-all', model='ofa_supernet_mbv3_w10', pretrained=True)\", 'api_arguments': {'repository': 'mit-han-lab/once-for-all', 'model': 'ofa_supernet_mbv3_w10', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"super_net_name = 'ofa_supernet_mbv3_w10'\", \"super_net = torch.hub.load('mit-han-lab/once-for-all', super_net_name, pretrained=True).eval()\"], 'performance': {'description': 'OFA networks outperform state-of-the-art NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x faster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency) while reducing many orders of magnitude GPU hours and CO2 emission.'}, 'description': 'Once-for-all (OFA) networks are a family of neural networks designed by MIT Han Lab. They decouple training and search, achieving efficient inference across various edge devices and resource constraints. OFA networks are pretrained on the IMAGENET dataset and are capable of classifying images into different categories.'}", "category": "generic"}
{"question_id": 78, "text": "I would like to build a tool that can produce human-like text given an input prompt. Recommend an API that can help me construct realistic sentences. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Natural Language Processing', 'api_name': 'PyTorch-Transformers', 'api_call': \"torch.hub.load(repo_or_dir='huggingface/pytorch-transformers')\", 'api_arguments': ['pretrained_model_or_path', 'output_attention', 'output_hidden_states', 'config', 'from_tf'], 'python_environment_requirements': ['tqdm', 'boto3', 'requests', 'regex', 'sentencepiece', 'sacremoses'], 'example_code': 'import torch\\ntokenizer = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'tokenizer\\', \\'bert-base-cased\\')\\n\\ntext_1 = \"Jim Henson was a puppeteer\"\\ntext_2 = \"Who was Jim Henson ?\"\\n\\nindexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\\n\\nmodel = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'model\\', \\'bert-base-cased\\')\\n\\nwith torch.no_grad():\\n encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)', 'performance': {'dataset': [{'name': 'MRPC', 'accuracy': 'Not provided'}]}, 'description': 'PyTorch-Transformers is a library of state-of-the-art pre-trained models for Natural Language Processing (NLP) including BERT, GPT, GPT-2, Transformer-XL, XLNet, XLM, RoBERTa, and DistilBERT. The library provides functionality for tokenization, configuration, and various model architectures for different tasks such as causal language modeling, sequence classification, question answering, and masked language modeling.'}", "category": "generic"}
{"question_id": 79, "text": "A wildlife photographer needs to classify his collection of animal images. Which API can be used to assist the photographer in image classification? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Semi-supervised and semi-weakly supervised ImageNet Models', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/semi-supervised-ImageNet1K-models', model='resnet18_swsl', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/semi-supervised-ImageNet1K-models', 'model': 'resnet18_swsl', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl', pretrained=True)\", 'model.eval()'], 'performance': {'description': 'Semi-supervised and semi-weakly supervised ImageNet models achieve state-of-the-art accuracy of 81.2% on ImageNet for the widely used/adopted ResNet-50 model architecture.'}, 'description': \"Semi-supervised and semi-weakly supervised ImageNet Models are introduced in the 'Billion scale semi-supervised learning for image classification' paper. These models are pretrained on a subset of unlabeled YFCC100M public image dataset and fine-tuned with the ImageNet1K training dataset. They are capable of classifying images into different categories and are provided by the Facebook Research library.\"}", "category": "generic"}
{"question_id": 80, "text": "I work at a small company that creates a deep learning-based smartphone app. I need a model to classify images super fast and with high performance. Guide me to the right API. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'GPUNet Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", 'api_arguments': {'repository': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_gpunet', 'pretrained': 'True', 'model_type': 'GPUNet-0', 'model_math': 'fp32'}, 'python_environment_requirements': ['torch', 'validators', 'matplotlib', 'timm==0.5.4'], 'example_code': ['import torch', \"model_type = 'GPUNet-0'\", \"precision = 'fp32'\", \"gpunet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'gpunet.to(device)', 'gpunet.eval()'], 'performance': {'dataset': 'IMAGENET', 'description': 'GPUNet demonstrates state-of-the-art inference performance up to 2x faster than EfficientNet-X and FBNet-V3.'}, 'description': 'GPUNet is a family of Convolutional Neural Networks designed by NVIDIA using novel Neural Architecture Search (NAS) methods. They are optimized for NVIDIA GPU and TensorRT performance. GPUNet models are pretrained on the IMAGENET dataset and are capable of classifying images into different categories. The models are provided by the NVIDIA Deep Learning Examples library.'}", "category": "generic"}
{"question_id": 81, "text": "Recommend an API for translating English text to French text. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Neural Machine Translation', 'api_name': 'Transformer (NMT)', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq')\", 'api_arguments': ['model_name', 'tokenizer', 'bpe', 'beam', 'sampling', 'sampling_topk'], 'python_environment_requirements': ['bitarray', 'fastBPE', 'hydra-core', 'omegaconf', 'regex', 'requests', 'sacremoses', 'subword_nmt'], 'example_code': \"import torch\\n\\nen2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\\n\\nen2fr.cuda()\\n\\nfr = en2fr.translate('Hello world!', beam=5)\\nassert fr == 'Bonjour \u00e0 tous !'\", 'performance': {'dataset': [{'name': \"WMT'14\", 'accuracy': 'Not provided'}, {'name': \"WMT'18\", 'accuracy': 'Not provided'}, {'name': \"WMT'19\", 'accuracy': 'Not provided'}]}, 'description': \"Transformer (NMT) is a powerful sequence-to-sequence modeling architecture that produces state-of-the-art neural machine translation systems. It is based on the paper 'Attention Is All You Need' and has been improved using techniques such as large-scale semi-supervised training, back-translation, and noisy-channel reranking. It supports English-French and English-German translation as well as round-trip translation for paraphrasing.\"}", "category": "generic"}
{"question_id": 82, "text": "Tell me an API for image classification with high accuracy and less computation resources. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'EfficientNet', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_efficientnet_b0', pretrained=True)\", 'api_arguments': ['model_name', 'pretrained'], 'python_environment_requirements': ['validators', 'matplotlib'], 'example_code': \"import torch\\n\\nefficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\n\\nefficientnet.eval().to(device)\\n\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\n\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(efficientnet(batch), dim=1)\\n \\nresults = utils.pick_n_best(predictions=output, n=5)\", 'performance': {'dataset': {'name': 'IMAGENET', 'accuracy': 'Not provided'}}, 'description': 'EfficientNet is a family of image classification models that achieve state-of-the-art accuracy while being smaller and faster. The models are trained with mixed precision using Tensor Cores on the NVIDIA Volta and Ampere GPU architectures. The EfficientNet models include EfficientNet-B0, EfficientNet-B4, EfficientNet-WideSE-B0, and EfficientNet-WideSE-B4. The WideSE models use wider Squeeze-and-Excitation layers than the original EfficientNet models, resulting in slightly better accuracy.'}", "category": "generic"}
{"question_id": 83, "text": "A social media company wants to detect if an image uploaded by users contains any inappropriate content. Recommend an API for this. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Single Shot MultiBox Detector', 'api_name': 'SSD', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_ssd', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['numpy', 'scipy', 'scikit-image', 'matplotlib'], 'example_code': \"import torch\\n\\nssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\\n\\nssd_model.to('cuda')\\nssd_model.eval()\\n\\ninputs = [utils.prepare_input(uri) for uri in uris]\\ntensor = utils.prepare_tensor(inputs)\\n\\nwith torch.no_grad():\\n detections_batch = ssd_model(tensor)\\n\\nresults_per_input = utils.decode_results(detections_batch)\\nbest_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\", 'performance': {'dataset': {'name': 'COCO', 'accuracy': 'Not provided'}}, 'description': \"The SSD (Single Shot MultiBox Detector) model is an object detection model based on the paper 'SSD: Single Shot MultiBox Detector'. It uses a deep neural network for detecting objects in images. This implementation replaces the obsolete VGG model backbone with the more modern ResNet-50 model. The SSD model is trained on the COCO dataset and can be used to detect objects in images with high accuracy and efficiency.\"}", "category": "generic"}
{"question_id": 84, "text": "Create a program to identify the species of a bird from an image taken from a bird watching trip in north America. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V1', model='mealv1_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv1_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V1 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '78.21', 'top5': '94.01'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 85, "text": "I run an online fashion store, and I'm looking for an AI model that can categorize images of clothing items into their respective categories. Suggest a suitable API for me to use. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.67', 'top5': '95.09'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 86, "text": "Recommend an API that can help me distinguish between cats and dogs in an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_cutmix', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_cutmix'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 + CutMix w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.98', 'top5': '95.35'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 87, "text": "What API do you recommend to discriminate between different breeds of dogs using only the color of the dogs?' \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 1.0', 'resolution': '224', 'parameters': '2.54M', 'top1': '69.65', 'top5': '88.71'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 88, "text": "Present an API to determine what plant is in a photo from a database containing 100,000 images without the use of common tricks. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_380x380', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_380x380'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '380', 'parameters': '25.6M', 'top1': '81.72', 'top5': '95.81'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 89, "text": "I am working on a project to classify images into different classes. Give me a API that has been pre-trained and can classify images across a wide range of categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_075', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_075'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 0.75', 'resolution': '224', 'parameters': '2.04M', 'top1': '67.60', 'top5': '87.23'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 90, "text": "I need an API that does Image Classification, which is pretrained on ImageNet dataset and has high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenet_v3_large_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenet_v3_large_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Large 1.0', 'resolution': '224', 'parameters': '5.48M', 'top1': '76.92', 'top5': '93.32'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 91, "text": "How can we convert spoken text \"The weather is nice today. Should we go for a walk?\" into speech using a deep learning model?, 'Input': 'The weather is nice today. Should we go for a walk?' \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Text-to-Speech', 'api_name': 'Tacotron 2', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_tacotron2', model_math='fp16')\", 'api_arguments': {'model_math': 'fp16'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': ['import torch', \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\", \"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()', \"text = 'Hello world, I missed you so much.'\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'performance': {'dataset': 'LJ Speech', 'accuracy': 'Not specified'}, 'description': 'The Tacotron 2 model generates mel spectrograms from input text using an encoder-decoder architecture, and it is designed for generating natural-sounding speech from raw transcripts without any additional prosody information. This implementation uses Dropout instead of Zoneout to regularize the LSTM layers. The WaveGlow model (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 92, "text": "FastEVs is developing an electric autonomous vehicle and needs an API to perceive traffic objects and detect drivable areas in real-time. Recommend a suitable API. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Traffic Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'HybridNets', 'api_call': \"torch.hub.load(repo_or_dir='datvuthanh/hybridnets', model='hybridnets', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'Python>=3.7, PyTorch>=1.10', 'example_code': \"import torch\\nmodel = torch.hub.load('datvuthanh/hybridnets', 'hybridnets', pretrained=True)\\nimg = torch.randn(1,3,640,384)\\nfeatures, regression, classification, anchors, segmentation = model(img)\", 'performance': {'dataset': [{'name': 'BDD100K', 'accuracy': {'Traffic Object Detection': {'Recall (%)': 92.8, 'mAP@0.5 (%)': 77.3}, 'Drivable Area Segmentation': {'Drivable mIoU (%)': 90.5}, 'Lane Line Detection': {'Accuracy (%)': 85.4, 'Lane Line IoU (%)': 31.6}}}]}, 'description': 'HybridNets is an end2end perception network for multi-tasks. Our work focused on traffic object detection, drivable area segmentation and lane detection. HybridNets can run real-time on embedded systems, and obtains SOTA Object Detection, Lane Detection on BDD100K Dataset.'}", "category": "generic"}
{"question_id": 93, "text": "Develop an application that classifies actions in sports videos. Recommend a suitable API to help analyze the videos and understand the actions performed. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorch', 'functionality': '3D ResNet', 'api_name': 'slow_r50', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slow_r50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'json', 'urllib', 'pytorchvideo', 'torchvision', 'torchaudio', 'torchtext', 'torcharrow', 'TorchData', 'TorchRec', 'TorchServe', 'PyTorch on XLA Devices'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top_1': 74.58, 'top_5': 91.63}, 'Flops (G)': 54.52, 'Params (M)': 32.45}, 'description': \"The 3D ResNet model is a Resnet-style video classification network pretrained on the Kinetics 400 dataset. It is based on the architecture from the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al.\"}", "category": "generic"}
{"question_id": 94, "text": "A startup is looking to build a drone security system for detecting intruders in restricted areas. Suggest an API suitable for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_efficientnet_b0', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_efficientnet_b0'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ EfficientNet-B0', 'resolution': '224', 'parameters': '5.29M', 'top1': '78.29', 'top5': '93.95'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 95, "text": "An autonomous vehicle company requires an API capable of object detection, drivable area segmentation, and lane detection. Provide the API and an example code to fulfill their requirements. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'YOLOP', 'api_call': \"torch.hub.load(repo_or_dir='hustvl/yolop', model='yolop', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'pip install -qr https://github.com/hustvl/YOLOP/blob/main/requirements.txt', 'example_code': \"import torch\\nmodel = torch.hub.load('hustvl/yolop', 'yolop', pretrained=True)\\nimg = torch.randn(1,3,640,640)\\ndet_out, da_seg_out,ll_seg_out = model(img)\", 'performance': {'dataset': 'BDD100K', 'accuracy': {'Object Detection': {'Recall(%)': 89.2, 'mAP50(%)': 76.5, 'Speed(fps)': 41}, 'Drivable Area Segmentation': {'mIOU(%)': 91.5, 'Speed(fps)': 41}, 'Lane Detection': {'mIOU(%)': 70.5, 'IOU(%)': 26.2}}}, 'description': 'YOLOP is an efficient multi-task network that can jointly handle three crucial tasks in autonomous driving: object detection, drivable area segmentation and lane detection. And it is also the first to reach real-time on embedded devices while maintaining state-of-the-art level performance on the BDD100K dataset.'}", "category": "generic"}
{"question_id": 96, "text": "Recommend an API to estimate relative depth from a single input image to help with Real Estate floor plans. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Large', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Large')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 97, "text": "I want to calculate the relative depth of a scene from a single photo. Recommend an API for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Hybrid', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Hybrid')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 98, "text": "I have a photo of an outdoor landscape, and I want to determine the relative depth of objects in the image. Provide an API that will help me achieve this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='MiDaS_small', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 99, "text": "I want an API to separate music into vocals, drums, bass, and other instruments for a music application I am developing. What API should I use? \n Use this API documentation for reference: {'domain': 'Audio Separation', 'framework': 'PyTorch', 'functionality': 'Music Source Separation', 'api_name': 'Open-Unmix', 'api_call': \"torch.hub.load(repo_or_dir='sigsep/open-unmix-pytorch', model='umxhq', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['PyTorch >=1.6.0', 'torchaudio'], 'example_code': ['import torch', \"separator = torch.hub.load('sigsep/open-unmix-pytorch', 'umxhq')\", 'audio = torch.rand((1, 2, 100000))', 'original_sample_rate = separator.sample_rate', 'estimates = separator(audio)'], 'performance': {'dataset': 'MUSDB18', 'accuracy': 'N/A'}, 'description': 'Open-Unmix provides ready-to-use models that allow users to separate pop music into four stems: vocals, drums, bass and the remaining other instruments. The models were pre-trained on the freely available MUSDB18 dataset.'}", "category": "generic"}
{"question_id": 100, "text": "Make a list of semantic audio conversion tasks, and specify a suitable API for speech to text conversion from various audio input formats. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Speech-To-Text', 'api_name': 'Silero Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_stt', 'language': ['en', 'de', 'es'], 'device': 'device'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf soundfile'], 'example_code': ['import torch', 'import zipfile', 'import torchaudio', 'from glob import glob', \"device = torch.device('cpu')\", \"model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', language='en', device=device)\", '(read_batch, split_into_batches, read_audio, prepare_model_input) = utils', \"torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav', dst ='speech_orig.wav', progress=True)\", \"test_files = glob('speech_orig.wav')\", 'batches = split_into_batches(test_files, batch_size=10)', 'input = prepare_model_input(read_batch(batches[0]), device=device)', 'output = model(input)', 'for example in output:', ' print(decoder(example.cpu()))'], 'performance': {'dataset': 'Open-STT', 'accuracy': 'See the wiki for quality and performance benchmarks'}, 'description': 'Silero Speech-To-Text models provide enterprise grade STT in a compact form-factor for several commonly spoken languages. The models are robust to a variety of dialects, codecs, domains, noises, and lower sampling rates. They consume a normalized audio in the form of samples and output frames with token probabilities. A decoder utility is provided for simplicity.'}", "category": "generic"}
{"question_id": 101, "text": "I am building a bird identification app but I have trouble indentifying birds from photo. Which API can I use to indentify birds given a photo? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Fine-grained image classifier', 'api_name': 'ntsnet', 'api_call': \"torch.hub.load(repo_or_dir='nicolalandro/ntsnet-cub200', model='ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\", 'api_arguments': {'pretrained': 'True', 'topN': '6', 'device': 'cpu', 'num_classes': '200'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': \"from torchvision import transforms\\nimport torch\\nimport urllib\\nfrom PIL import Image\\n\\ntransform_test = transforms.Compose([\\n transforms.Resize((600, 600), Image.BILINEAR),\\n transforms.CenterCrop((448, 448)),\\n transforms.ToTensor(),\\n transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\\n])\\n\\nmodel = torch.hub.load('nicolalandro/ntsnet-cub200', 'ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\\nmodel.eval()\\n\\nurl = 'https://raw.githubusercontent.com/nicolalandro/ntsnet-cub200/master/images/nts-net.png'\\nimg = Image.open(urllib.request.urlopen(url))\\nscaled_img = transform_test(img)\\ntorch_images = scaled_img.unsqueeze(0)\\n\\nwith torch.no_grad():\\n top_n_coordinates, concat_out, raw_logits, concat_logits, part_logits, top_n_index, top_n_prob = model(torch_images)\\n\\n_, predict = torch.max(concat_logits, 1)\\npred_id = predict.item()\\nprint('bird class:', model.bird_classes[pred_id])\", 'performance': {'dataset': 'CUB200 2011', 'accuracy': 'Not provided'}, 'description': 'This is an nts-net pretrained with CUB200 2011 dataset, which is a fine-grained dataset of birds species.'}", "category": "generic"}
{"question_id": 102, "text": "A business meeting is being transcribed, and we need to detect speech segments in the recorded audio. Provide me with an API to perform voice activity detection on the audio file. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Voice Activity Detection', 'api_name': 'Silero Voice Activity Detector', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-vad', 'model': 'silero_vad', 'force_reload': 'True'}, 'python_environment_requirements': {'torchaudio': 'pip install -q torchaudio'}, 'example_code': {'import': ['import torch', 'torch.set_num_threads(1)', 'from IPython.display import Audio', 'from pprint import pprint'], 'download_example': \"torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\", 'load_model': \"model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'load_utils': '(get_speech_timestamps, _, read_audio, _) = utils', 'set_sampling_rate': 'sampling_rate = 16000', 'read_audio': \"wav = read_audio('en_example.wav', sampling_rate=sampling_rate)\", 'get_speech_timestamps': 'speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sampling_rate)', 'print_speech_timestamps': 'pprint(speech_timestamps)'}, 'performance': {'dataset': '', 'accuracy': ''}, 'description': 'Silero VAD is a pre-trained enterprise-grade Voice Activity Detector (VAD) that aims to provide a high-quality and modern alternative to the WebRTC Voice Activity Detector. The model is optimized for performance on 1 CPU thread and is quantized.'}", "category": "generic"}
{"question_id": 103, "text": "A drone company, SkyEye, wants to use an API that will segment the image collected from the drone for better object recognition. Recommend an API that could handle this task. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet101', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet101', 'Mean IOU': 67.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 104, "text": "Identify an API to perform semantic segmentation of the street labeled with road, sidewalk, and building for a given picture. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet50', 'Mean IOU': 66.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 105, "text": "A photographer wants to separate the foreground and background in their images using semantic segmentation. Suggest an API for this purpose. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_mobilenet_v3_large', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_mobilenet_v3_large', 'Mean IOU': 60.3, 'Global Pixelwise Accuracy': 91.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 106, "text": "Propose a neural network model to use for detecting furniture in photos and identifying their types. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'YOLOv5', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='ultralytics/yolov5', model='yolov5s', pretrained=True)\", 'api_arguments': [\"'ultralytics/yolov5'\", \"'yolov5s'\", 'pretrained=True'], 'python_environment_requirements': 'Python>=3.8, PyTorch>=1.7', 'example_code': ['import torch', \"model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\", \"imgs = ['https://ultralytics.com/images/zidane.jpg']\", 'results = model(imgs)', 'results.print()', 'results.save()', 'results.xyxy[0]', 'results.pandas().xyxy[0]'], 'performance': {'dataset': 'COCO', 'accuracy': {'YOLOv5s6': {'mAPval0.5:0.95': 43.3, 'mAPtest0.5:0.95': 43.3, 'mAPval0.5': 61.9}, 'YOLOv5m6': {'mAPval0.5:0.95': 50.5, 'mAPtest0.5:0.95': 50.5, 'mAPval0.5': 68.7}, 'YOLOv5l6': {'mAPval0.5:0.95': 53.4, 'mAPtest0.5:0.95': 53.4, 'mAPval0.5': 71.1}, 'YOLOv5x6': {'mAPval0.5:0.95': 54.4, 'mAPtest0.5:0.95': 54.4, 'mAPval0.5': 72.0}, 'YOLOv5x6 TTA': {'mAPval0.5:0.95': 55.0, 'mAPtest0.5:0.95': 55.0, 'mAPval0.5': 72.0}}}, 'description': 'YOLOv5 is a family of compound-scaled object detection models trained on the COCO dataset, and includes simple functionality for Test Time Augmentation (TTA), model ensembling, hyperparameter evolution, and export to ONNX, CoreML and TFLite.'}", "category": "generic"}
{"question_id": 107, "text": "Alex is a deaf user who needs an app to convert text to voice. Which API would you recommend for that? \n Use this API documentation for reference: {'domain': 'Text-To-Speech', 'framework': 'PyTorch', 'functionality': 'Text-To-Speech', 'api_name': 'Silero Text-To-Speech Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_tts', 'language': 'language', 'speaker': 'speaker'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf'], 'example_code': \"import torch\\nlanguage = 'en'\\nspeaker = 'lj_16khz'\\ndevice = torch.device('cpu')\\nmodel, symbols, sample_rate, example_text, apply_tts = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', language=language, speaker=speaker)\\nmodel = model.to(device)\\naudio = apply_tts(texts=[example_text], model=model, sample_rate=sample_rate, symbols=symbols, device=device)\", 'performance': {'dataset': [{'language': 'Russian', 'speakers': 6}, {'language': 'English', 'speakers': 1}, {'language': 'German', 'speakers': 1}, {'language': 'Spanish', 'speakers': 1}, {'language': 'French', 'speakers': 1}], 'accuracy': 'High throughput on slow hardware. Decent performance on one CPU thread'}, 'description': 'Silero Text-To-Speech models provide enterprise grade TTS in a compact form-factor for several commonly spoken languages. They offer one-line usage, naturally sounding speech, no GPU or training required, minimalism and lack of dependencies, a library of voices in many languages, support for 16kHz and 8kHz out of the box.'}", "category": "generic"}
{"question_id": 108, "text": "Recommend me an API that identifies animals in a given image to feed as data to other functionalities. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x16d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x16d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x16d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x16d': {'Top-1 Acc.': '84.2', 'Top-5 Acc.': '97.2'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 109, "text": "We are building an image classifier for our meme sharing platform. Suggest an API for high-accuracy image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x48d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x48d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x48d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x48d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x48d': {'Top-1 Acc.': '85.4', 'Top-5 Acc.': '97.6'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 110, "text": "Suggest an API that can identify the species of a bird from an image taken in Yosemite National Park. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x32d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x32d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x32d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x32d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x32d': {'Top-1 Acc.': '85.1', 'Top-5 Acc.': '97.5'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 111, "text": "An artist is trying to generate new art from existing 64x64 art images for an online gallery. Provide me an API that can generate new images utilizing training data of previously generated art images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks', 'api_name': 'DCGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='DCGAN', pretrained=True, useGPU=use_gpu)\", 'api_arguments': {'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': ['import torch', 'import matplotlib.pyplot as plt', 'import torchvision'], 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'generate_images': 'with torch.no_grad(): generated_images = model.test(noise)', 'plot_images': ['plt.imshow(torchvision.utils.make_grid(generated_images).permute(1, 2, 0).cpu().numpy())', 'plt.show()']}, 'performance': {'dataset': 'FashionGen', 'accuracy': 'N/A'}, 'description': 'DCGAN is a model designed in 2015 by Radford et. al. in the paper Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. It is a GAN architecture both very simple and efficient for low resolution image generation (up to 64x64).'}", "category": "generic"}
{"question_id": 112, "text": "I want to know more about ResNet50 from NVIDIA Deep Learning Examples. Provide me with an API that I can use in my system to classify images with high precision. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNet50', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['pip install validators matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", \"print(f'Using {device} for inference')\", \"resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resnet50.eval().to(device)', 'uris = [...]', 'batch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resnet50(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'ImageNet', 'accuracy': '~0.5% top1 improvement over ResNet50 v1'}, 'description': 'The ResNet50 v1.5 model is a modified version of the original ResNet50 v1 model. The difference between v1 and v1.5 is that, in the bottleneck blocks which requires downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate (~0.5% top1) than v1, but comes with a small performance drawback (~5% imgs/sec). The model is initialized as described in Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures.'}", "category": "generic"}
{"question_id": 113, "text": "Determine if the given image is of a car or not using an appropriate API., 'Input': 'https://www.example.com/images/car_image.jpg' \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'AlexNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='alexnet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 43.45, 'top-5_error': 20.91}}, 'description': 'AlexNet is a deep convolutional neural network that achieved a top-5 error of 15.3% in the 2012 ImageNet Large Scale Visual Recognition Challenge. The main contribution of the original paper was the depth of the model, which was computationally expensive but made feasible through the use of GPUs during training. The pretrained AlexNet model in PyTorch can be used for image classification tasks.'}", "category": "generic"}
{"question_id": 114, "text": "I need to create an image of a realistic building. Is there an API that can help me with this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks (GANs)', 'api_name': 'PGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='PGAN', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'facebookresearch/pytorch_GAN_zoo:hub', 'model': 'PGAN', 'model_name': 'celebAHQ-512', 'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': 'import torch', 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'PGAN', model_name='celebAHQ-512', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'test': 'generated_images = model.test(noise)', 'plot_images': {'import_matplotlib': 'import matplotlib.pyplot as plt', 'import_torchvision': 'import torchvision', 'make_grid': 'grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1), scale_each=True, normalize=True)', 'imshow': 'plt.imshow(grid.permute(1, 2, 0).cpu().numpy())', 'show': 'plt.show()'}}, 'performance': {'dataset': 'celebA', 'accuracy': 'High-quality celebrity faces'}, 'description': \"Progressive Growing of GANs (PGAN) is a method for generating high-resolution images using generative adversarial networks. The model is trained progressively, starting with low-resolution images and gradually increasing the resolution until the desired output is achieved. This implementation is based on the paper by Tero Karras et al., 'Progressive Growing of GANs for Improved Quality, Stability, and Variation'.\"}", "category": "generic"}
{"question_id": 115, "text": "A medical researcher from Johns Hopkins University wants to analyze brain MRI scans for tumor detection. Recommend an API that can perform tumor segmentation in brain MRI images. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Biomedical Image Segmentation', 'api_name': 'U-Net for brain MRI', 'api_call': \"torch.hub.load(repo_or_dir='mateuszbuda/brain-segmentation-pytorch', model='unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'api_arguments': {'in_channels': 3, 'out_channels': 1, 'init_features': 32, 'pretrained': True}, 'python_environment_requirements': ['torch', 'torchvision', 'numpy', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'import numpy as np', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'm, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))', 'preprocess = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=m, std=s)])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model = model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.round(output[0]))'], 'performance': {'dataset': 'kaggle.com/mateuszbuda/lgg-mri-segmentation'}, 'description': 'U-Net with batch normalization for biomedical image segmentation with pretrained weights for abnormality segmentation in brain MRI. The model comprises four levels of blocks containing two convolutional layers with batch normalization and ReLU activation function, and one max pooling layer in the encoding part and up-convolutional layers instead in the decoding part. The number of convolutional filters in each block is 32, 64, 128, and 256. The bottleneck layer has 512 convolutional filters. From the encoding layers, skip connections are used to the corresponding layers in the decoding part. Input image is a 3-channel brain MRI slice from pre-contrast, FLAIR, and post-contrast sequences, respectively. Output is a one-channel probability map of abnormality regions with the same size as the input image.'}", "category": "generic"}
{"question_id": 116, "text": "Can you help me find an API for image classification which can recognize the objects in a given image? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeXt101-32x4d', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resneXt', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'validators', 'matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', 'device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")', \"print(f'Using {device} for inference')\", \"resneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resneXt')\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resneXt.eval().to(device)', 'uris = [', \" 'http://images.cocodataset.org/test-stuff2017/000000024309.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000028117.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000006149.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000004954.jpg',\", ']', 'batch = torch.cat(', ' [utils.prepare_input_from_uri(uri) for uri in uris]', ').to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resneXt(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'IMAGENET', 'accuracy': 'Not provided'}, 'description': 'ResNeXt101-32x4d is a model introduced in the Aggregated Residual Transformations for Deep Neural Networks paper. It is based on regular ResNet model, substituting 3x3 convolutions inside the bottleneck block for 3x3 grouped convolutions. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures. It can be deployed for inference on the NVIDIA Triton Inference Server using TorchScript, ONNX Runtime or TensorRT as an execution backend.'}", "category": "generic"}
{"question_id": 117, "text": "Derive a recommendation for a CNN used in image classification, trained on the ImageNet dataset. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SE-ResNeXt101', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_se_resnext101_32x4d', pretrained=True)\", 'api_arguments': 'N/A', 'python_environment_requirements': 'validators, matplotlib', 'example_code': \"import torch\\nfrom PIL import Image\\nimport torchvision.transforms as transforms\\nimport numpy as np\\nimport json\\nimport requests\\nimport matplotlib.pyplot as plt\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n%matplotlib inline\\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\nprint(f'Using {device} for inference')\\nresneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_se_resnext101_32x4d')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\nresneXt.eval().to(device)\\nuris = ['http://images.cocodataset.org/test-stuff2017/000000024309.jpg','http://images.cocodataset.org/test-stuff2017/000000028117.jpg','http://images.cocodataset.org/test-stuff2017/000000006149.jpg','http://images.cocodataset.org/test-stuff2017/000000004954.jpg']\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(resneXt(batch), dim=1)\\nresults = utils.pick_n_best(predictions=output, n=5)\\nfor uri, result in zip(uris, results):\\n img = Image.open(requests.get(uri, stream=True).raw)\\n img.thumbnail((256,256), Image.ANTIALIAS)\\n plt.imshow(img)\\n plt.show()\\n print(result)\", 'performance': {'dataset': 'IMAGENET', 'accuracy': 'N/A'}, 'description': 'The SE-ResNeXt101-32x4d is a ResNeXt101-32x4d model with added Squeeze-and-Excitation module. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures, which allows researchers to get results 3x faster than training without Tensor Cores while experiencing the benefits of mixed precision training.'}", "category": "generic"}
{"question_id": 118, "text": "A company wants to build an app that can classify images into 1000 different categories. Can you provide a machine learning API and some sample code that can help with the task? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x8d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x8d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x8d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x8d': {'Top-1 Acc.': '82.2', 'Top-5 Acc.': '96.4'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 119, "text": "What is an API that does an automatic image classification of flowers? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet121', pretrained=True)\", 'api_arguments': [{'name': 'densenet121', 'type': 'str', 'description': 'Densenet-121 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet121': {'Top-1 error': 25.35, 'Top-5 error': 7.83}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 120, "text": "Report an API that can turn text into speech for a vocal assistant app. \n Use this API documentation for reference: {'domain': 'Text-to-Speech', 'framework': 'PyTorch', 'functionality': 'Speech Synthesis', 'api_name': 'WaveGlow', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_waveglow', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_waveglow', 'model_math': 'fp32'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': {'load_waveglow_model': \"waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp32')\", 'prepare_waveglow_model': ['waveglow = waveglow.remove_weightnorm(waveglow)', \"waveglow = waveglow.to('cuda')\", 'waveglow.eval()'], 'load_tacotron2_model': \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp32')\", 'prepare_tacotron2_model': [\"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()'], 'synthesize_speech': ['text = \"hello world, I missed you so much\"', \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'save_audio': 'write(\"audio.wav\", rate, audio_numpy)', 'play_audio': 'Audio(audio_numpy, rate=rate)'}, 'performance': {'dataset': 'LJ Speech', 'accuracy': None}, 'description': 'The Tacotron 2 and WaveGlow model form a text-to-speech system that enables users to synthesize natural-sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 121, "text": "A company wants to develop a text classification model for their customer support operations. Suggest an API that uses transfer learning to achieve this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'RoBERTa', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq', model='roberta.large', pretrained=True)\", 'api_arguments': [\"'pytorch/fairseq'\", \"'roberta.large'\"], 'python_environment_requirements': ['regex', 'requests', 'hydra-core', 'omegaconf'], 'example_code': ['import torch', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\", 'roberta.eval()', \"tokens = roberta.encode('Hello world!')\", 'last_layer_features = roberta.extract_features(tokens)', 'all_layers = roberta.extract_features(tokens, return_all_hiddens=True)', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\", 'roberta.eval()', \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is not very optimized.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is based on BERT.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"roberta.register_classification_head('new_task', num_classes=3)\", \"logprobs = roberta.predict('new_task', tokens)\"], 'performance': {'dataset': 'MNLI', 'accuracy': 'N/A'}, 'description': \"RoBERTa is a robustly optimized version of BERT, a revolutionary self-supervised pretraining technique that learns to predict intentionally hidden (masked) sections of text. RoBERTa builds on BERT's language masking strategy and modifies key hyperparameters, including removing BERT's next-sentence pretraining objective, and training with much larger mini-batches and learning rates. RoBERTa was also trained on an order of magnitude more data than BERT, for a longer amount of time, allowing it to generalize even better to downstream tasks.\"}", "category": "generic"}
{"question_id": 122, "text": "Suggest an API able to classify images with a high level of accuracy, using the fewest possible parameters. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet201', pretrained=True)\", 'api_arguments': [{'name': 'densenet201', 'type': 'str', 'description': 'Densenet-201 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet201': {'Top-1 error': 22.8, 'Top-5 error': 6.43}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 123, "text": "I need a model for classifying images, and I want to use Densenet-169. Give me an API to use. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet169', pretrained=True)\", 'api_arguments': [{'name': 'densenet169', 'type': 'str', 'description': 'Densenet-169 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet169': {'Top-1 error': 24.0, 'Top-5 error': 7.0}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 124, "text": "Design an image classification model to recognize different objects in images. Recommend an API appropriate for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet161', pretrained=True)\", 'api_arguments': [{'name': 'densenet161', 'type': 'str', 'description': 'Densenet-161 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet161', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet161': {'Top-1 error': 22.35, 'Top-5 error': 6.2}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 125, "text": "An urban planner needs to segment different objects in cityscape images. Recommend an API that can do this task efficiently. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet50', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet50': {'Mean IOU': 60.5, 'Global Pixelwise Accuracy': 91.4}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 126, "text": "Find a suitable API to perform semantic segmentation of an aerial image into building, road, and vegetation. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet101', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet101': {'Mean IOU': 63.7, 'Global Pixelwise Accuracy': 91.9}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 127, "text": "Recommend an API that can classify images using a fast and efficient model. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet85', pretrained=True)\", 'api_arguments': [{'name': 'hardnet85', 'type': 'str', 'description': 'HarDNet-85 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet85', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet85': {'Top-1 error': 21.96, 'Top-5 error': 6.11}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 128, "text": "Can you suggest an efficient API for classifying a large collection of images that minimizes computational cost? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Efficient networks by generating more features from cheap operations', 'api_name': 'GhostNet', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/ghostnet', model='ghostnet_1x', pretrained=True)\", 'api_arguments': ['pretrained'], 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/ghostnet', 'ghostnet_1x', pretrained=True)\", 'model.eval()', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 acc': '73.98', 'Top-5 acc': '91.46'}}, 'description': 'The GhostNet architecture is based on an Ghost module structure which generates more features from cheap operations. Based on a set of intrinsic feature maps, a series of cheap operations are applied to generate many ghost feature maps that could fully reveal information underlying intrinsic features. Experiments conducted on benchmarks demonstrate the superiority of GhostNet in terms of speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 129, "text": "Identify an API that can classify flora and fauna species by analyzing images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet39ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet39ds', 'type': 'str', 'description': 'HarDNet-39DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet39ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet39ds': {'Top-1 error': 27.92, 'Top-5 error': 9.57}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 130, "text": "A robotics company wants to reduce the computational and memory cost of an image classification model for mobile robot applications. Suggest an API suited for this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68ds', 'type': 'str', 'description': 'HarDNet-68DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68ds': {'Top-1 error': 25.71, 'Top-5 error': 8.13}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 131, "text": "I need an API to help identify dog breeds in images. Recommend one with a light model that is fast in processing the images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68', 'type': 'str', 'description': 'HarDNet-68 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68': {'Top-1 error': 23.52, 'Top-5 error': 6.99}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory trafficCNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 132, "text": "Find an API suitable for cross-domain image classification with high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnext101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_ibn_a', 'type': 'str', 'description': 'ResNeXt-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnext101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext101_ibn_a': {'Top-1 acc': 79.12, 'Top-5 acc': 94.58}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 133, "text": "A fashion ecommerce app wants to automatically classify and tag images of clothing items. Help them find a suitable API for image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'GoogLeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='googlenet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.0.0', 'torchvision': '>=0.2.2'}, 'example_code': {'import': ['import torch', 'import urllib', 'from PIL import Image', 'from torchvision import transforms'], 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\", 'model_eval': 'model.eval()', 'image_preprocessing': ['input_image = Image.open(filename)', 'preprocess = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'model_execution': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'output_processing': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'top5_prob, top5_catid = torch.topk(probabilities, 5)']}, 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 error': '30.22', 'Top-5 error': '10.47'}}, 'description': \"GoogLeNet is based on a deep convolutional neural network architecture codenamed 'Inception', which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014).\"}", "category": "generic"}
{"question_id": 134, "text": "Recommend an API that can create models having domain or appearance invariance. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet101_ibn_a', 'type': 'str', 'description': 'ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet101_ibn_a': {'Top-1 acc': 78.61, 'Top-5 acc': 94.41}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 135, "text": "I need to re-identify a person in a different set of images, suggest an API I can use to make this process easier. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet50_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet50_ibn_a', 'type': 'str', 'description': 'ResNet-50-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet50_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet50_ibn_a': {'Top-1 acc': 77.46, 'Top-5 acc': 93.68}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 136, "text": "Find me an API for classifying different breeds of dogs from their photos. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'Inception_v3', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='inception_v3', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '1.9.0', 'torchvision': '0.10.0'}, 'example_code': {'import_libraries': 'import torch', 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\", 'model_evaluation': 'model.eval()'}, 'performance': {'dataset': 'imagenet', 'accuracy': {'top-1_error': 22.55, 'top-5_error': 6.44}}, 'description': 'Inception v3, also called GoogleNetv3, is a famous Convolutional Neural Network trained on the ImageNet dataset from 2015. It is based on the exploration of ways to scale up networks to utilize the added computation as efficiently as possible by using suitably factorized convolutions and aggressive regularization. The model achieves a top-1 error of 22.55% and a top-5 error of 6.44% on the ImageNet dataset.'}", "category": "generic"}
{"question_id": 137, "text": "My manager just asked me to implement a classification system that can categorize pictures into different animal species. Can you recommend an API that can help me with this task? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest50', pretrained=True)\", 'api_arguments': 'resnest50', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-50': 81.03}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 138, "text": "Detect the type of tree species in a park from an image taken by a smartphone. Provide an API that can help with this classification problem. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest101', pretrained=True)\", 'api_arguments': 'resnest101', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-101': 82.83}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 139, "text": "Many people loves to create different memes. Propose an API that can use keywords from meme text to detect if a meme is negative or not. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest200', pretrained=True)\", 'api_arguments': 'resnest200', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest200', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-200': 83.84}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 140, "text": "Can you find an API that can identify objects in images? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest269', pretrained=True)\", 'api_arguments': 'resnest269', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest269', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-269': 84.54}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 141, "text": "Tell me an API that can classify a given image into one of the predefined categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet18', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet18', 'top-1_error': 30.24, 'top-5_error': 10.92}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 142, "text": "I want to perform classification on my dataset with a model that is optimized for a CPU. Suggest me an API. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_cpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_cpu', 'type': 'str', 'description': 'ProxylessNAS optimized for CPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_cpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_cpu', 'accuracy': 75.3}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 143, "text": "I want to classify images on my mobile efficiently. Suggest an API to achieve this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_mobile', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_mobile', 'type': 'str', 'description': 'ProxylessNAS optimized for Mobile'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_mobile'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_mobile', 'accuracy': 74.6}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 144, "text": "A company needs to classify a large number of photos by their content. Suggest an API that is optimized for GPU and can perform classifications efficiently. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_gpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_gpu', 'type': 'str', 'description': 'ProxylessNAS optimized for GPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_gpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_gpu', 'accuracy': 75.1}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 145, "text": "I need to create an app that can analyze food image and can tell its catagory like pizza, burger, etc. Write an API that can help me in achieving this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MobileNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='mobilenet_v2', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 28.12, 'top-5_error': 9.71}}, 'description': 'The MobileNet v2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input. MobileNet v2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, non-linearities in the narrow layers were removed in order to maintain representational power.'}", "category": "generic"}
{"question_id": 146, "text": "Design me an API for classifying images using a pretrained model. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet34', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet34', 'top-1_error': 26.7, 'top-5_error': 8.58}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 147, "text": "Can you customize an API that can detect eco-friendly packaging from photos? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet101', 'top-1_error': 22.63, 'top-5_error': 6.44}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 148, "text": "Explain the idea behind deep residual networks, and provide an API that can identify different types of trees from images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet50', 'top-1_error': 23.85, 'top-5_error': 7.13}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 149, "text": "Identify an API that can classify types of dogs from a given image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet152', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet152', 'top-1_error': 21.69, 'top-5_error': 5.94}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 150, "text": "Can you suggest an API that will help a company build an image classification model for their photo sharing app to identify objects in the photos? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext101_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext101_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'resnext101_32x8d': {'top-1': 20.69, 'top-5': 5.47}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 151, "text": "I'm working on a computer vision project that requires a deep learning model for image classification. Can you provide an API that is efficient and accurate for this task? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext50_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext50_32x4d': {'top-1': 22.38, 'top-5': 6.3}}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 152, "text": "Find me an API to classify clothing items from a real-time camera feed. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_t', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_t', 'type': 'str', 'description': 'SNNMLP Tiny model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_t', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Tiny', 'top-1': 81.88}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 153, "text": "I want to classify everyday objects in images. Is there an AI model that can help me to do this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_s', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_s', 'type': 'str', 'description': 'SNNMLP Small model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_s', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Small', 'top-1': 83.3}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 154, "text": "Help me find an image classifier model that can be used in a mobile application to classify everyday objects from images. The model should be light and efficient. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_b', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_b', 'type': 'str', 'description': 'SNNMLP Base model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_b', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Base', 'top-1': 85.59}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 155, "text": "Can you suggest an API that can classify objects in images with a high level of accuracy but maintaining small model size and low computational cost? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_0', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_0'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_0': {'Top-1 error': 41.9, 'Top-5 error': 19.58}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 156, "text": "Analyze and classify objects in a photo using an efficient convolutional neural network. The model should balance between accuracy and computational resources. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ShuffleNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='shufflenet_v2_x1_0', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'torch', 'torchvision': 'torchvision', 'PIL': 'Image', 'urllib': 'urllib'}, 'example_code': {'import_libraries': ['import torch', 'from PIL import Image', 'from torchvision import transforms', 'import urllib'], 'load_model': [\"model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\", 'model.eval()'], 'load_image': [\"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'try: urllib.URLopener().retrieve(url, filename)', 'except: urllib.request.urlretrieve(url, filename)', 'input_image = Image.open(filename)'], 'preprocess_image': ['preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'run_inference': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'get_probabilities': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'top_categories': ['top5_prob, top5_catid = torch.topk(probabilities, 5)', 'for i in range(top5_prob.size(0)):', ' print(categories[top5_catid[i]], top5_prob[i].item())']}, 'performance': {'dataset': 'Imagenet', 'accuracy': {'top-1_error': 30.64, 'top-5_error': 11.68}}, 'description': 'ShuffleNet V2 is an efficient ConvNet optimized for speed and memory, pre-trained on Imagenet. It is designed based on practical guidelines for efficient network design, including speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 157, "text": "Is there any image classification API that I can use for tiny object, e.g., fruits in the market images, to save memory on my smartphone application? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_1', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_1'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_1': {'Top-1 error': 41.81, 'Top-5 error': 19.38}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 158, "text": "Help me recognize the objects present in an image. Recommend an API that can do this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg11_bn', 'type': 'str', 'description': 'VGG11 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11_bn': {'Top-1 error': 26.7, 'Top-5 error': 8.58}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 159, "text": "I need a way to efficiently detect and categorize various types of plants and animals in images taken from a nature reserve, could you provide an API that could help me with this task using a pretrained model? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11', pretrained=True)\", 'api_arguments': [{'name': 'vgg11', 'type': 'str', 'description': 'VGG11 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11': {'Top-1 error': 30.98, 'Top-5 error': 11.37}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 160, "text": "I'm looking for an API that recognizes different objects in images. Can you recommend one? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13', pretrained=True)\", 'api_arguments': [{'name': 'vgg13', 'type': 'str', 'description': 'VGG13 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13': {'Top-1 error': 30.07, 'Top-5 error': 10.75}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn,vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 161, "text": "Help me classify species of birds from images using an API call. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16', pretrained=True)\", 'api_arguments': [{'name': 'vgg16', 'type': 'str', 'description': 'VGG16 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16': {'Top-1 error': 28.41, 'Top-5 error': 9.62}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 162, "text": "Which API should I use to recognize images containing fruits and vegetables in a grocery store setting? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg13_bn', 'type': 'str', 'description': 'VGG13 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13_bn': {'Top-1 error': 28.45, 'Top-5 error': 9.63}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 163, "text": "Help me identify the objects in a photo using an API that is pretrained with many different classes. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg16_bn', 'type': 'str', 'description': 'VGG16 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16_bn': {'Top-1 error': 26.63, 'Top-5 error': 8.5}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 164, "text": "Our application identifies objects in images. What is the best image recognition API from torchvision for our case? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19', pretrained=True)\", 'api_arguments': [{'name': 'vgg19', 'type': 'str', 'description': 'VGG19 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19': {'Top-1 error': 27.62, 'Top-5 error': 9.12}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 165, "text": "Recommend an API that can recognize animals in an image and classify them into categories like pets, wildlife, and aquatic animals. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg19_bn', 'type': 'str', 'description': 'VGG19 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19_bn': {'Top-1 error': 25.76, 'Top-5 error': 8.15}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 166, "text": "What is an API that can classify photos of foods into their meal category? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet50_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet50_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet50_2': {'Top-1 error': 21.49, 'Top-5 error': 5.91}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 167, "text": "Find me a powerful API that can classify dozens of classes from an image taken. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet101_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet101_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet101_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet101_2': {'Top-1 error': 21.16, 'Top-5 error': 5.72}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 168, "text": "A sport streaming platform needs to detect clips of football plays for highlight creation. Recommend an API that can classify video clips into different action categories. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'SlowFast Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slowfast_r50', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'slowfast_r50', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 76.94, 'top5': 92.69}, 'flops': 65.71, 'params': 34.57}, 'description': \"Slow Fast model architectures are based on the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al. They are pretrained on the Kinetics 400 dataset using the 8x8 setting. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 169, "text": "I am developing a video platform and I need an API that can classify the type of sports played in the video. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'X3D Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='x3d_s', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'x3d_s', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_s', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 73.33, 'top5': 91.27}, 'flops': 2.96, 'params': 3.79}, 'description': \"X3D model architectures are based on the paper 'X3D: Expanding Architectures for Efficient Video Recognition' by Christoph Feichtenhofer. They are pretrained on the Kinetics 400 dataset. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 170, "text": "Recommend a machine learning API for classifying images with high inference speed and low latency on NVIDIA GPUs. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'GPUNet Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", 'api_arguments': {'repository': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_gpunet', 'pretrained': 'True', 'model_type': 'GPUNet-0', 'model_math': 'fp32'}, 'python_environment_requirements': ['torch', 'validators', 'matplotlib', 'timm==0.5.4'], 'example_code': ['import torch', \"model_type = 'GPUNet-0'\", \"precision = 'fp32'\", \"gpunet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'gpunet.to(device)', 'gpunet.eval()'], 'performance': {'dataset': 'IMAGENET', 'description': 'GPUNet demonstrates state-of-the-art inference performance up to 2x faster than EfficientNet-X and FBNet-V3.'}, 'description': 'GPUNet is a family of Convolutional Neural Networks designed by NVIDIA using novel Neural Architecture Search (NAS) methods. They are optimized for NVIDIA GPU and TensorRT performance. GPUNet models are pretrained on the IMAGENET dataset and are capable of classifying images into different categories. The models are provided by the NVIDIA Deep Learning Examples library.'}", "category": "generic"}
{"question_id": 171, "text": "Recommend an image classification API that can be used for classifying medical instruments in a biomedical dataset. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Semi-supervised and semi-weakly supervised ImageNet Models', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/semi-supervised-ImageNet1K-models', model='resnet18_swsl', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/semi-supervised-ImageNet1K-models', 'model': 'resnet18_swsl', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl', pretrained=True)\", 'model.eval()'], 'performance': {'description': 'Semi-supervised and semi-weakly supervised ImageNet models achieve state-of-the-art accuracy of 81.2% on ImageNet for the widely used/adopted ResNet-50 model architecture.'}, 'description': \"Semi-supervised and semi-weakly supervised ImageNet Models are introduced in the 'Billion scale semi-supervised learning for image classification' paper. These models are pretrained on a subset of unlabeled YFCC100M public image dataset and fine-tuned with the ImageNet1K training dataset. They are capable of classifying images into different categories and are provided by the Facebook Research library.\"}", "category": "generic"}
{"question_id": 172, "text": "There is a need at an NGO to develop a model that can analyze and classify the comments of the articles they publish. Tell me an API that can do this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Natural Language Processing', 'api_name': 'PyTorch-Transformers', 'api_call': \"torch.hub.load(repo_or_dir='huggingface/pytorch-transformers')\", 'api_arguments': ['pretrained_model_or_path', 'output_attention', 'output_hidden_states', 'config', 'from_tf'], 'python_environment_requirements': ['tqdm', 'boto3', 'requests', 'regex', 'sentencepiece', 'sacremoses'], 'example_code': 'import torch\\ntokenizer = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'tokenizer\\', \\'bert-base-cased\\')\\n\\ntext_1 = \"Jim Henson was a puppeteer\"\\ntext_2 = \"Who was Jim Henson ?\"\\n\\nindexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\\n\\nmodel = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'model\\', \\'bert-base-cased\\')\\n\\nwith torch.no_grad():\\n encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)', 'performance': {'dataset': [{'name': 'MRPC', 'accuracy': 'Not provided'}]}, 'description': 'PyTorch-Transformers is a library of state-of-the-art pre-trained models for Natural Language Processing (NLP) including BERT, GPT, GPT-2, Transformer-XL, XLNet, XLM, RoBERTa, and DistilBERT. The library provides functionality for tokenization, configuration, and various model architectures for different tasks such as causal language modeling, sequence classification, question answering, and masked language modeling.'}", "category": "generic"}
{"question_id": 173, "text": "An AI startup that builds ML models for drones is exploring APIs that can help improve the drones' real-time visual perception performance. Which API can serve their purpose the best? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Once-for-all (OFA) Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/once-for-all', model='ofa_supernet_mbv3_w10', pretrained=True)\", 'api_arguments': {'repository': 'mit-han-lab/once-for-all', 'model': 'ofa_supernet_mbv3_w10', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"super_net_name = 'ofa_supernet_mbv3_w10'\", \"super_net = torch.hub.load('mit-han-lab/once-for-all', super_net_name, pretrained=True).eval()\"], 'performance': {'description': 'OFA networks outperform state-of-the-art NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x faster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency) while reducing many orders of magnitude GPU hours and CO2 emission.'}, 'description': 'Once-for-all (OFA) networks are a family of neural networks designed by MIT Han Lab. They decouple training and search, achieving efficient inference across various edge devices and resource constraints. OFA networks are pretrained on the IMAGENET dataset and are capable of classifying images into different categories.'}", "category": "generic"}
{"question_id": 174, "text": "A freelance translator wants to automate their translation process from English to French. Can you suggest an API that can perform neural machine translation from English to French? \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Neural Machine Translation', 'api_name': 'Transformer (NMT)', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq')\", 'api_arguments': ['model_name', 'tokenizer', 'bpe', 'beam', 'sampling', 'sampling_topk'], 'python_environment_requirements': ['bitarray', 'fastBPE', 'hydra-core', 'omegaconf', 'regex', 'requests', 'sacremoses', 'subword_nmt'], 'example_code': \"import torch\\n\\nen2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\\n\\nen2fr.cuda()\\n\\nfr = en2fr.translate('Hello world!', beam=5)\\nassert fr == 'Bonjour \u00e0 tous !'\", 'performance': {'dataset': [{'name': \"WMT'14\", 'accuracy': 'Not provided'}, {'name': \"WMT'18\", 'accuracy': 'Not provided'}, {'name': \"WMT'19\", 'accuracy': 'Not provided'}]}, 'description': \"Transformer (NMT) is a powerful sequence-to-sequence modeling architecture that produces state-of-the-art neural machine translation systems. It is based on the paper 'Attention Is All You Need' and has been improved using techniques such as large-scale semi-supervised training, back-translation, and noisy-channel reranking. It supports English-French and English-German translation as well as round-trip translation for paraphrasing.\"}", "category": "generic"}
{"question_id": 175, "text": "CrateChef is a food subscription service and wants to develop a plate classifier for their users. Suggest an API to classify images of food plates. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'EfficientNet', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_efficientnet_b0', pretrained=True)\", 'api_arguments': ['model_name', 'pretrained'], 'python_environment_requirements': ['validators', 'matplotlib'], 'example_code': \"import torch\\n\\nefficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\n\\nefficientnet.eval().to(device)\\n\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\n\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(efficientnet(batch), dim=1)\\n \\nresults = utils.pick_n_best(predictions=output, n=5)\", 'performance': {'dataset': {'name': 'IMAGENET', 'accuracy': 'Not provided'}}, 'description': 'EfficientNet is a family of image classification models that achieve state-of-the-art accuracy while being smaller and faster. The models are trained with mixed precision using Tensor Cores on the NVIDIA Volta and Ampere GPU architectures. The EfficientNet models include EfficientNet-B0, EfficientNet-B4, EfficientNet-WideSE-B0, and EfficientNet-WideSE-B4. The WideSE models use wider Squeeze-and-Excitation layers than the original EfficientNet models, resulting in slightly better accuracy.'}", "category": "generic"}
{"question_id": 176, "text": "In a smart city project, I need to find an API that can detect multiple objects such as cars or stop signs from an image provided by surveillance cameras. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Single Shot MultiBox Detector', 'api_name': 'SSD', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_ssd', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['numpy', 'scipy', 'scikit-image', 'matplotlib'], 'example_code': \"import torch\\n\\nssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\\n\\nssd_model.to('cuda')\\nssd_model.eval()\\n\\ninputs = [utils.prepare_input(uri) for uri in uris]\\ntensor = utils.prepare_tensor(inputs)\\n\\nwith torch.no_grad():\\n detections_batch = ssd_model(tensor)\\n\\nresults_per_input = utils.decode_results(detections_batch)\\nbest_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\", 'performance': {'dataset': {'name': 'COCO', 'accuracy': 'Not provided'}}, 'description': \"The SSD (Single Shot MultiBox Detector) model is an object detection model based on the paper 'SSD: Single Shot MultiBox Detector'. It uses a deep neural network for detecting objects in images. This implementation replaces the obsolete VGG model backbone with the more modern ResNet-50 model. The SSD model is trained on the COCO dataset and can be used to detect objects in images with high accuracy and efficiency.\"}", "category": "generic"}
{"question_id": 177, "text": "Develop a text-to-speech solution to help visually impaired users read material. Propose an API that can do this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Text-to-Speech', 'api_name': 'Tacotron 2', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_tacotron2', model_math='fp16')\", 'api_arguments': {'model_math': 'fp16'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': ['import torch', \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\", \"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()', \"text = 'Hello world, I missed you so much.'\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'performance': {'dataset': 'LJ Speech', 'accuracy': 'Not specified'}, 'description': 'The Tacotron 2 model generates mel spectrograms from input text using an encoder-decoder architecture, and it is designed for generating natural-sounding speech from raw transcripts without any additional prosody information. This implementation uses Dropout instead of Zoneout to regularize the LSTM layers. The WaveGlow model (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 178, "text": "A developer needs an API for image classification that can classify images without image augmentation and has a higher top-1 accuracy, suggest an API for the same. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V1', model='mealv1_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv1_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V1 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '78.21', 'top5': '94.01'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 179, "text": "As a developer at an app company, I need an API to classify images from users' phone galleries. Please suggest a suitable API. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_cutmix', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_cutmix'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 + CutMix w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.98', 'top5': '95.35'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 180, "text": "I work in a tech company and we want to identify different objects from images. Give me an API that can perform image classification tasks. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.67', 'top5': '95.09'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 181, "text": "Recommend an API to classify large datasets of photographs into categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 1.0', 'resolution': '224', 'parameters': '2.54M', 'top1': '69.65', 'top5': '88.71'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 182, "text": "I am experimenting with models to train them on images of newspaper covers to classify them according to their content. Do you know any API that would be highly accurate and will work on this task? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_075', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_075'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 0.75', 'resolution': '224', 'parameters': '2.04M', 'top1': '67.60', 'top5': '87.23'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 183, "text": "Suggest an API that can classify images into a variety of categories, such as animals or objects, given an image as input. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_380x380', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_380x380'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '380', 'parameters': '25.6M', 'top1': '81.72', 'top5': '95.81'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 184, "text": "Nike is building an automated system to classify shoes in their inventory. Suggest an API to classify images for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_efficientnet_b0', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_efficientnet_b0'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ EfficientNet-B0', 'resolution': '224', 'parameters': '5.29M', 'top1': '78.29', 'top5': '93.95'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 185, "text": "A zookeeper wants to create an app that can classify the animal types in a picture. Suggest an image classification API that could be implemented. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenet_v3_large_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenet_v3_large_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Large 1.0', 'resolution': '224', 'parameters': '5.48M', 'top1': '76.92', 'top5': '93.32'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 186, "text": "I need an API to categorize sports activities from a given video clip. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorch', 'functionality': '3D ResNet', 'api_name': 'slow_r50', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slow_r50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'json', 'urllib', 'pytorchvideo', 'torchvision', 'torchaudio', 'torchtext', 'torcharrow', 'TorchData', 'TorchRec', 'TorchServe', 'PyTorch on XLA Devices'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top_1': 74.58, 'top_5': 91.63}, 'Flops (G)': 54.52, 'Params (M)': 32.45}, 'description': \"The 3D ResNet model is a Resnet-style video classification network pretrained on the Kinetics 400 dataset. It is based on the architecture from the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al.\"}", "category": "generic"}
{"question_id": 187, "text": "My self-driving car company requires an API for perception tasks like detecting traffic objects, drivable area segmentation, and lane detection. Can you provide one? \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Traffic Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'HybridNets', 'api_call': \"torch.hub.load(repo_or_dir='datvuthanh/hybridnets', model='hybridnets', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'Python>=3.7, PyTorch>=1.10', 'example_code': \"import torch\\nmodel = torch.hub.load('datvuthanh/hybridnets', 'hybridnets', pretrained=True)\\nimg = torch.randn(1,3,640,384)\\nfeatures, regression, classification, anchors, segmentation = model(img)\", 'performance': {'dataset': [{'name': 'BDD100K', 'accuracy': {'Traffic Object Detection': {'Recall (%)': 92.8, 'mAP@0.5 (%)': 77.3}, 'Drivable Area Segmentation': {'Drivable mIoU (%)': 90.5}, 'Lane Line Detection': {'Accuracy (%)': 85.4, 'Lane Line IoU (%)': 31.6}}}]}, 'description': 'HybridNets is an end2end perception network for multi-tasks. Our work focused on traffic object detection, drivable area segmentation and lane detection. HybridNets can run real-time on embedded systems, and obtains SOTA Object Detection, Lane Detection on BDD100K Dataset.'}", "category": "generic"}
{"question_id": 188, "text": "What would be an API to estimate the relative depth of objects in a provided image? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Hybrid', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Hybrid')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 189, "text": "Recommend me an API to generate the depth data of an image for building an augmented reality application. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Large', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Large')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 190, "text": "Suggest an API to estimate the depth from a single image for an obstacle detection system in a drone surveillance application. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='MiDaS_small', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 191, "text": "Recommend an API that can perform real-time object detection, drivable area segmentation, and lane detection for an autonomous vehicle. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'YOLOP', 'api_call': \"torch.hub.load(repo_or_dir='hustvl/yolop', model='yolop', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'pip install -qr https://github.com/hustvl/YOLOP/blob/main/requirements.txt', 'example_code': \"import torch\\nmodel = torch.hub.load('hustvl/yolop', 'yolop', pretrained=True)\\nimg = torch.randn(1,3,640,640)\\ndet_out, da_seg_out,ll_seg_out = model(img)\", 'performance': {'dataset': 'BDD100K', 'accuracy': {'Object Detection': {'Recall(%)': 89.2, 'mAP50(%)': 76.5, 'Speed(fps)': 41}, 'Drivable Area Segmentation': {'mIOU(%)': 91.5, 'Speed(fps)': 41}, 'Lane Detection': {'mIOU(%)': 70.5, 'IOU(%)': 26.2}}}, 'description': 'YOLOP is an efficient multi-task network that can jointly handle three crucial tasks in autonomous driving: object detection, drivable area segmentation and lane detection. And it is also the first to reach real-time on embedded devices while maintaining state-of-the-art level performance on the BDD100K dataset.'}", "category": "generic"}
{"question_id": 192, "text": "I work at Spotify and I'm looking for an API that can separate the vocals, drums, bass, and other instruments from a pop music track. \n Use this API documentation for reference: {'domain': 'Audio Separation', 'framework': 'PyTorch', 'functionality': 'Music Source Separation', 'api_name': 'Open-Unmix', 'api_call': \"torch.hub.load(repo_or_dir='sigsep/open-unmix-pytorch', model='umxhq', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['PyTorch >=1.6.0', 'torchaudio'], 'example_code': ['import torch', \"separator = torch.hub.load('sigsep/open-unmix-pytorch', 'umxhq')\", 'audio = torch.rand((1, 2, 100000))', 'original_sample_rate = separator.sample_rate', 'estimates = separator(audio)'], 'performance': {'dataset': 'MUSDB18', 'accuracy': 'N/A'}, 'description': 'Open-Unmix provides ready-to-use models that allow users to separate pop music into four stems: vocals, drums, bass and the remaining other instruments. The models were pre-trained on the freely available MUSDB18 dataset.'}", "category": "generic"}
{"question_id": 193, "text": "Identify a suitable API for bird species recognition in images for a wildlife photographer. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Fine-grained image classifier', 'api_name': 'ntsnet', 'api_call': \"torch.hub.load(repo_or_dir='nicolalandro/ntsnet-cub200', model='ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\", 'api_arguments': {'pretrained': 'True', 'topN': '6', 'device': 'cpu', 'num_classes': '200'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': \"from torchvision import transforms\\nimport torch\\nimport urllib\\nfrom PIL import Image\\n\\ntransform_test = transforms.Compose([\\n transforms.Resize((600, 600), Image.BILINEAR),\\n transforms.CenterCrop((448, 448)),\\n transforms.ToTensor(),\\n transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\\n])\\n\\nmodel = torch.hub.load('nicolalandro/ntsnet-cub200', 'ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\\nmodel.eval()\\n\\nurl = 'https://raw.githubusercontent.com/nicolalandro/ntsnet-cub200/master/images/nts-net.png'\\nimg = Image.open(urllib.request.urlopen(url))\\nscaled_img = transform_test(img)\\ntorch_images = scaled_img.unsqueeze(0)\\n\\nwith torch.no_grad():\\n top_n_coordinates, concat_out, raw_logits, concat_logits, part_logits, top_n_index, top_n_prob = model(torch_images)\\n\\n_, predict = torch.max(concat_logits, 1)\\npred_id = predict.item()\\nprint('bird class:', model.bird_classes[pred_id])\", 'performance': {'dataset': 'CUB200 2011', 'accuracy': 'Not provided'}, 'description': 'This is an nts-net pretrained with CUB200 2011 dataset, which is a fine-grained dataset of birds species.'}", "category": "generic"}
{"question_id": 194, "text": "Provide an API that can segment objects present in a given image. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet101', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet101', 'Mean IOU': 67.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 195, "text": "Help me in segmenting objects in an image. Suggest an API that I can use for this purpose. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet50', 'Mean IOU': 66.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 196, "text": "A podcast producer needs a solution to detect speech in audio recordings. Recommend an API to recognize the timestamps where voice is present in an audio file. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Voice Activity Detection', 'api_name': 'Silero Voice Activity Detector', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-vad', 'model': 'silero_vad', 'force_reload': 'True'}, 'python_environment_requirements': {'torchaudio': 'pip install -q torchaudio'}, 'example_code': {'import': ['import torch', 'torch.set_num_threads(1)', 'from IPython.display import Audio', 'from pprint import pprint'], 'download_example': \"torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\", 'load_model': \"model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'load_utils': '(get_speech_timestamps, _, read_audio, _) = utils', 'set_sampling_rate': 'sampling_rate = 16000', 'read_audio': \"wav = read_audio('en_example.wav', sampling_rate=sampling_rate)\", 'get_speech_timestamps': 'speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sampling_rate)', 'print_speech_timestamps': 'pprint(speech_timestamps)'}, 'performance': {'dataset': '', 'accuracy': ''}, 'description': 'Silero VAD is a pre-trained enterprise-grade Voice Activity Detector (VAD) that aims to provide a high-quality and modern alternative to the WebRTC Voice Activity Detector. The model is optimized for performance on 1 CPU thread and is quantized.'}", "category": "generic"}
{"question_id": 197, "text": "Suggest an API that can transcribe spoken words in a German audio file to written text. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Speech-To-Text', 'api_name': 'Silero Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_stt', 'language': ['en', 'de', 'es'], 'device': 'device'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf soundfile'], 'example_code': ['import torch', 'import zipfile', 'import torchaudio', 'from glob import glob', \"device = torch.device('cpu')\", \"model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', language='en', device=device)\", '(read_batch, split_into_batches, read_audio, prepare_model_input) = utils', \"torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav', dst ='speech_orig.wav', progress=True)\", \"test_files = glob('speech_orig.wav')\", 'batches = split_into_batches(test_files, batch_size=10)', 'input = prepare_model_input(read_batch(batches[0]), device=device)', 'output = model(input)', 'for example in output:', ' print(decoder(example.cpu()))'], 'performance': {'dataset': 'Open-STT', 'accuracy': 'See the wiki for quality and performance benchmarks'}, 'description': 'Silero Speech-To-Text models provide enterprise grade STT in a compact form-factor for several commonly spoken languages. The models are robust to a variety of dialects, codecs, domains, noises, and lower sampling rates. They consume a normalized audio in the form of samples and output frames with token probabilities. A decoder utility is provided for simplicity.'}", "category": "generic"}
{"question_id": 198, "text": "Help me find an API that can perform semantic segmentation on an image, classifying objects within it at the pixel level. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_mobilenet_v3_large', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_mobilenet_v3_large', 'Mean IOU': 60.3, 'Global Pixelwise Accuracy': 91.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 199, "text": "I want to count the number of people in a crowd using an image. Provide me with an API that can do this. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'YOLOv5', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='ultralytics/yolov5', model='yolov5s', pretrained=True)\", 'api_arguments': [\"'ultralytics/yolov5'\", \"'yolov5s'\", 'pretrained=True'], 'python_environment_requirements': 'Python>=3.8, PyTorch>=1.7', 'example_code': ['import torch', \"model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\", \"imgs = ['https://ultralytics.com/images/zidane.jpg']\", 'results = model(imgs)', 'results.print()', 'results.save()', 'results.xyxy[0]', 'results.pandas().xyxy[0]'], 'performance': {'dataset': 'COCO', 'accuracy': {'YOLOv5s6': {'mAPval0.5:0.95': 43.3, 'mAPtest0.5:0.95': 43.3, 'mAPval0.5': 61.9}, 'YOLOv5m6': {'mAPval0.5:0.95': 50.5, 'mAPtest0.5:0.95': 50.5, 'mAPval0.5': 68.7}, 'YOLOv5l6': {'mAPval0.5:0.95': 53.4, 'mAPtest0.5:0.95': 53.4, 'mAPval0.5': 71.1}, 'YOLOv5x6': {'mAPval0.5:0.95': 54.4, 'mAPtest0.5:0.95': 54.4, 'mAPval0.5': 72.0}, 'YOLOv5x6 TTA': {'mAPval0.5:0.95': 55.0, 'mAPtest0.5:0.95': 55.0, 'mAPval0.5': 72.0}}}, 'description': 'YOLOv5 is a family of compound-scaled object detection models trained on the COCO dataset, and includes simple functionality for Test Time Augmentation (TTA), model ensembling, hyperparameter evolution, and export to ONNX, CoreML and TFLite.'}", "category": "generic"}
{"question_id": 200, "text": "I want to create some new clothing designs using AI. Which API should I use to generate diverse clothing designs? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks', 'api_name': 'DCGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='DCGAN', pretrained=True, useGPU=use_gpu)\", 'api_arguments': {'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': ['import torch', 'import matplotlib.pyplot as plt', 'import torchvision'], 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'generate_images': 'with torch.no_grad(): generated_images = model.test(noise)', 'plot_images': ['plt.imshow(torchvision.utils.make_grid(generated_images).permute(1, 2, 0).cpu().numpy())', 'plt.show()']}, 'performance': {'dataset': 'FashionGen', 'accuracy': 'N/A'}, 'description': 'DCGAN is a model designed in 2015 by Radford et. al. in the paper Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. It is a GAN architecture both very simple and efficient for low resolution image generation (up to 64x64).'}", "category": "generic"}
{"question_id": 201, "text": "I want to implement an image classification model for an app, can you suggest an API that I can use and give me the code snippet to load the model? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x8d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x8d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x8d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x8d': {'Top-1 Acc.': '82.2', 'Top-5 Acc.': '96.4'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 202, "text": "Tell me an API that can accurately classify a wide range of images into different categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x48d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x48d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x48d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x48d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x48d': {'Top-1 Acc.': '85.4', 'Top-5 Acc.': '97.6'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 203, "text": "A researcher needs to categorize real world objects in images using machine learning. Provide a suitable API for image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x32d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x32d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x32d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x32d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x32d': {'Top-1 Acc.': '85.1', 'Top-5 Acc.': '97.5'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 204, "text": "I am developing a visual content recognition system for an e-commerce website to categorize images. Recommend an API that can help me with image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x16d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x16d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x16d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x16d': {'Top-1 Acc.': '84.2', 'Top-5 Acc.': '97.2'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 205, "text": "Discover an API suitable for segmenting abnormal regions in brain MRI scans. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Biomedical Image Segmentation', 'api_name': 'U-Net for brain MRI', 'api_call': \"torch.hub.load(repo_or_dir='mateuszbuda/brain-segmentation-pytorch', model='unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'api_arguments': {'in_channels': 3, 'out_channels': 1, 'init_features': 32, 'pretrained': True}, 'python_environment_requirements': ['torch', 'torchvision', 'numpy', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'import numpy as np', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'm, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))', 'preprocess = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=m, std=s)])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model = model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.round(output[0]))'], 'performance': {'dataset': 'kaggle.com/mateuszbuda/lgg-mri-segmentation'}, 'description': 'U-Net with batch normalization for biomedical image segmentation with pretrained weights for abnormality segmentation in brain MRI. The model comprises four levels of blocks containing two convolutional layers with batch normalization and ReLU activation function, and one max pooling layer in the encoding part and up-convolutional layers instead in the decoding part. The number of convolutional filters in each block is 32, 64, 128, and 256. The bottleneck layer has 512 convolutional filters. From the encoding layers, skip connections are used to the corresponding layers in the decoding part. Input image is a 3-channel brain MRI slice from pre-contrast, FLAIR, and post-contrast sequences, respectively. Output is a one-channel probability map of abnormality regions with the same size as the input image.'}", "category": "generic"}
{"question_id": 206, "text": "I need an API that I can use to create a project for a Tech event about classifying several bird species for local naturalists. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNet50', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['pip install validators matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", \"print(f'Using {device} for inference')\", \"resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resnet50.eval().to(device)', 'uris = [...]', 'batch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resnet50(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'ImageNet', 'accuracy': '~0.5% top1 improvement over ResNet50 v1'}, 'description': 'The ResNet50 v1.5 model is a modified version of the original ResNet50 v1 model. The difference between v1 and v1.5 is that, in the bottleneck blocks which requires downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate (~0.5% top1) than v1, but comes with a small performance drawback (~5% imgs/sec). The model is initialized as described in Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures.'}", "category": "generic"}
{"question_id": 207, "text": "Can you provide a GAN architecture that can generate high-resolution images progressively? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks (GANs)', 'api_name': 'PGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='PGAN', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'facebookresearch/pytorch_GAN_zoo:hub', 'model': 'PGAN', 'model_name': 'celebAHQ-512', 'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': 'import torch', 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'PGAN', model_name='celebAHQ-512', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'test': 'generated_images = model.test(noise)', 'plot_images': {'import_matplotlib': 'import matplotlib.pyplot as plt', 'import_torchvision': 'import torchvision', 'make_grid': 'grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1), scale_each=True, normalize=True)', 'imshow': 'plt.imshow(grid.permute(1, 2, 0).cpu().numpy())', 'show': 'plt.show()'}}, 'performance': {'dataset': 'celebA', 'accuracy': 'High-quality celebrity faces'}, 'description': \"Progressive Growing of GANs (PGAN) is a method for generating high-resolution images using generative adversarial networks. The model is trained progressively, starting with low-resolution images and gradually increasing the resolution until the desired output is achieved. This implementation is based on the paper by Tero Karras et al., 'Progressive Growing of GANs for Improved Quality, Stability, and Variation'.\"}", "category": "generic"}
{"question_id": 208, "text": "\"I'm building an app for tourists to identify famous landmarks based on their photos. Suggest an API.\" \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'AlexNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='alexnet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 43.45, 'top-5_error': 20.91}}, 'description': 'AlexNet is a deep convolutional neural network that achieved a top-5 error of 15.3% in the 2012 ImageNet Large Scale Visual Recognition Challenge. The main contribution of the original paper was the depth of the model, which was computationally expensive but made feasible through the use of GPUs during training. The pretrained AlexNet model in PyTorch can be used for image classification tasks.'}", "category": "generic"}
{"question_id": 209, "text": "Tell me an API that can efficiently classify thousands of real-world objects from an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SE-ResNeXt101', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_se_resnext101_32x4d', pretrained=True)\", 'api_arguments': 'N/A', 'python_environment_requirements': 'validators, matplotlib', 'example_code': \"import torch\\nfrom PIL import Image\\nimport torchvision.transforms as transforms\\nimport numpy as np\\nimport json\\nimport requests\\nimport matplotlib.pyplot as plt\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n%matplotlib inline\\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\nprint(f'Using {device} for inference')\\nresneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_se_resnext101_32x4d')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\nresneXt.eval().to(device)\\nuris = ['http://images.cocodataset.org/test-stuff2017/000000024309.jpg','http://images.cocodataset.org/test-stuff2017/000000028117.jpg','http://images.cocodataset.org/test-stuff2017/000000006149.jpg','http://images.cocodataset.org/test-stuff2017/000000004954.jpg']\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(resneXt(batch), dim=1)\\nresults = utils.pick_n_best(predictions=output, n=5)\\nfor uri, result in zip(uris, results):\\n img = Image.open(requests.get(uri, stream=True).raw)\\n img.thumbnail((256,256), Image.ANTIALIAS)\\n plt.imshow(img)\\n plt.show()\\n print(result)\", 'performance': {'dataset': 'IMAGENET', 'accuracy': 'N/A'}, 'description': 'The SE-ResNeXt101-32x4d is a ResNeXt101-32x4d model with added Squeeze-and-Excitation module. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures, which allows researchers to get results 3x faster than training without Tensor Cores while experiencing the benefits of mixed precision training.'}", "category": "generic"}
{"question_id": 210, "text": "I have the URL of an image and I want to classify it in real-time. Provide me an API that can classify the image and output 5 top predictions. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeXt101-32x4d', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resneXt', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'validators', 'matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', 'device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")', \"print(f'Using {device} for inference')\", \"resneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resneXt')\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resneXt.eval().to(device)', 'uris = [', \" 'http://images.cocodataset.org/test-stuff2017/000000024309.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000028117.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000006149.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000004954.jpg',\", ']', 'batch = torch.cat(', ' [utils.prepare_input_from_uri(uri) for uri in uris]', ').to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resneXt(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'IMAGENET', 'accuracy': 'Not provided'}, 'description': 'ResNeXt101-32x4d is a model introduced in the Aggregated Residual Transformations for Deep Neural Networks paper. It is based on regular ResNet model, substituting 3x3 convolutions inside the bottleneck block for 3x3 grouped convolutions. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures. It can be deployed for inference on the NVIDIA Triton Inference Server using TorchScript, ONNX Runtime or TensorRT as an execution backend.'}", "category": "generic"}
{"question_id": 211, "text": "Recommend an API capable of converting given text to natural-sounding speech. \n Use this API documentation for reference: {'domain': 'Text-to-Speech', 'framework': 'PyTorch', 'functionality': 'Speech Synthesis', 'api_name': 'WaveGlow', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_waveglow', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_waveglow', 'model_math': 'fp32'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': {'load_waveglow_model': \"waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp32')\", 'prepare_waveglow_model': ['waveglow = waveglow.remove_weightnorm(waveglow)', \"waveglow = waveglow.to('cuda')\", 'waveglow.eval()'], 'load_tacotron2_model': \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp32')\", 'prepare_tacotron2_model': [\"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()'], 'synthesize_speech': ['text = \"hello world, I missed you so much\"', \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'save_audio': 'write(\"audio.wav\", rate, audio_numpy)', 'play_audio': 'Audio(audio_numpy, rate=rate)'}, 'performance': {'dataset': 'LJ Speech', 'accuracy': None}, 'description': 'The Tacotron 2 and WaveGlow model form a text-to-speech system that enables users to synthesize natural-sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 212, "text": "I want to train a sentiment analysis model to classify Yelp reviews. Suggest an API for a good base model that I can fine-tune. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'RoBERTa', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq', model='roberta.large', pretrained=True)\", 'api_arguments': [\"'pytorch/fairseq'\", \"'roberta.large'\"], 'python_environment_requirements': ['regex', 'requests', 'hydra-core', 'omegaconf'], 'example_code': ['import torch', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\", 'roberta.eval()', \"tokens = roberta.encode('Hello world!')\", 'last_layer_features = roberta.extract_features(tokens)', 'all_layers = roberta.extract_features(tokens, return_all_hiddens=True)', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\", 'roberta.eval()', \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is not very optimized.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is based on BERT.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"roberta.register_classification_head('new_task', num_classes=3)\", \"logprobs = roberta.predict('new_task', tokens)\"], 'performance': {'dataset': 'MNLI', 'accuracy': 'N/A'}, 'description': \"RoBERTa is a robustly optimized version of BERT, a revolutionary self-supervised pretraining technique that learns to predict intentionally hidden (masked) sections of text. RoBERTa builds on BERT's language masking strategy and modifies key hyperparameters, including removing BERT's next-sentence pretraining objective, and training with much larger mini-batches and learning rates. RoBERTa was also trained on an order of magnitude more data than BERT, for a longer amount of time, allowing it to generalize even better to downstream tasks.\"}", "category": "generic"}
{"question_id": 213, "text": "I am developing an image classification application. What API can I use to perform classification using a Dense Convolutional Network? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet121', pretrained=True)\", 'api_arguments': [{'name': 'densenet121', 'type': 'str', 'description': 'Densenet-121 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet121': {'Top-1 error': 25.35, 'Top-5 error': 7.83}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 214, "text": "Please recommend an API suitable for image classification that can identify objects contained in arbitrary photographs. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet201', pretrained=True)\", 'api_arguments': [{'name': 'densenet201', 'type': 'str', 'description': 'Densenet-201 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet201': {'Top-1 error': 22.8, 'Top-5 error': 6.43}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 215, "text": "A zoo automated their entrance control system, and they need a program that recognizes animal types to monitor statistics. Please provide me with an API to classify animals based on their images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet169', pretrained=True)\", 'api_arguments': [{'name': 'densenet169', 'type': 'str', 'description': 'Densenet-169 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet169': {'Top-1 error': 24.0, 'Top-5 error': 7.0}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 216, "text": "Develop an image classifier that detects plant diseases from leaf images. Suggest an appropriate API for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet161', pretrained=True)\", 'api_arguments': [{'name': 'densenet161', 'type': 'str', 'description': 'Densenet-161 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet161', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet161': {'Top-1 error': 22.35, 'Top-5 error': 6.2}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 217, "text": "I am a software developer working on an autonomous car project. I need an API to segment an image so I can identify different objects in the area. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet101', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet101': {'Mean IOU': 63.7, 'Global Pixelwise Accuracy': 91.9}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 218, "text": "I have a project where I am asked to perform semantic segmentation on cityscape images. Recommend me an API that would be useful for this. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet50', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet50': {'Mean IOU': 60.5, 'Global Pixelwise Accuracy': 91.4}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 219, "text": "I am a software engineer developing a mobile application capable of classifying images. Please provide me with an API for image classification in PyTorch that has low memory requirements and high efficiency. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet39ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet39ds', 'type': 'str', 'description': 'HarDNet-39DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet39ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet39ds': {'Top-1 error': 27.92, 'Top-5 error': 9.57}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 220, "text": "Recommend an API that can classify objects in images efficiently, suitable to run on smartphones. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68ds', 'type': 'str', 'description': 'HarDNet-68DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68ds': {'Top-1 error': 25.71, 'Top-5 error': 8.13}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 221, "text": "I work at Google Photos and my team needs an API that can efficiently classify photos into different categories. What do you suggest? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet85', pretrained=True)\", 'api_arguments': [{'name': 'hardnet85', 'type': 'str', 'description': 'HarDNet-85 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet85', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet85': {'Top-1 error': 21.96, 'Top-5 error': 6.11}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 222, "text": "Identify an API that can classify objects in images quickly and requires low memory. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68', 'type': 'str', 'description': 'HarDNet-68 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68': {'Top-1 error': 23.52, 'Top-5 error': 6.99}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory trafficCNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 223, "text": "A teenager wants their child to play with his new toy cars, but they want the phone to recognize the cars using machine vision. Give me an API that is computationally cheap and could recognize toy cars. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Efficient networks by generating more features from cheap operations', 'api_name': 'GhostNet', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/ghostnet', model='ghostnet_1x', pretrained=True)\", 'api_arguments': ['pretrained'], 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/ghostnet', 'ghostnet_1x', pretrained=True)\", 'model.eval()', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 acc': '73.98', 'Top-5 acc': '91.46'}}, 'description': 'The GhostNet architecture is based on an Ghost module structure which generates more features from cheap operations. Based on a set of intrinsic feature maps, a series of cheap operations are applied to generate many ghost feature maps that could fully reveal information underlying intrinsic features. Experiments conducted on benchmarks demonstrate the superiority of GhostNet in terms of speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 224, "text": "Invent a smart camera system for a library that is capable of finding the book section from an image. Recommend an API capable of doing this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'GoogLeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='googlenet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.0.0', 'torchvision': '>=0.2.2'}, 'example_code': {'import': ['import torch', 'import urllib', 'from PIL import Image', 'from torchvision import transforms'], 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\", 'model_eval': 'model.eval()', 'image_preprocessing': ['input_image = Image.open(filename)', 'preprocess = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'model_execution': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'output_processing': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'top5_prob, top5_catid = torch.topk(probabilities, 5)']}, 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 error': '30.22', 'Top-5 error': '10.47'}}, 'description': \"GoogLeNet is based on a deep convolutional neural network architecture codenamed 'Inception', which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014).\"}", "category": "generic"}
{"question_id": 225, "text": "Our team needs an image classification model for cross-domain tasks. Recommend a pre-trained model we can use in a project. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet101_ibn_a', 'type': 'str', 'description': 'ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet101_ibn_a': {'Top-1 acc': 78.61, 'Top-5 acc': 94.41}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 226, "text": "A fashion E-commerce platform needs to predict clothing types from images. Suggest me a machine learning API that can be used to classify clothing items. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet50_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet50_ibn_a', 'type': 'str', 'description': 'ResNet-50-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet50_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet50_ibn_a': {'Top-1 acc': 77.46, 'Top-5 acc': 93.68}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 227, "text": "I need a model that can classify various objects in images while being capable of distinguishing between a wide range of domains and appearances. Can you suggest an API for this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='se_resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'se_resnet101_ibn_a', 'type': 'str', 'description': 'SE-ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'se_resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'se_resnet101_ibn_a': {'Top-1 acc': 78.75, 'Top-5 acc': 94.49}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 228, "text": "Suggest a suitable API for cross-domain classification tasks like person re-identification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnext101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_ibn_a', 'type': 'str', 'description': 'ResNeXt-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnext101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext101_ibn_a': {'Top-1 acc': 79.12, 'Top-5 acc': 94.58}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 229, "text": "A fashion company needs to categorize dresses from its newly released stock. Give me an API that can classify a dress type from its image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'Inception_v3', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='inception_v3', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '1.9.0', 'torchvision': '0.10.0'}, 'example_code': {'import_libraries': 'import torch', 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\", 'model_evaluation': 'model.eval()'}, 'performance': {'dataset': 'imagenet', 'accuracy': {'top-1_error': 22.55, 'top-5_error': 6.44}}, 'description': 'Inception v3, also called GoogleNetv3, is a famous Convolutional Neural Network trained on the ImageNet dataset from 2015. It is based on the exploration of ways to scale up networks to utilize the added computation as efficiently as possible by using suitably factorized convolutions and aggressive regularization. The model achieves a top-1 error of 22.55% and a top-5 error of 6.44% on the ImageNet dataset.'}", "category": "generic"}
{"question_id": 230, "text": "Can you give me an API capable of identifying animal species from a provided image? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest50', pretrained=True)\", 'api_arguments': 'resnest50', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-50': 81.03}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 231, "text": "I have images of various objects and I need to classify them into different categories. Can you suggest an API that can help me with this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest200', pretrained=True)\", 'api_arguments': 'resnest200', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest200', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-200': 83.84}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 232, "text": "Create an instance of an API that takes an image of a bird and predicts what type of bird it is. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest101', pretrained=True)\", 'api_arguments': 'resnest101', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-101': 82.83}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 233, "text": "I need to classify the content of an image using a high-performance, state-of-the-art image classification model. Please recommend an API for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest269', pretrained=True)\", 'api_arguments': 'resnest269', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest269', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-269': 84.54}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 234, "text": "Find me an efficient API for image classification that's optimized for better performance on CPUs. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_cpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_cpu', 'type': 'str', 'description': 'ProxylessNAS optimized for CPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_cpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_cpu', 'accuracy': 75.3}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 235, "text": "I need to classify objects using an efficient model optimized for GPU. Provide me an API for that purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_gpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_gpu', 'type': 'str', 'description': 'ProxylessNAS optimized for GPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_gpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_gpu', 'accuracy': 75.1}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 236, "text": "We need to develop an object detection app for mobile devices. Suggest an API for a neural network based on ProxylessNAS that is optimized for mobile devices. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_mobile', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_mobile', 'type': 'str', 'description': 'ProxylessNAS optimized for Mobile'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_mobile'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_mobile', 'accuracy': 74.6}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 237, "text": "I want to create an app that identifies dog breeds from user uploaded images. Suggest an API that could recognize different dog breeds from images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MobileNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='mobilenet_v2', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 28.12, 'top-5_error': 9.71}}, 'description': 'The MobileNet v2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input. MobileNet v2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, non-linearities in the narrow layers were removed in order to maintain representational power.'}", "category": "generic"}
{"question_id": 238, "text": "I have a dataset of images and want to classify them into different categories. Suggest an API that can do this task with high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet50', 'top-1_error': 23.85, 'top-5_error': 7.13}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 239, "text": "I am working on a project that requires me to identify objects in an image. Find me an API that can do the task with pretrained models. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet34', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet34', 'top-1_error': 26.7, 'top-5_error': 8.58}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 240, "text": "An AI company needs a pre-trained model to classify plant species from images. Suggest an API to use for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet18', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet18', 'top-1_error': 30.24, 'top-5_error': 10.92}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 241, "text": "Can you assist me in selecting an API that automatically sorts through images of different kinds of animals? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet152', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet152', 'top-1_error': 21.69, 'top-5_error': 5.94}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 242, "text": "A mobile application developer is exploring an API that can detect objects in a photo from a room. Suggest an API for detecting objects. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet101', 'top-1_error': 22.63, 'top-5_error': 6.44}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 243, "text": "Develop a program to categorize animals' species from a set of images with the help of an API. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext50_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext50_32x4d': {'top-1': 22.38, 'top-5': 6.3}}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 244, "text": "A museum wants to build an image classifier for paintings. Recommend me an appropriate API that can be fine-tuned for painting classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext101_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext101_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'resnext101_32x8d': {'top-1': 20.69, 'top-5': 5.47}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 245, "text": "A startup is in need of an efficient image classification API. Tell me about an API that can classify images effectively. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_s', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_s', 'type': 'str', 'description': 'SNNMLP Small model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_s', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Small', 'top-1': 83.3}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 246, "text": "Find me an API that can recognize dog breeds in a given image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_0', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_0'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_0': {'Top-1 error': 41.9, 'Top-5 error': 19.58}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 247, "text": "What are the operational concepts for replacing an old neural network mechanism facilitating an MLP model with better accuracy? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_t', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_t', 'type': 'str', 'description': 'SNNMLP Tiny model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_t', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Tiny', 'top-1': 81.88}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 248, "text": "We are looking to classify the make and model of a car from visible images. Can you provide an API to accomplish this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_b', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_b', 'type': 'str', 'description': 'SNNMLP Base model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_b', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Base', 'top-1': 85.59}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 249, "text": "Design an image classification system for a smart doorbell that aims to classify different types of animals like cats, dogs, and birds. Propose a machine learning API suitable for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_1', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_1'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_1': {'Top-1 error': 41.81, 'Top-5 error': 19.38}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 250, "text": "A startup is building a robot to classify street objects. Tell me an API that can detect objects in a street view photograph and provide efficient inference. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ShuffleNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='shufflenet_v2_x1_0', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'torch', 'torchvision': 'torchvision', 'PIL': 'Image', 'urllib': 'urllib'}, 'example_code': {'import_libraries': ['import torch', 'from PIL import Image', 'from torchvision import transforms', 'import urllib'], 'load_model': [\"model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\", 'model.eval()'], 'load_image': [\"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'try: urllib.URLopener().retrieve(url, filename)', 'except: urllib.request.urlretrieve(url, filename)', 'input_image = Image.open(filename)'], 'preprocess_image': ['preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'run_inference': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'get_probabilities': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'top_categories': ['top5_prob, top5_catid = torch.topk(probabilities, 5)', 'for i in range(top5_prob.size(0)):', ' print(categories[top5_catid[i]], top5_prob[i].item())']}, 'performance': {'dataset': 'Imagenet', 'accuracy': {'top-1_error': 30.64, 'top-5_error': 11.68}}, 'description': 'ShuffleNet V2 is an efficient ConvNet optimized for speed and memory, pre-trained on Imagenet. It is designed based on practical guidelines for efficient network design, including speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 251, "text": "Can you suggest an API I can use to classify various types of plants from their images? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13', pretrained=True)\", 'api_arguments': [{'name': 'vgg13', 'type': 'str', 'description': 'VGG13 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13': {'Top-1 error': 30.07, 'Top-5 error': 10.75}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn,vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 252, "text": "Help me to identify what objects are in an image. Can you suggest an API that is capable of doing this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11', pretrained=True)\", 'api_arguments': [{'name': 'vgg11', 'type': 'str', 'description': 'VGG11 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11': {'Top-1 error': 30.98, 'Top-5 error': 11.37}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 253, "text": "What is a pre-trained model I can use to recognize objects in a picture? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg13_bn', 'type': 'str', 'description': 'VGG13 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13_bn': {'Top-1 error': 28.45, 'Top-5 error': 9.63}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 254, "text": "I am building a software for an AI art gallery, and it needs to recognize artistic characteristics of different famous painting images. Identify a pre-trained model which can help me in this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg11_bn', 'type': 'str', 'description': 'VGG11 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11_bn': {'Top-1 error': 26.7, 'Top-5 error': 8.58}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 255, "text": "I have a bunch of pictures of plants, and I need an API that can identify the species for me. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16', pretrained=True)\", 'api_arguments': [{'name': 'vgg16', 'type': 'str', 'description': 'VGG16 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16': {'Top-1 error': 28.41, 'Top-5 error': 9.62}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 256, "text": "An app developer needs a machine learning API for recognizing images taken by users to suggest appropriate captions for those images, recommend an API for that. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19', pretrained=True)\", 'api_arguments': [{'name': 'vgg19', 'type': 'str', 'description': 'VGG19 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19': {'Top-1 error': 27.62, 'Top-5 error': 9.12}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 257, "text": "Recommend an API that will help me classify animals and birds in high quality images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet101_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet101_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet101_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet101_2': {'Top-1 error': 21.16, 'Top-5 error': 5.72}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 258, "text": "I need an image recognition API. Can you please suggest a model? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg19_bn', 'type': 'str', 'description': 'VGG19 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19_bn': {'Top-1 error': 25.76, 'Top-5 error': 8.15}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 259, "text": "I am a content moderator for a video streaming platform, and I need a pretrained API to identify category of actions performed in a clip. What do you recommend? \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'X3D Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='x3d_s', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'x3d_s', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_s', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 73.33, 'top5': 91.27}, 'flops': 2.96, 'params': 3.79}, 'description': \"X3D model architectures are based on the paper 'X3D: Expanding Architectures for Efficient Video Recognition' by Christoph Feichtenhofer. They are pretrained on the Kinetics 400 dataset. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 260, "text": "I built an AI personal trainer app that uses images from users' workouts to give live feedback. Recommend a model for classifying these workout images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet50_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet50_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet50_2': {'Top-1 error': 21.49, 'Top-5 error': 5.91}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 261, "text": "Tell me an API that can be used to classify different actions happening in a video clip. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'SlowFast Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slowfast_r50', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'slowfast_r50', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 76.94, 'top5': 92.69}, 'flops': 65.71, 'params': 34.57}, 'description': \"Slow Fast model architectures are based on the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al. They are pretrained on the Kinetics 400 dataset using the 8x8 setting. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 262, "text": "Recommend an image classification API capable of working efficiently on NVIDIA GPUs. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'GPUNet Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", 'api_arguments': {'repository': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_gpunet', 'pretrained': 'True', 'model_type': 'GPUNet-0', 'model_math': 'fp32'}, 'python_environment_requirements': ['torch', 'validators', 'matplotlib', 'timm==0.5.4'], 'example_code': ['import torch', \"model_type = 'GPUNet-0'\", \"precision = 'fp32'\", \"gpunet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'gpunet.to(device)', 'gpunet.eval()'], 'performance': {'dataset': 'IMAGENET', 'description': 'GPUNet demonstrates state-of-the-art inference performance up to 2x faster than EfficientNet-X and FBNet-V3.'}, 'description': 'GPUNet is a family of Convolutional Neural Networks designed by NVIDIA using novel Neural Architecture Search (NAS) methods. They are optimized for NVIDIA GPU and TensorRT performance. GPUNet models are pretrained on the IMAGENET dataset and are capable of classifying images into different categories. The models are provided by the NVIDIA Deep Learning Examples library.'}", "category": "generic"}
{"question_id": 263, "text": "We need to compare the performance of an NLP model across different frameworks, can you provide an API to load a pretrained transformer model for sequence classification? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Natural Language Processing', 'api_name': 'PyTorch-Transformers', 'api_call': \"torch.hub.load(repo_or_dir='huggingface/pytorch-transformers')\", 'api_arguments': ['pretrained_model_or_path', 'output_attention', 'output_hidden_states', 'config', 'from_tf'], 'python_environment_requirements': ['tqdm', 'boto3', 'requests', 'regex', 'sentencepiece', 'sacremoses'], 'example_code': 'import torch\\ntokenizer = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'tokenizer\\', \\'bert-base-cased\\')\\n\\ntext_1 = \"Jim Henson was a puppeteer\"\\ntext_2 = \"Who was Jim Henson ?\"\\n\\nindexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\\n\\nmodel = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'model\\', \\'bert-base-cased\\')\\n\\nwith torch.no_grad():\\n encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)', 'performance': {'dataset': [{'name': 'MRPC', 'accuracy': 'Not provided'}]}, 'description': 'PyTorch-Transformers is a library of state-of-the-art pre-trained models for Natural Language Processing (NLP) including BERT, GPT, GPT-2, Transformer-XL, XLNet, XLM, RoBERTa, and DistilBERT. The library provides functionality for tokenization, configuration, and various model architectures for different tasks such as causal language modeling, sequence classification, question answering, and masked language modeling.'}", "category": "generic"}
{"question_id": 264, "text": "I want to quickly and efficiently classify images, I need an API for Once-for-all Networks. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Once-for-all (OFA) Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/once-for-all', model='ofa_supernet_mbv3_w10', pretrained=True)\", 'api_arguments': {'repository': 'mit-han-lab/once-for-all', 'model': 'ofa_supernet_mbv3_w10', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"super_net_name = 'ofa_supernet_mbv3_w10'\", \"super_net = torch.hub.load('mit-han-lab/once-for-all', super_net_name, pretrained=True).eval()\"], 'performance': {'description': 'OFA networks outperform state-of-the-art NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x faster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency) while reducing many orders of magnitude GPU hours and CO2 emission.'}, 'description': 'Once-for-all (OFA) networks are a family of neural networks designed by MIT Han Lab. They decouple training and search, achieving efficient inference across various edge devices and resource constraints. OFA networks are pretrained on the IMAGENET dataset and are capable of classifying images into different categories.'}", "category": "generic"}
{"question_id": 265, "text": "A startup company is working on a new app where customers can upload photos and have them automatically categorized into objects. Suggest an API that can recognize objects in images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Semi-supervised and semi-weakly supervised ImageNet Models', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/semi-supervised-ImageNet1K-models', model='resnet18_swsl', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/semi-supervised-ImageNet1K-models', 'model': 'resnet18_swsl', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl', pretrained=True)\", 'model.eval()'], 'performance': {'description': 'Semi-supervised and semi-weakly supervised ImageNet models achieve state-of-the-art accuracy of 81.2% on ImageNet for the widely used/adopted ResNet-50 model architecture.'}, 'description': \"Semi-supervised and semi-weakly supervised ImageNet Models are introduced in the 'Billion scale semi-supervised learning for image classification' paper. These models are pretrained on a subset of unlabeled YFCC100M public image dataset and fine-tuned with the ImageNet1K training dataset. They are capable of classifying images into different categories and are provided by the Facebook Research library.\"}", "category": "generic"}
{"question_id": 266, "text": "I am building a mobile app that classifies pictures of cats and dogs. Recommend an API for image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'EfficientNet', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_efficientnet_b0', pretrained=True)\", 'api_arguments': ['model_name', 'pretrained'], 'python_environment_requirements': ['validators', 'matplotlib'], 'example_code': \"import torch\\n\\nefficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\n\\nefficientnet.eval().to(device)\\n\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\n\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(efficientnet(batch), dim=1)\\n \\nresults = utils.pick_n_best(predictions=output, n=5)\", 'performance': {'dataset': {'name': 'IMAGENET', 'accuracy': 'Not provided'}}, 'description': 'EfficientNet is a family of image classification models that achieve state-of-the-art accuracy while being smaller and faster. The models are trained with mixed precision using Tensor Cores on the NVIDIA Volta and Ampere GPU architectures. The EfficientNet models include EfficientNet-B0, EfficientNet-B4, EfficientNet-WideSE-B0, and EfficientNet-WideSE-B4. The WideSE models use wider Squeeze-and-Excitation layers than the original EfficientNet models, resulting in slightly better accuracy.'}", "category": "generic"}
{"question_id": 267, "text": "Which API can I use to build a powerful English to French translation system? \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Neural Machine Translation', 'api_name': 'Transformer (NMT)', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq')\", 'api_arguments': ['model_name', 'tokenizer', 'bpe', 'beam', 'sampling', 'sampling_topk'], 'python_environment_requirements': ['bitarray', 'fastBPE', 'hydra-core', 'omegaconf', 'regex', 'requests', 'sacremoses', 'subword_nmt'], 'example_code': \"import torch\\n\\nen2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\\n\\nen2fr.cuda()\\n\\nfr = en2fr.translate('Hello world!', beam=5)\\nassert fr == 'Bonjour \u00e0 tous !'\", 'performance': {'dataset': [{'name': \"WMT'14\", 'accuracy': 'Not provided'}, {'name': \"WMT'18\", 'accuracy': 'Not provided'}, {'name': \"WMT'19\", 'accuracy': 'Not provided'}]}, 'description': \"Transformer (NMT) is a powerful sequence-to-sequence modeling architecture that produces state-of-the-art neural machine translation systems. It is based on the paper 'Attention Is All You Need' and has been improved using techniques such as large-scale semi-supervised training, back-translation, and noisy-channel reranking. It supports English-French and English-German translation as well as round-trip translation for paraphrasing.\"}", "category": "generic"}
{"question_id": 268, "text": "Tell me a model to use if I want to identify different objects in images without having my own dataset. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Single Shot MultiBox Detector', 'api_name': 'SSD', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_ssd', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['numpy', 'scipy', 'scikit-image', 'matplotlib'], 'example_code': \"import torch\\n\\nssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\\n\\nssd_model.to('cuda')\\nssd_model.eval()\\n\\ninputs = [utils.prepare_input(uri) for uri in uris]\\ntensor = utils.prepare_tensor(inputs)\\n\\nwith torch.no_grad():\\n detections_batch = ssd_model(tensor)\\n\\nresults_per_input = utils.decode_results(detections_batch)\\nbest_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\", 'performance': {'dataset': {'name': 'COCO', 'accuracy': 'Not provided'}}, 'description': \"The SSD (Single Shot MultiBox Detector) model is an object detection model based on the paper 'SSD: Single Shot MultiBox Detector'. It uses a deep neural network for detecting objects in images. This implementation replaces the obsolete VGG model backbone with the more modern ResNet-50 model. The SSD model is trained on the COCO dataset and can be used to detect objects in images with high accuracy and efficiency.\"}", "category": "generic"}
{"question_id": 269, "text": "Let me know about an API that can convert English text into speech. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Text-to-Speech', 'api_name': 'Tacotron 2', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_tacotron2', model_math='fp16')\", 'api_arguments': {'model_math': 'fp16'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': ['import torch', \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\", \"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()', \"text = 'Hello world, I missed you so much.'\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'performance': {'dataset': 'LJ Speech', 'accuracy': 'Not specified'}, 'description': 'The Tacotron 2 model generates mel spectrograms from input text using an encoder-decoder architecture, and it is designed for generating natural-sounding speech from raw transcripts without any additional prosody information. This implementation uses Dropout instead of Zoneout to regularize the LSTM layers. The WaveGlow model (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 270, "text": "I want to build an Instagram-like app that can tag dogs based on their breed. What API can help me with this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.67', 'top5': '95.09'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 271, "text": "Propose a way to classify random images with an efficiency of around 80% without any tricks. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V1', model='mealv1_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv1_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V1 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '78.21', 'top5': '94.01'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 272, "text": "I need an API to help me identify different breeds of dogs in images. Can you find me one? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_380x380', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_380x380'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '380', 'parameters': '25.6M', 'top1': '81.72', 'top5': '95.81'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 273, "text": "I am developing an app that can recognize different dog breeds from a photo. Can you recommend an API for this task? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_075', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_075'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 0.75', 'resolution': '224', 'parameters': '2.04M', 'top1': '67.60', 'top5': '87.23'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 274, "text": "I have an image of an object, and I need an API to classify it. Ensure the API provides a high accuracy without tricks like architecture modification or mixup/cutmix training. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_cutmix', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_cutmix'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 + CutMix w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.98', 'top5': '95.35'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 275, "text": "I need an API that can identify the type of fruit in an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 1.0', 'resolution': '224', 'parameters': '2.54M', 'top1': '69.65', 'top5': '88.71'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 276, "text": "We want to build an application that recognize objects in an image. What API can classify these images for us? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenet_v3_large_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenet_v3_large_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Large 1.0', 'resolution': '224', 'parameters': '5.48M', 'top1': '76.92', 'top5': '93.32'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 277, "text": "Recommend an API to analyze workout videos and classify them into different exercise categories. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorch', 'functionality': '3D ResNet', 'api_name': 'slow_r50', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slow_r50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'json', 'urllib', 'pytorchvideo', 'torchvision', 'torchaudio', 'torchtext', 'torcharrow', 'TorchData', 'TorchRec', 'TorchServe', 'PyTorch on XLA Devices'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top_1': 74.58, 'top_5': 91.63}, 'Flops (G)': 54.52, 'Params (M)': 32.45}, 'description': \"The 3D ResNet model is a Resnet-style video classification network pretrained on the Kinetics 400 dataset. It is based on the architecture from the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al.\"}", "category": "generic"}
{"question_id": 278, "text": "Identify an API that can detect vehicles, drivable areas, and lanes from images of roads. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Traffic Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'HybridNets', 'api_call': \"torch.hub.load(repo_or_dir='datvuthanh/hybridnets', model='hybridnets', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'Python>=3.7, PyTorch>=1.10', 'example_code': \"import torch\\nmodel = torch.hub.load('datvuthanh/hybridnets', 'hybridnets', pretrained=True)\\nimg = torch.randn(1,3,640,384)\\nfeatures, regression, classification, anchors, segmentation = model(img)\", 'performance': {'dataset': [{'name': 'BDD100K', 'accuracy': {'Traffic Object Detection': {'Recall (%)': 92.8, 'mAP@0.5 (%)': 77.3}, 'Drivable Area Segmentation': {'Drivable mIoU (%)': 90.5}, 'Lane Line Detection': {'Accuracy (%)': 85.4, 'Lane Line IoU (%)': 31.6}}}]}, 'description': 'HybridNets is an end2end perception network for multi-tasks. Our work focused on traffic object detection, drivable area segmentation and lane detection. HybridNets can run real-time on embedded systems, and obtains SOTA Object Detection, Lane Detection on BDD100K Dataset.'}", "category": "generic"}
{"question_id": 279, "text": "Describe an API suitable for recognizing objects in an image with at least 80% accuracy on the ImageNet dataset. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_efficientnet_b0', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_efficientnet_b0'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ EfficientNet-B0', 'resolution': '224', 'parameters': '5.29M', 'top1': '78.29', 'top5': '93.95'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 280, "text": "Find me an API that can compute depth information from a single image of a scene. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Large', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Large')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 281, "text": "A friend is building a robot that can detect distance of object from camera. Provide an ML API that computes relative depth using a single image input. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Hybrid', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Hybrid')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 282, "text": "Tell me about an API that can estimate depth for single images, suitable for real-time scenarios like autonomous vehicles. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='MiDaS_small', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 283, "text": "I am developing an application for autonomous driving and I need an API that can efficiently detect objects, drivable area segmentation, and lane detection in real-time. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'YOLOP', 'api_call': \"torch.hub.load(repo_or_dir='hustvl/yolop', model='yolop', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'pip install -qr https://github.com/hustvl/YOLOP/blob/main/requirements.txt', 'example_code': \"import torch\\nmodel = torch.hub.load('hustvl/yolop', 'yolop', pretrained=True)\\nimg = torch.randn(1,3,640,640)\\ndet_out, da_seg_out,ll_seg_out = model(img)\", 'performance': {'dataset': 'BDD100K', 'accuracy': {'Object Detection': {'Recall(%)': 89.2, 'mAP50(%)': 76.5, 'Speed(fps)': 41}, 'Drivable Area Segmentation': {'mIOU(%)': 91.5, 'Speed(fps)': 41}, 'Lane Detection': {'mIOU(%)': 70.5, 'IOU(%)': 26.2}}}, 'description': 'YOLOP is an efficient multi-task network that can jointly handle three crucial tasks in autonomous driving: object detection, drivable area segmentation and lane detection. And it is also the first to reach real-time on embedded devices while maintaining state-of-the-art level performance on the BDD100K dataset.'}", "category": "generic"}
{"question_id": 284, "text": "I need to separate the vocals from a piece of music for a DJ performance. Find me an API that can do this. \n Use this API documentation for reference: {'domain': 'Audio Separation', 'framework': 'PyTorch', 'functionality': 'Music Source Separation', 'api_name': 'Open-Unmix', 'api_call': \"torch.hub.load(repo_or_dir='sigsep/open-unmix-pytorch', model='umxhq', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['PyTorch >=1.6.0', 'torchaudio'], 'example_code': ['import torch', \"separator = torch.hub.load('sigsep/open-unmix-pytorch', 'umxhq')\", 'audio = torch.rand((1, 2, 100000))', 'original_sample_rate = separator.sample_rate', 'estimates = separator(audio)'], 'performance': {'dataset': 'MUSDB18', 'accuracy': 'N/A'}, 'description': 'Open-Unmix provides ready-to-use models that allow users to separate pop music into four stems: vocals, drums, bass and the remaining other instruments. The models were pre-trained on the freely available MUSDB18 dataset.'}", "category": "generic"}
{"question_id": 285, "text": "I have a collection of bird photos and I need an API to identify the bird species in each photo. Can you help me? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Fine-grained image classifier', 'api_name': 'ntsnet', 'api_call': \"torch.hub.load(repo_or_dir='nicolalandro/ntsnet-cub200', model='ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\", 'api_arguments': {'pretrained': 'True', 'topN': '6', 'device': 'cpu', 'num_classes': '200'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': \"from torchvision import transforms\\nimport torch\\nimport urllib\\nfrom PIL import Image\\n\\ntransform_test = transforms.Compose([\\n transforms.Resize((600, 600), Image.BILINEAR),\\n transforms.CenterCrop((448, 448)),\\n transforms.ToTensor(),\\n transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\\n])\\n\\nmodel = torch.hub.load('nicolalandro/ntsnet-cub200', 'ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\\nmodel.eval()\\n\\nurl = 'https://raw.githubusercontent.com/nicolalandro/ntsnet-cub200/master/images/nts-net.png'\\nimg = Image.open(urllib.request.urlopen(url))\\nscaled_img = transform_test(img)\\ntorch_images = scaled_img.unsqueeze(0)\\n\\nwith torch.no_grad():\\n top_n_coordinates, concat_out, raw_logits, concat_logits, part_logits, top_n_index, top_n_prob = model(torch_images)\\n\\n_, predict = torch.max(concat_logits, 1)\\npred_id = predict.item()\\nprint('bird class:', model.bird_classes[pred_id])\", 'performance': {'dataset': 'CUB200 2011', 'accuracy': 'Not provided'}, 'description': 'This is an nts-net pretrained with CUB200 2011 dataset, which is a fine-grained dataset of birds species.'}", "category": "generic"}
{"question_id": 286, "text": "Can you suggest an API that can be used to convert a recorded speech to text? I have recordings from meetings I want to be transcribed. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Speech-To-Text', 'api_name': 'Silero Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_stt', 'language': ['en', 'de', 'es'], 'device': 'device'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf soundfile'], 'example_code': ['import torch', 'import zipfile', 'import torchaudio', 'from glob import glob', \"device = torch.device('cpu')\", \"model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', language='en', device=device)\", '(read_batch, split_into_batches, read_audio, prepare_model_input) = utils', \"torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav', dst ='speech_orig.wav', progress=True)\", \"test_files = glob('speech_orig.wav')\", 'batches = split_into_batches(test_files, batch_size=10)', 'input = prepare_model_input(read_batch(batches[0]), device=device)', 'output = model(input)', 'for example in output:', ' print(decoder(example.cpu()))'], 'performance': {'dataset': 'Open-STT', 'accuracy': 'See the wiki for quality and performance benchmarks'}, 'description': 'Silero Speech-To-Text models provide enterprise grade STT in a compact form-factor for several commonly spoken languages. The models are robust to a variety of dialects, codecs, domains, noises, and lower sampling rates. They consume a normalized audio in the form of samples and output frames with token probabilities. A decoder utility is provided for simplicity.'}", "category": "generic"}
{"question_id": 287, "text": "Recommend an API to analyze audio streams and detect when someone is speaking. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Voice Activity Detection', 'api_name': 'Silero Voice Activity Detector', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-vad', 'model': 'silero_vad', 'force_reload': 'True'}, 'python_environment_requirements': {'torchaudio': 'pip install -q torchaudio'}, 'example_code': {'import': ['import torch', 'torch.set_num_threads(1)', 'from IPython.display import Audio', 'from pprint import pprint'], 'download_example': \"torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\", 'load_model': \"model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'load_utils': '(get_speech_timestamps, _, read_audio, _) = utils', 'set_sampling_rate': 'sampling_rate = 16000', 'read_audio': \"wav = read_audio('en_example.wav', sampling_rate=sampling_rate)\", 'get_speech_timestamps': 'speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sampling_rate)', 'print_speech_timestamps': 'pprint(speech_timestamps)'}, 'performance': {'dataset': '', 'accuracy': ''}, 'description': 'Silero VAD is a pre-trained enterprise-grade Voice Activity Detector (VAD) that aims to provide a high-quality and modern alternative to the WebRTC Voice Activity Detector. The model is optimized for performance on 1 CPU thread and is quantized.'}", "category": "generic"}
{"question_id": 288, "text": "Identify an API for recognizing objects and dividing them into different regions in given images. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet101', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet101', 'Mean IOU': 67.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 289, "text": "Help me find an API for segmenting objects in images using a pre-trained model for semantic segmentation. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet50', 'Mean IOU': 66.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 290, "text": "An airport is trying to implement a system to detect unattended luggage. Provide an API that can detect objects from a real-time video feed. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'YOLOv5', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='ultralytics/yolov5', model='yolov5s', pretrained=True)\", 'api_arguments': [\"'ultralytics/yolov5'\", \"'yolov5s'\", 'pretrained=True'], 'python_environment_requirements': 'Python>=3.8, PyTorch>=1.7', 'example_code': ['import torch', \"model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\", \"imgs = ['https://ultralytics.com/images/zidane.jpg']\", 'results = model(imgs)', 'results.print()', 'results.save()', 'results.xyxy[0]', 'results.pandas().xyxy[0]'], 'performance': {'dataset': 'COCO', 'accuracy': {'YOLOv5s6': {'mAPval0.5:0.95': 43.3, 'mAPtest0.5:0.95': 43.3, 'mAPval0.5': 61.9}, 'YOLOv5m6': {'mAPval0.5:0.95': 50.5, 'mAPtest0.5:0.95': 50.5, 'mAPval0.5': 68.7}, 'YOLOv5l6': {'mAPval0.5:0.95': 53.4, 'mAPtest0.5:0.95': 53.4, 'mAPval0.5': 71.1}, 'YOLOv5x6': {'mAPval0.5:0.95': 54.4, 'mAPtest0.5:0.95': 54.4, 'mAPval0.5': 72.0}, 'YOLOv5x6 TTA': {'mAPval0.5:0.95': 55.0, 'mAPtest0.5:0.95': 55.0, 'mAPval0.5': 72.0}}}, 'description': 'YOLOv5 is a family of compound-scaled object detection models trained on the COCO dataset, and includes simple functionality for Test Time Augmentation (TTA), model ensembling, hyperparameter evolution, and export to ONNX, CoreML and TFLite.'}", "category": "generic"}
{"question_id": 291, "text": "An architect wishes to semantically segment different objects in an urban image. What API can they use for this purpose? \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_mobilenet_v3_large', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_mobilenet_v3_large', 'Mean IOU': 60.3, 'Global Pixelwise Accuracy': 91.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 292, "text": "ABC news needs a text-to-speech service for their articles. Offer them an API. \n Use this API documentation for reference: {'domain': 'Text-To-Speech', 'framework': 'PyTorch', 'functionality': 'Text-To-Speech', 'api_name': 'Silero Text-To-Speech Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_tts', 'language': 'language', 'speaker': 'speaker'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf'], 'example_code': \"import torch\\nlanguage = 'en'\\nspeaker = 'lj_16khz'\\ndevice = torch.device('cpu')\\nmodel, symbols, sample_rate, example_text, apply_tts = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', language=language, speaker=speaker)\\nmodel = model.to(device)\\naudio = apply_tts(texts=[example_text], model=model, sample_rate=sample_rate, symbols=symbols, device=device)\", 'performance': {'dataset': [{'language': 'Russian', 'speakers': 6}, {'language': 'English', 'speakers': 1}, {'language': 'German', 'speakers': 1}, {'language': 'Spanish', 'speakers': 1}, {'language': 'French', 'speakers': 1}], 'accuracy': 'High throughput on slow hardware. Decent performance on one CPU thread'}, 'description': 'Silero Text-To-Speech models provide enterprise grade TTS in a compact form-factor for several commonly spoken languages. They offer one-line usage, naturally sounding speech, no GPU or training required, minimalism and lack of dependencies, a library of voices in many languages, support for 16kHz and 8kHz out of the box.'}", "category": "generic"}
{"question_id": 293, "text": "Design a neural network that efficiently generates low-resolution images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks', 'api_name': 'DCGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='DCGAN', pretrained=True, useGPU=use_gpu)\", 'api_arguments': {'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': ['import torch', 'import matplotlib.pyplot as plt', 'import torchvision'], 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'generate_images': 'with torch.no_grad(): generated_images = model.test(noise)', 'plot_images': ['plt.imshow(torchvision.utils.make_grid(generated_images).permute(1, 2, 0).cpu().numpy())', 'plt.show()']}, 'performance': {'dataset': 'FashionGen', 'accuracy': 'N/A'}, 'description': 'DCGAN is a model designed in 2015 by Radford et. al. in the paper Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. It is a GAN architecture both very simple and efficient for low resolution image generation (up to 64x64).'}", "category": "generic"}
{"question_id": 294, "text": "Recommend an API suitable for classifying images of different dog breeds. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x8d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x8d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x8d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x8d': {'Top-1 Acc.': '82.2', 'Top-5 Acc.': '96.4'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 295, "text": "A researcher is looking for an image classification API that has been trained on a large dataset like ImageNet. Provide the API details for the ResNext WSL model. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x16d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x16d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x16d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x16d': {'Top-1 Acc.': '84.2', 'Top-5 Acc.': '97.2'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 296, "text": "Find me an pretrained model for image classification that has scored 85% or more Top-1 accuracy on ImageNet. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x32d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x32d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x32d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x32d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x32d': {'Top-1 Acc.': '85.1', 'Top-5 Acc.': '97.5'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 297, "text": "I want an API to classify birds into different species using images. Can you provide me a code snippet to load a pre-trained model that can perform this task? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x48d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x48d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x48d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x48d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x48d': {'Top-1 Acc.': '85.4', 'Top-5 Acc.': '97.6'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 298, "text": "I need an API that can classify images into 1000 different classes with high accuracy. How can create this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNet50', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['pip install validators matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", \"print(f'Using {device} for inference')\", \"resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resnet50.eval().to(device)', 'uris = [...]', 'batch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resnet50(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'ImageNet', 'accuracy': '~0.5% top1 improvement over ResNet50 v1'}, 'description': 'The ResNet50 v1.5 model is a modified version of the original ResNet50 v1 model. The difference between v1 and v1.5 is that, in the bottleneck blocks which requires downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate (~0.5% top1) than v1, but comes with a small performance drawback (~5% imgs/sec). The model is initialized as described in Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures.'}", "category": "generic"}
{"question_id": 299, "text": "A designer wants to create an AI model that would generate thousands unique celebrity faces for his digital galleries. Present an API that can accomplish this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks (GANs)', 'api_name': 'PGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='PGAN', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'facebookresearch/pytorch_GAN_zoo:hub', 'model': 'PGAN', 'model_name': 'celebAHQ-512', 'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': 'import torch', 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'PGAN', model_name='celebAHQ-512', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'test': 'generated_images = model.test(noise)', 'plot_images': {'import_matplotlib': 'import matplotlib.pyplot as plt', 'import_torchvision': 'import torchvision', 'make_grid': 'grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1), scale_each=True, normalize=True)', 'imshow': 'plt.imshow(grid.permute(1, 2, 0).cpu().numpy())', 'show': 'plt.show()'}}, 'performance': {'dataset': 'celebA', 'accuracy': 'High-quality celebrity faces'}, 'description': \"Progressive Growing of GANs (PGAN) is a method for generating high-resolution images using generative adversarial networks. The model is trained progressively, starting with low-resolution images and gradually increasing the resolution until the desired output is achieved. This implementation is based on the paper by Tero Karras et al., 'Progressive Growing of GANs for Improved Quality, Stability, and Variation'.\"}", "category": "generic"}
{"question_id": 300, "text": "Sandra, a radiologist, needs to find abnormal regions in a brain MRI image quickly. Recommend an API that can automatically identify abnormal regions in a 3-channel brain MRI slice. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Biomedical Image Segmentation', 'api_name': 'U-Net for brain MRI', 'api_call': \"torch.hub.load(repo_or_dir='mateuszbuda/brain-segmentation-pytorch', model='unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'api_arguments': {'in_channels': 3, 'out_channels': 1, 'init_features': 32, 'pretrained': True}, 'python_environment_requirements': ['torch', 'torchvision', 'numpy', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'import numpy as np', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'm, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))', 'preprocess = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=m, std=s)])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model = model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.round(output[0]))'], 'performance': {'dataset': 'kaggle.com/mateuszbuda/lgg-mri-segmentation'}, 'description': 'U-Net with batch normalization for biomedical image segmentation with pretrained weights for abnormality segmentation in brain MRI. The model comprises four levels of blocks containing two convolutional layers with batch normalization and ReLU activation function, and one max pooling layer in the encoding part and up-convolutional layers instead in the decoding part. The number of convolutional filters in each block is 32, 64, 128, and 256. The bottleneck layer has 512 convolutional filters. From the encoding layers, skip connections are used to the corresponding layers in the decoding part. Input image is a 3-channel brain MRI slice from pre-contrast, FLAIR, and post-contrast sequences, respectively. Output is a one-channel probability map of abnormality regions with the same size as the input image.'}", "category": "generic"}
{"question_id": 301, "text": "Suggest me an API for classifying dog breeds from an image of a dog and output the top three likely breeds. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeXt101-32x4d', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resneXt', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'validators', 'matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', 'device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")', \"print(f'Using {device} for inference')\", \"resneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resneXt')\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resneXt.eval().to(device)', 'uris = [', \" 'http://images.cocodataset.org/test-stuff2017/000000024309.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000028117.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000006149.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000004954.jpg',\", ']', 'batch = torch.cat(', ' [utils.prepare_input_from_uri(uri) for uri in uris]', ').to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resneXt(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'IMAGENET', 'accuracy': 'Not provided'}, 'description': 'ResNeXt101-32x4d is a model introduced in the Aggregated Residual Transformations for Deep Neural Networks paper. It is based on regular ResNet model, substituting 3x3 convolutions inside the bottleneck block for 3x3 grouped convolutions. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures. It can be deployed for inference on the NVIDIA Triton Inference Server using TorchScript, ONNX Runtime or TensorRT as an execution backend.'}", "category": "generic"}
{"question_id": 302, "text": "Recommend an API to classify objects in an image taken from the camera feed of a drone. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SE-ResNeXt101', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_se_resnext101_32x4d', pretrained=True)\", 'api_arguments': 'N/A', 'python_environment_requirements': 'validators, matplotlib', 'example_code': \"import torch\\nfrom PIL import Image\\nimport torchvision.transforms as transforms\\nimport numpy as np\\nimport json\\nimport requests\\nimport matplotlib.pyplot as plt\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n%matplotlib inline\\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\nprint(f'Using {device} for inference')\\nresneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_se_resnext101_32x4d')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\nresneXt.eval().to(device)\\nuris = ['http://images.cocodataset.org/test-stuff2017/000000024309.jpg','http://images.cocodataset.org/test-stuff2017/000000028117.jpg','http://images.cocodataset.org/test-stuff2017/000000006149.jpg','http://images.cocodataset.org/test-stuff2017/000000004954.jpg']\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(resneXt(batch), dim=1)\\nresults = utils.pick_n_best(predictions=output, n=5)\\nfor uri, result in zip(uris, results):\\n img = Image.open(requests.get(uri, stream=True).raw)\\n img.thumbnail((256,256), Image.ANTIALIAS)\\n plt.imshow(img)\\n plt.show()\\n print(result)\", 'performance': {'dataset': 'IMAGENET', 'accuracy': 'N/A'}, 'description': 'The SE-ResNeXt101-32x4d is a ResNeXt101-32x4d model with added Squeeze-and-Excitation module. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures, which allows researchers to get results 3x faster than training without Tensor Cores while experiencing the benefits of mixed precision training.'}", "category": "generic"}
{"question_id": 303, "text": "I need to classify objects in images with high accuracy. Can you recommend an API to use for this purpose? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet169', pretrained=True)\", 'api_arguments': [{'name': 'densenet169', 'type': 'str', 'description': 'Densenet-169 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet169': {'Top-1 error': 24.0, 'Top-5 error': 7.0}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 304, "text": "Snapchat is working on a new feature to enable their users to tag their pictures with predefined categories. Suggest a machine learning model that can classify an image into different categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'AlexNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='alexnet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 43.45, 'top-5_error': 20.91}}, 'description': 'AlexNet is a deep convolutional neural network that achieved a top-5 error of 15.3% in the 2012 ImageNet Large Scale Visual Recognition Challenge. The main contribution of the original paper was the depth of the model, which was computationally expensive but made feasible through the use of GPUs during training. The pretrained AlexNet model in PyTorch can be used for image classification tasks.'}", "category": "generic"}
{"question_id": 305, "text": "My application requires turning text into natural-sounding speech. What API can I use to achieve this? \n Use this API documentation for reference: {'domain': 'Text-to-Speech', 'framework': 'PyTorch', 'functionality': 'Speech Synthesis', 'api_name': 'WaveGlow', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_waveglow', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_waveglow', 'model_math': 'fp32'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': {'load_waveglow_model': \"waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp32')\", 'prepare_waveglow_model': ['waveglow = waveglow.remove_weightnorm(waveglow)', \"waveglow = waveglow.to('cuda')\", 'waveglow.eval()'], 'load_tacotron2_model': \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp32')\", 'prepare_tacotron2_model': [\"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()'], 'synthesize_speech': ['text = \"hello world, I missed you so much\"', \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'save_audio': 'write(\"audio.wav\", rate, audio_numpy)', 'play_audio': 'Audio(audio_numpy, rate=rate)'}, 'performance': {'dataset': 'LJ Speech', 'accuracy': None}, 'description': 'The Tacotron 2 and WaveGlow model form a text-to-speech system that enables users to synthesize natural-sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 306, "text": "I need to classify a picture of a cat among 1000 classes in ImageNet. Give me an API that can classify my cat picture. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet121', pretrained=True)\", 'api_arguments': [{'name': 'densenet121', 'type': 'str', 'description': 'Densenet-121 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet121': {'Top-1 error': 25.35, 'Top-5 error': 7.83}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 307, "text": "I am running a sentiment analysis on public opinion about a new social media app, could you recommend an API to classify the sentiments given a piece of text? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'RoBERTa', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq', model='roberta.large', pretrained=True)\", 'api_arguments': [\"'pytorch/fairseq'\", \"'roberta.large'\"], 'python_environment_requirements': ['regex', 'requests', 'hydra-core', 'omegaconf'], 'example_code': ['import torch', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\", 'roberta.eval()', \"tokens = roberta.encode('Hello world!')\", 'last_layer_features = roberta.extract_features(tokens)', 'all_layers = roberta.extract_features(tokens, return_all_hiddens=True)', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\", 'roberta.eval()', \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is not very optimized.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is based on BERT.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"roberta.register_classification_head('new_task', num_classes=3)\", \"logprobs = roberta.predict('new_task', tokens)\"], 'performance': {'dataset': 'MNLI', 'accuracy': 'N/A'}, 'description': \"RoBERTa is a robustly optimized version of BERT, a revolutionary self-supervised pretraining technique that learns to predict intentionally hidden (masked) sections of text. RoBERTa builds on BERT's language masking strategy and modifies key hyperparameters, including removing BERT's next-sentence pretraining objective, and training with much larger mini-batches and learning rates. RoBERTa was also trained on an order of magnitude more data than BERT, for a longer amount of time, allowing it to generalize even better to downstream tasks.\"}", "category": "generic"}
{"question_id": 308, "text": "A company needs to create an application that can classify objects on the factory floor. Can you recommend an API that can do object classification? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet201', pretrained=True)\", 'api_arguments': [{'name': 'densenet201', 'type': 'str', 'description': 'Densenet-201 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet201': {'Top-1 error': 22.8, 'Top-5 error': 6.43}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 309, "text": "Give me an API that can output the category of a car accident given a car accident dashcam footage. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet39ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet39ds', 'type': 'str', 'description': 'HarDNet-39DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet39ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet39ds': {'Top-1 error': 27.92, 'Top-5 error': 9.57}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 310, "text": "Explain an API for street scene semantic segmentation using an RGB image and find the names of objects from the segmentation model. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet50', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet50': {'Mean IOU': 60.5, 'Global Pixelwise Accuracy': 91.4}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 311, "text": "We would like to do semantic segmentation on a given image. Provide an API that can perform this functionality using the Fully Convolutional Network with ResNet101 backbone. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet101', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet101': {'Mean IOU': 63.7, 'Global Pixelwise Accuracy': 91.9}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 312, "text": "A photographer needs a tool for tagging various types of images. Recommend an API that would be suitable for classifying images into different categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68ds', 'type': 'str', 'description': 'HarDNet-68DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68ds': {'Top-1 error': 25.71, 'Top-5 error': 8.13}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 313, "text": "I work at a Tesla factory, and I need to find an AI that can classify whether the assembly of the Model 3 is of good quality or not. What should I use? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet161', pretrained=True)\", 'api_arguments': [{'name': 'densenet161', 'type': 'str', 'description': 'Densenet-161 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet161', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet161': {'Top-1 error': 22.35, 'Top-5 error': 6.2}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 314, "text": "I am developing a mobile app that identifies objects within images. Suggest an API that is efficient in terms of memory and computation for image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet85', pretrained=True)\", 'api_arguments': [{'name': 'hardnet85', 'type': 'str', 'description': 'HarDNet-85 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet85', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet85': {'Top-1 error': 21.96, 'Top-5 error': 6.11}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 315, "text": "I am building a recommendation system for clothing and need an image classification API for detecting types of clothing. Can you suggest one? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68', 'type': 'str', 'description': 'HarDNet-68 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68': {'Top-1 error': 23.52, 'Top-5 error': 6.99}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory trafficCNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 316, "text": "I want to build an application for image categorization using minimum resources such as memory and computational speed. Suggest me an API that serves my purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Efficient networks by generating more features from cheap operations', 'api_name': 'GhostNet', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/ghostnet', model='ghostnet_1x', pretrained=True)\", 'api_arguments': ['pretrained'], 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/ghostnet', 'ghostnet_1x', pretrained=True)\", 'model.eval()', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 acc': '73.98', 'Top-5 acc': '91.46'}}, 'description': 'The GhostNet architecture is based on an Ghost module structure which generates more features from cheap operations. Based on a set of intrinsic feature maps, a series of cheap operations are applied to generate many ghost feature maps that could fully reveal information underlying intrinsic features. Experiments conducted on benchmarks demonstrate the superiority of GhostNet in terms of speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 317, "text": "A content curator wants to automatically classify images to better organize their media library. Recommend an API that can help classify images into different categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'GoogLeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='googlenet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.0.0', 'torchvision': '>=0.2.2'}, 'example_code': {'import': ['import torch', 'import urllib', 'from PIL import Image', 'from torchvision import transforms'], 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\", 'model_eval': 'model.eval()', 'image_preprocessing': ['input_image = Image.open(filename)', 'preprocess = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'model_execution': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'output_processing': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'top5_prob, top5_catid = torch.topk(probabilities, 5)']}, 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 error': '30.22', 'Top-5 error': '10.47'}}, 'description': \"GoogLeNet is based on a deep convolutional neural network architecture codenamed 'Inception', which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014).\"}", "category": "generic"}
{"question_id": 318, "text": "I am working on a project that requires classifying thousands of images into different categories. Suggest an API that can identify objects within the images for my task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnext101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_ibn_a', 'type': 'str', 'description': 'ResNeXt-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnext101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext101_ibn_a': {'Top-1 acc': 79.12, 'Top-5 acc': 94.58}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 319, "text": "I am conducting research on cross-domain image classification. Can you suggest an API that offers a pretrained model that considers domain/appearance invariance? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet101_ibn_a', 'type': 'str', 'description': 'ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet101_ibn_a': {'Top-1 acc': 78.61, 'Top-5 acc': 94.41}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 320, "text": "I work for a camera security company, and I need a deep learning model to interpret and recognize person/vehicle in live streaming CCTV. Which API should I use? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='se_resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'se_resnet101_ibn_a', 'type': 'str', 'description': 'SE-ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'se_resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'se_resnet101_ibn_a': {'Top-1 acc': 78.75, 'Top-5 acc': 94.49}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 321, "text": "I need to classify photos of different human faces taken from different places. Can you provide me an API that can help with that? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet50_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet50_ibn_a', 'type': 'str', 'description': 'ResNet-50-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet50_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet50_ibn_a': {'Top-1 acc': 77.46, 'Top-5 acc': 93.68}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 322, "text": "The AI team at Snapchat is looking for a model to classify objects using images. Recommend a suitable API for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'Inception_v3', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='inception_v3', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '1.9.0', 'torchvision': '0.10.0'}, 'example_code': {'import_libraries': 'import torch', 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\", 'model_evaluation': 'model.eval()'}, 'performance': {'dataset': 'imagenet', 'accuracy': {'top-1_error': 22.55, 'top-5_error': 6.44}}, 'description': 'Inception v3, also called GoogleNetv3, is a famous Convolutional Neural Network trained on the ImageNet dataset from 2015. It is based on the exploration of ways to scale up networks to utilize the added computation as efficiently as possible by using suitably factorized convolutions and aggressive regularization. The model achieves a top-1 error of 22.55% and a top-5 error of 6.44% on the ImageNet dataset.'}", "category": "generic"}
{"question_id": 323, "text": "Prepare an API to classify objects in an image using a model with split-attention networks. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest101', pretrained=True)\", 'api_arguments': 'resnest101', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-101': 82.83}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 324, "text": "I need an image classifier based on a new ResNet variant to classify images according to the trained categories. Which API should I use? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest50', pretrained=True)\", 'api_arguments': 'resnest50', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-50': 81.03}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 325, "text": "An e-commerce website is trying to determine appropriate categories for images of products. They need an API that can return a category/class of an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest200', pretrained=True)\", 'api_arguments': 'resnest200', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest200', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-200': 83.84}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 326, "text": "A real-estate company is classifying homes using images taken by a drone. Suggest an API for classifying images of homes. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest269', pretrained=True)\", 'api_arguments': 'resnest269', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest269', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-269': 84.54}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 327, "text": "Identify a deep learning model that can efficiently be used for image classification on a mobile device. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_cpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_cpu', 'type': 'str', 'description': 'ProxylessNAS optimized for CPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_cpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_cpu', 'accuracy': 75.3}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 328, "text": "A wildlife photographer wants to classify animal species in his photos. Please recommend a machine learning API for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MobileNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='mobilenet_v2', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 28.12, 'top-5_error': 9.71}}, 'description': 'The MobileNet v2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input. MobileNet v2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, non-linearities in the narrow layers were removed in order to maintain representational power.'}", "category": "generic"}
{"question_id": 329, "text": "I need to classify the objects in the image using an API that is optimized for the GPU. Can you suggest one? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_gpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_gpu', 'type': 'str', 'description': 'ProxylessNAS optimized for GPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_gpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_gpu', 'accuracy': 75.1}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 330, "text": "I want to create an app that can classify images taken by phone cameras. Recommend me an API that is optimized for mobile devices. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_mobile', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_mobile', 'type': 'str', 'description': 'ProxylessNAS optimized for Mobile'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_mobile'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_mobile', 'accuracy': 74.6}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 331, "text": "A security firm is looking for an image classifier for categorization of security camera footage. Suggest an appropriate API for them. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet34', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet34', 'top-1_error': 26.7, 'top-5_error': 8.58}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 332, "text": "I want to classify images of dogs into different breeds using a pre-trained deep learning model. Which API can I use? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet18', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet18', 'top-1_error': 30.24, 'top-5_error': 10.92}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 333, "text": "Tell me how to create a code for identifying whether an image contains a dog or a cat. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet50', 'top-1_error': 23.85, 'top-5_error': 7.13}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 334, "text": "I need to categorize images into 1000 classes. Can you recommend an API for image classification? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet101', 'top-1_error': 22.63, 'top-5_error': 6.44}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 335, "text": "I am developing an app to label dog breeds found in images. Can you suggest an API that can be used to classify dog breeds? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet152', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet152', 'top-1_error': 21.69, 'top-5_error': 5.94}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 336, "text": "A mobile application developer wants to build a plant species identifier. Recommend an API that can easily classify plant species from images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext50_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext50_32x4d': {'top-1': 22.38, 'top-5': 6.3}}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 337, "text": "Discuss an API that can classify images using lateral inhibition-inspired mechanisms and efficient backbones. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_t', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_t', 'type': 'str', 'description': 'SNNMLP Tiny model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_t', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Tiny', 'top-1': 81.88}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 338, "text": "Pinai is looking for a model that can classify images using increased accuracy without additional computational cost. Provide an API to classify images that incorporates LIF neurons for better accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_s', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_s', 'type': 'str', 'description': 'SNNMLP Small model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_s', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Small', 'top-1': 83.3}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 339, "text": "I want an API that can effectively distinguish between breeds of dogs using deep learning. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_b', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_b', 'type': 'str', 'description': 'SNNMLP Base model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_b', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Base', 'top-1': 85.59}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 340, "text": "A YouTube vlogger is building a content suggestion tool for their viewers. Recommend me an API that can classify objects in their video clips to figure out what types of videos will be popular. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext101_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext101_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'resnext101_32x8d': {'top-1': 20.69, 'top-5': 5.47}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 341, "text": "Can you suggest an API that can classify images with the least number of parameters possible without losing much accuracy? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_0', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_0'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_0': {'Top-1 error': 41.9, 'Top-5 error': 19.58}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 342, "text": "I am building an image recognition software for my school project, Can you give me an API that will help me in recognizing the images I upload? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ShuffleNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='shufflenet_v2_x1_0', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'torch', 'torchvision': 'torchvision', 'PIL': 'Image', 'urllib': 'urllib'}, 'example_code': {'import_libraries': ['import torch', 'from PIL import Image', 'from torchvision import transforms', 'import urllib'], 'load_model': [\"model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\", 'model.eval()'], 'load_image': [\"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'try: urllib.URLopener().retrieve(url, filename)', 'except: urllib.request.urlretrieve(url, filename)', 'input_image = Image.open(filename)'], 'preprocess_image': ['preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'run_inference': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'get_probabilities': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'top_categories': ['top5_prob, top5_catid = torch.topk(probabilities, 5)', 'for i in range(top5_prob.size(0)):', ' print(categories[top5_catid[i]], top5_prob[i].item())']}, 'performance': {'dataset': 'Imagenet', 'accuracy': {'top-1_error': 30.64, 'top-5_error': 11.68}}, 'description': 'ShuffleNet V2 is an efficient ConvNet optimized for speed and memory, pre-trained on Imagenet. It is designed based on practical guidelines for efficient network design, including speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 343, "text": "I am working on an app that can identify plants from images. Can you provide a good API for this task? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_1', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_1'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_1': {'Top-1 error': 41.81, 'Top-5 error': 19.38}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 344, "text": "I want to recognize objects in images. Recommend an API for image recognition. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11', pretrained=True)\", 'api_arguments': [{'name': 'vgg11', 'type': 'str', 'description': 'VGG11 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11': {'Top-1 error': 30.98, 'Top-5 error': 11.37}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 345, "text": "Recommend me an API that can be used for classification of images using the VGG architecture. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg13_bn', 'type': 'str', 'description': 'VGG13 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13_bn': {'Top-1 error': 28.45, 'Top-5 error': 9.63}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 346, "text": "What is a suitable API that utilizes deep learning to detect and recognize hundreds of object categories in images? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg11_bn', 'type': 'str', 'description': 'VGG11 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11_bn': {'Top-1 error': 26.7, 'Top-5 error': 8.58}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 347, "text": "I have a bunch of images and I need a pre-trained deep learning model for image classification. Suggest an API for me to use. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13', pretrained=True)\", 'api_arguments': [{'name': 'vgg13', 'type': 'str', 'description': 'VGG13 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13': {'Top-1 error': 30.07, 'Top-5 error': 10.75}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn,vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 348, "text": "I have an image of an object and I want to classify the object in the image. Can you suggest an API that can help me with this task? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16', pretrained=True)\", 'api_arguments': [{'name': 'vgg16', 'type': 'str', 'description': 'VGG16 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16': {'Top-1 error': 28.41, 'Top-5 error': 9.62}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 349, "text": "I want an API to recognize different animals in a series of photos. Can you give me an example? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg16_bn', 'type': 'str', 'description': 'VGG16 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16_bn': {'Top-1 error': 26.63, 'Top-5 error': 8.5}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 350, "text": "I want to create an API that recognizes objects in an image. Recommend a pre-trained model that will be suitable. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg19_bn', 'type': 'str', 'description': 'VGG19 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19_bn': {'Top-1 error': 25.76, 'Top-5 error': 8.15}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 351, "text": "You are building a Chatbot for a car company that helps identify the model just by looking a picture. Provide an API that can help you recognize car models from a given image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19', pretrained=True)\", 'api_arguments': [{'name': 'vgg19', 'type': 'str', 'description': 'VGG19 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19': {'Top-1 error': 27.62, 'Top-5 error': 9.12}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 352, "text": "I need to create an image classifier implementing Wide Residual Networks. Will you provide me an API call to accomplish this task using pre-trained weights? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet50_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet50_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet50_2': {'Top-1 error': 21.49, 'Top-5 error': 5.91}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 353, "text": "A start-up company plans to develop media dashboard to monitor and categorize the latest YouTube trends. Which API should they use for video classification? \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'SlowFast Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slowfast_r50', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'slowfast_r50', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 76.94, 'top5': 92.69}, 'flops': 65.71, 'params': 34.57}, 'description': \"Slow Fast model architectures are based on the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al. They are pretrained on the Kinetics 400 dataset using the 8x8 setting. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 354, "text": "Determine an API that can identify plant species from images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet101_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet101_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet101_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet101_2': {'Top-1 error': 21.16, 'Top-5 error': 5.72}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 355, "text": "Find me an API to use for video analysis in a project where we need to analyze football games. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'X3D Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='x3d_s', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'x3d_s', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_s', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 73.33, 'top5': 91.27}, 'flops': 2.96, 'params': 3.79}, 'description': \"X3D model architectures are based on the paper 'X3D: Expanding Architectures for Efficient Video Recognition' by Christoph Feichtenhofer. They are pretrained on the Kinetics 400 dataset. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 356, "text": "Share with me a model to classify furniture pictures posted on an online store. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Once-for-all (OFA) Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/once-for-all', model='ofa_supernet_mbv3_w10', pretrained=True)\", 'api_arguments': {'repository': 'mit-han-lab/once-for-all', 'model': 'ofa_supernet_mbv3_w10', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"super_net_name = 'ofa_supernet_mbv3_w10'\", \"super_net = torch.hub.load('mit-han-lab/once-for-all', super_net_name, pretrained=True).eval()\"], 'performance': {'description': 'OFA networks outperform state-of-the-art NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x faster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency) while reducing many orders of magnitude GPU hours and CO2 emission.'}, 'description': 'Once-for-all (OFA) networks are a family of neural networks designed by MIT Han Lab. They decouple training and search, achieving efficient inference across various edge devices and resource constraints. OFA networks are pretrained on the IMAGENET dataset and are capable of classifying images into different categories.'}", "category": "generic"}
{"question_id": 357, "text": "Imagine a new photo album app that sorts photos by its theme. Find me an API that can classify images according to their theme. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'GPUNet Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", 'api_arguments': {'repository': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_gpunet', 'pretrained': 'True', 'model_type': 'GPUNet-0', 'model_math': 'fp32'}, 'python_environment_requirements': ['torch', 'validators', 'matplotlib', 'timm==0.5.4'], 'example_code': ['import torch', \"model_type = 'GPUNet-0'\", \"precision = 'fp32'\", \"gpunet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'gpunet.to(device)', 'gpunet.eval()'], 'performance': {'dataset': 'IMAGENET', 'description': 'GPUNet demonstrates state-of-the-art inference performance up to 2x faster than EfficientNet-X and FBNet-V3.'}, 'description': 'GPUNet is a family of Convolutional Neural Networks designed by NVIDIA using novel Neural Architecture Search (NAS) methods. They are optimized for NVIDIA GPU and TensorRT performance. GPUNet models are pretrained on the IMAGENET dataset and are capable of classifying images into different categories. The models are provided by the NVIDIA Deep Learning Examples library.'}", "category": "generic"}
{"question_id": 358, "text": "Identify an API that can analyze customer reviews and classify them as positive or negative. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Natural Language Processing', 'api_name': 'PyTorch-Transformers', 'api_call': \"torch.hub.load(repo_or_dir='huggingface/pytorch-transformers')\", 'api_arguments': ['pretrained_model_or_path', 'output_attention', 'output_hidden_states', 'config', 'from_tf'], 'python_environment_requirements': ['tqdm', 'boto3', 'requests', 'regex', 'sentencepiece', 'sacremoses'], 'example_code': 'import torch\\ntokenizer = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'tokenizer\\', \\'bert-base-cased\\')\\n\\ntext_1 = \"Jim Henson was a puppeteer\"\\ntext_2 = \"Who was Jim Henson ?\"\\n\\nindexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\\n\\nmodel = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'model\\', \\'bert-base-cased\\')\\n\\nwith torch.no_grad():\\n encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)', 'performance': {'dataset': [{'name': 'MRPC', 'accuracy': 'Not provided'}]}, 'description': 'PyTorch-Transformers is a library of state-of-the-art pre-trained models for Natural Language Processing (NLP) including BERT, GPT, GPT-2, Transformer-XL, XLNet, XLM, RoBERTa, and DistilBERT. The library provides functionality for tokenization, configuration, and various model architectures for different tasks such as causal language modeling, sequence classification, question answering, and masked language modeling.'}", "category": "generic"}
{"question_id": 359, "text": "Design an API and example code that can classify optical, cable, and copper wires by images with accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Semi-supervised and semi-weakly supervised ImageNet Models', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/semi-supervised-ImageNet1K-models', model='resnet18_swsl', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/semi-supervised-ImageNet1K-models', 'model': 'resnet18_swsl', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl', pretrained=True)\", 'model.eval()'], 'performance': {'description': 'Semi-supervised and semi-weakly supervised ImageNet models achieve state-of-the-art accuracy of 81.2% on ImageNet for the widely used/adopted ResNet-50 model architecture.'}, 'description': \"Semi-supervised and semi-weakly supervised ImageNet Models are introduced in the 'Billion scale semi-supervised learning for image classification' paper. These models are pretrained on a subset of unlabeled YFCC100M public image dataset and fine-tuned with the ImageNet1K training dataset. They are capable of classifying images into different categories and are provided by the Facebook Research library.\"}", "category": "generic"}
{"question_id": 360, "text": "Find me an API for neural machine translation that can translate English text to French. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Neural Machine Translation', 'api_name': 'Transformer (NMT)', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq')\", 'api_arguments': ['model_name', 'tokenizer', 'bpe', 'beam', 'sampling', 'sampling_topk'], 'python_environment_requirements': ['bitarray', 'fastBPE', 'hydra-core', 'omegaconf', 'regex', 'requests', 'sacremoses', 'subword_nmt'], 'example_code': \"import torch\\n\\nen2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\\n\\nen2fr.cuda()\\n\\nfr = en2fr.translate('Hello world!', beam=5)\\nassert fr == 'Bonjour \u00e0 tous !'\", 'performance': {'dataset': [{'name': \"WMT'14\", 'accuracy': 'Not provided'}, {'name': \"WMT'18\", 'accuracy': 'Not provided'}, {'name': \"WMT'19\", 'accuracy': 'Not provided'}]}, 'description': \"Transformer (NMT) is a powerful sequence-to-sequence modeling architecture that produces state-of-the-art neural machine translation systems. It is based on the paper 'Attention Is All You Need' and has been improved using techniques such as large-scale semi-supervised training, back-translation, and noisy-channel reranking. It supports English-French and English-German translation as well as round-trip translation for paraphrasing.\"}", "category": "generic"}
{"question_id": 361, "text": "Design an API to identify objects in an image quickly and efficiently. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Single Shot MultiBox Detector', 'api_name': 'SSD', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_ssd', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['numpy', 'scipy', 'scikit-image', 'matplotlib'], 'example_code': \"import torch\\n\\nssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\\n\\nssd_model.to('cuda')\\nssd_model.eval()\\n\\ninputs = [utils.prepare_input(uri) for uri in uris]\\ntensor = utils.prepare_tensor(inputs)\\n\\nwith torch.no_grad():\\n detections_batch = ssd_model(tensor)\\n\\nresults_per_input = utils.decode_results(detections_batch)\\nbest_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\", 'performance': {'dataset': {'name': 'COCO', 'accuracy': 'Not provided'}}, 'description': \"The SSD (Single Shot MultiBox Detector) model is an object detection model based on the paper 'SSD: Single Shot MultiBox Detector'. It uses a deep neural network for detecting objects in images. This implementation replaces the obsolete VGG model backbone with the more modern ResNet-50 model. The SSD model is trained on the COCO dataset and can be used to detect objects in images with high accuracy and efficiency.\"}", "category": "generic"}
{"question_id": 362, "text": "What API should I use to detect vehicles from the surveillance camera images? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'EfficientNet', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_efficientnet_b0', pretrained=True)\", 'api_arguments': ['model_name', 'pretrained'], 'python_environment_requirements': ['validators', 'matplotlib'], 'example_code': \"import torch\\n\\nefficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\n\\nefficientnet.eval().to(device)\\n\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\n\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(efficientnet(batch), dim=1)\\n \\nresults = utils.pick_n_best(predictions=output, n=5)\", 'performance': {'dataset': {'name': 'IMAGENET', 'accuracy': 'Not provided'}}, 'description': 'EfficientNet is a family of image classification models that achieve state-of-the-art accuracy while being smaller and faster. The models are trained with mixed precision using Tensor Cores on the NVIDIA Volta and Ampere GPU architectures. The EfficientNet models include EfficientNet-B0, EfficientNet-B4, EfficientNet-WideSE-B0, and EfficientNet-WideSE-B4. The WideSE models use wider Squeeze-and-Excitation layers than the original EfficientNet models, resulting in slightly better accuracy.'}", "category": "generic"}
{"question_id": 363, "text": "Come up with an API for our IVR system that generates natural-sounding spoken responses from provided text. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Text-to-Speech', 'api_name': 'Tacotron 2', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_tacotron2', model_math='fp16')\", 'api_arguments': {'model_math': 'fp16'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': ['import torch', \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\", \"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()', \"text = 'Hello world, I missed you so much.'\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'performance': {'dataset': 'LJ Speech', 'accuracy': 'Not specified'}, 'description': 'The Tacotron 2 model generates mel spectrograms from input text using an encoder-decoder architecture, and it is designed for generating natural-sounding speech from raw transcripts without any additional prosody information. This implementation uses Dropout instead of Zoneout to regularize the LSTM layers. The WaveGlow model (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 364, "text": "I want to extract features from a given image using a pre-trained deep learning model. Can you provide me an API for this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V1', model='mealv1_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv1_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V1 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '78.21', 'top5': '94.01'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 365, "text": "An artist wants to claim their work in Reddit. Give an API that can identify their art from an uploaded picture. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.67', 'top5': '95.09'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 366, "text": "I want an API for classifying images into 1000 classes. What do you suggest? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_075', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_075'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 0.75', 'resolution': '224', 'parameters': '2.04M', 'top1': '67.60', 'top5': '87.23'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 367, "text": "An app developer wants to classify images of pets to make a pet-themed camera app. Suggest an API that can classify images of different pets. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_380x380', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_380x380'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '380', 'parameters': '25.6M', 'top1': '81.72', 'top5': '95.81'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 368, "text": "Please provide an API that can classify images of healthy foods to identify if it's vegan or not based on its ingredients. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenet_v3_large_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenet_v3_large_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Large 1.0', 'resolution': '224', 'parameters': '5.48M', 'top1': '76.92', 'top5': '93.32'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 369, "text": "What is an API that can classify images into categories without using common tricks such as mixup, cutmix, or autoaugmentation? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 1.0', 'resolution': '224', 'parameters': '2.54M', 'top1': '69.65', 'top5': '88.71'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 370, "text": "Apple TV is categorizing their movie trailers. Recommend an API that can categorize video clips by analyzing their content. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorch', 'functionality': '3D ResNet', 'api_name': 'slow_r50', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slow_r50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'json', 'urllib', 'pytorchvideo', 'torchvision', 'torchaudio', 'torchtext', 'torcharrow', 'TorchData', 'TorchRec', 'TorchServe', 'PyTorch on XLA Devices'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top_1': 74.58, 'top_5': 91.63}, 'Flops (G)': 54.52, 'Params (M)': 32.45}, 'description': \"The 3D ResNet model is a Resnet-style video classification network pretrained on the Kinetics 400 dataset. It is based on the architecture from the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al.\"}", "category": "generic"}
{"question_id": 371, "text": "Help me to classify images in a Python project. What API should I use to achieve more than 80% top-1 accuracy on ImageNet without using any tricks? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_efficientnet_b0', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_efficientnet_b0'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ EfficientNet-B0', 'resolution': '224', 'parameters': '5.29M', 'top1': '78.29', 'top5': '93.95'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 372, "text": "Suggest me an AI model to classify animals given an image of a dog. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_cutmix', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_cutmix'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 + CutMix w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.98', 'top5': '95.35'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 373, "text": "I want an object detection API capable of handling object detection, drivable area segmentation, and lane detection for autonomous driving tasks. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'YOLOP', 'api_call': \"torch.hub.load(repo_or_dir='hustvl/yolop', model='yolop', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'pip install -qr https://github.com/hustvl/YOLOP/blob/main/requirements.txt', 'example_code': \"import torch\\nmodel = torch.hub.load('hustvl/yolop', 'yolop', pretrained=True)\\nimg = torch.randn(1,3,640,640)\\ndet_out, da_seg_out,ll_seg_out = model(img)\", 'performance': {'dataset': 'BDD100K', 'accuracy': {'Object Detection': {'Recall(%)': 89.2, 'mAP50(%)': 76.5, 'Speed(fps)': 41}, 'Drivable Area Segmentation': {'mIOU(%)': 91.5, 'Speed(fps)': 41}, 'Lane Detection': {'mIOU(%)': 70.5, 'IOU(%)': 26.2}}}, 'description': 'YOLOP is an efficient multi-task network that can jointly handle three crucial tasks in autonomous driving: object detection, drivable area segmentation and lane detection. And it is also the first to reach real-time on embedded devices while maintaining state-of-the-art level performance on the BDD100K dataset.'}", "category": "generic"}
{"question_id": 374, "text": "Design an autonomous vehicle algorithm that can detect other vehicles, pedestrians, and the drivable area on the road. Suggest an appropriate API for this purpose. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Traffic Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'HybridNets', 'api_call': \"torch.hub.load(repo_or_dir='datvuthanh/hybridnets', model='hybridnets', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'Python>=3.7, PyTorch>=1.10', 'example_code': \"import torch\\nmodel = torch.hub.load('datvuthanh/hybridnets', 'hybridnets', pretrained=True)\\nimg = torch.randn(1,3,640,384)\\nfeatures, regression, classification, anchors, segmentation = model(img)\", 'performance': {'dataset': [{'name': 'BDD100K', 'accuracy': {'Traffic Object Detection': {'Recall (%)': 92.8, 'mAP@0.5 (%)': 77.3}, 'Drivable Area Segmentation': {'Drivable mIoU (%)': 90.5}, 'Lane Line Detection': {'Accuracy (%)': 85.4, 'Lane Line IoU (%)': 31.6}}}]}, 'description': 'HybridNets is an end2end perception network for multi-tasks. Our work focused on traffic object detection, drivable area segmentation and lane detection. HybridNets can run real-time on embedded systems, and obtains SOTA Object Detection, Lane Detection on BDD100K Dataset.'}", "category": "generic"}
{"question_id": 375, "text": "Calculate the relative inverse depth from a single input image. Is there an API that can do this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Large', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Large')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 376, "text": "How can I estimate depth from a single image? Can you suggest an API for it? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Hybrid', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Hybrid')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 377, "text": "I have a single image and I want to compute the relative depth from it. Recommend an API that can help me achieve this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='MiDaS_small', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 378, "text": "A DJ wants to separate a song into four stems: vocals, drums, bass, and other instruments. What API can be used to achieve this? \n Use this API documentation for reference: {'domain': 'Audio Separation', 'framework': 'PyTorch', 'functionality': 'Music Source Separation', 'api_name': 'Open-Unmix', 'api_call': \"torch.hub.load(repo_or_dir='sigsep/open-unmix-pytorch', model='umxhq', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['PyTorch >=1.6.0', 'torchaudio'], 'example_code': ['import torch', \"separator = torch.hub.load('sigsep/open-unmix-pytorch', 'umxhq')\", 'audio = torch.rand((1, 2, 100000))', 'original_sample_rate = separator.sample_rate', 'estimates = separator(audio)'], 'performance': {'dataset': 'MUSDB18', 'accuracy': 'N/A'}, 'description': 'Open-Unmix provides ready-to-use models that allow users to separate pop music into four stems: vocals, drums, bass and the remaining other instruments. The models were pre-trained on the freely available MUSDB18 dataset.'}", "category": "generic"}
{"question_id": 379, "text": "Recommend an API that can convert a given text into speech with minimal dependencies. \n Use this API documentation for reference: {'domain': 'Text-To-Speech', 'framework': 'PyTorch', 'functionality': 'Text-To-Speech', 'api_name': 'Silero Text-To-Speech Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_tts', 'language': 'language', 'speaker': 'speaker'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf'], 'example_code': \"import torch\\nlanguage = 'en'\\nspeaker = 'lj_16khz'\\ndevice = torch.device('cpu')\\nmodel, symbols, sample_rate, example_text, apply_tts = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', language=language, speaker=speaker)\\nmodel = model.to(device)\\naudio = apply_tts(texts=[example_text], model=model, sample_rate=sample_rate, symbols=symbols, device=device)\", 'performance': {'dataset': [{'language': 'Russian', 'speakers': 6}, {'language': 'English', 'speakers': 1}, {'language': 'German', 'speakers': 1}, {'language': 'Spanish', 'speakers': 1}, {'language': 'French', 'speakers': 1}], 'accuracy': 'High throughput on slow hardware. Decent performance on one CPU thread'}, 'description': 'Silero Text-To-Speech models provide enterprise grade TTS in a compact form-factor for several commonly spoken languages. They offer one-line usage, naturally sounding speech, no GPU or training required, minimalism and lack of dependencies, a library of voices in many languages, support for 16kHz and 8kHz out of the box.'}", "category": "generic"}
{"question_id": 380, "text": "My application requires voice activity detection for processing phone calls. Give me an API that detects speech segments in an audio file. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Voice Activity Detection', 'api_name': 'Silero Voice Activity Detector', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-vad', 'model': 'silero_vad', 'force_reload': 'True'}, 'python_environment_requirements': {'torchaudio': 'pip install -q torchaudio'}, 'example_code': {'import': ['import torch', 'torch.set_num_threads(1)', 'from IPython.display import Audio', 'from pprint import pprint'], 'download_example': \"torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\", 'load_model': \"model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'load_utils': '(get_speech_timestamps, _, read_audio, _) = utils', 'set_sampling_rate': 'sampling_rate = 16000', 'read_audio': \"wav = read_audio('en_example.wav', sampling_rate=sampling_rate)\", 'get_speech_timestamps': 'speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sampling_rate)', 'print_speech_timestamps': 'pprint(speech_timestamps)'}, 'performance': {'dataset': '', 'accuracy': ''}, 'description': 'Silero VAD is a pre-trained enterprise-grade Voice Activity Detector (VAD) that aims to provide a high-quality and modern alternative to the WebRTC Voice Activity Detector. The model is optimized for performance on 1 CPU thread and is quantized.'}", "category": "generic"}
{"question_id": 381, "text": "A drone startup requires an API to analyze aerial images to recognize roads, buildings, and trees. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet50', 'Mean IOU': 66.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 382, "text": "How can I transcribe a recorded sales pitch from English speech to text using an API? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Speech-To-Text', 'api_name': 'Silero Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_stt', 'language': ['en', 'de', 'es'], 'device': 'device'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf soundfile'], 'example_code': ['import torch', 'import zipfile', 'import torchaudio', 'from glob import glob', \"device = torch.device('cpu')\", \"model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', language='en', device=device)\", '(read_batch, split_into_batches, read_audio, prepare_model_input) = utils', \"torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav', dst ='speech_orig.wav', progress=True)\", \"test_files = glob('speech_orig.wav')\", 'batches = split_into_batches(test_files, batch_size=10)', 'input = prepare_model_input(read_batch(batches[0]), device=device)', 'output = model(input)', 'for example in output:', ' print(decoder(example.cpu()))'], 'performance': {'dataset': 'Open-STT', 'accuracy': 'See the wiki for quality and performance benchmarks'}, 'description': 'Silero Speech-To-Text models provide enterprise grade STT in a compact form-factor for several commonly spoken languages. The models are robust to a variety of dialects, codecs, domains, noises, and lower sampling rates. They consume a normalized audio in the form of samples and output frames with token probabilities. A decoder utility is provided for simplicity.'}", "category": "generic"}
{"question_id": 383, "text": "I am working on a project that involves identifying bird species in pictures. Find me an API that can classify the bird species in an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Fine-grained image classifier', 'api_name': 'ntsnet', 'api_call': \"torch.hub.load(repo_or_dir='nicolalandro/ntsnet-cub200', model='ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\", 'api_arguments': {'pretrained': 'True', 'topN': '6', 'device': 'cpu', 'num_classes': '200'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': \"from torchvision import transforms\\nimport torch\\nimport urllib\\nfrom PIL import Image\\n\\ntransform_test = transforms.Compose([\\n transforms.Resize((600, 600), Image.BILINEAR),\\n transforms.CenterCrop((448, 448)),\\n transforms.ToTensor(),\\n transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\\n])\\n\\nmodel = torch.hub.load('nicolalandro/ntsnet-cub200', 'ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\\nmodel.eval()\\n\\nurl = 'https://raw.githubusercontent.com/nicolalandro/ntsnet-cub200/master/images/nts-net.png'\\nimg = Image.open(urllib.request.urlopen(url))\\nscaled_img = transform_test(img)\\ntorch_images = scaled_img.unsqueeze(0)\\n\\nwith torch.no_grad():\\n top_n_coordinates, concat_out, raw_logits, concat_logits, part_logits, top_n_index, top_n_prob = model(torch_images)\\n\\n_, predict = torch.max(concat_logits, 1)\\npred_id = predict.item()\\nprint('bird class:', model.bird_classes[pred_id])\", 'performance': {'dataset': 'CUB200 2011', 'accuracy': 'Not provided'}, 'description': 'This is an nts-net pretrained with CUB200 2011 dataset, which is a fine-grained dataset of birds species.'}", "category": "generic"}
{"question_id": 384, "text": "A drone is flying over the neighborhood and is recording video. How can I process the video and perform semantic segmentation on each frame? \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet101', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet101', 'Mean IOU': 67.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 385, "text": "I need to detect objects in a given image from a security camera. Can you provide me an API that can perform this task? \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'YOLOv5', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='ultralytics/yolov5', model='yolov5s', pretrained=True)\", 'api_arguments': [\"'ultralytics/yolov5'\", \"'yolov5s'\", 'pretrained=True'], 'python_environment_requirements': 'Python>=3.8, PyTorch>=1.7', 'example_code': ['import torch', \"model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\", \"imgs = ['https://ultralytics.com/images/zidane.jpg']\", 'results = model(imgs)', 'results.print()', 'results.save()', 'results.xyxy[0]', 'results.pandas().xyxy[0]'], 'performance': {'dataset': 'COCO', 'accuracy': {'YOLOv5s6': {'mAPval0.5:0.95': 43.3, 'mAPtest0.5:0.95': 43.3, 'mAPval0.5': 61.9}, 'YOLOv5m6': {'mAPval0.5:0.95': 50.5, 'mAPtest0.5:0.95': 50.5, 'mAPval0.5': 68.7}, 'YOLOv5l6': {'mAPval0.5:0.95': 53.4, 'mAPtest0.5:0.95': 53.4, 'mAPval0.5': 71.1}, 'YOLOv5x6': {'mAPval0.5:0.95': 54.4, 'mAPtest0.5:0.95': 54.4, 'mAPval0.5': 72.0}, 'YOLOv5x6 TTA': {'mAPval0.5:0.95': 55.0, 'mAPtest0.5:0.95': 55.0, 'mAPval0.5': 72.0}}}, 'description': 'YOLOv5 is a family of compound-scaled object detection models trained on the COCO dataset, and includes simple functionality for Test Time Augmentation (TTA), model ensembling, hyperparameter evolution, and export to ONNX, CoreML and TFLite.'}", "category": "generic"}
{"question_id": 386, "text": "Let's assume google earth has giant maps with satellite images. Help me to find an API that can apply segmentation to analyze the images better. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_mobilenet_v3_large', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_mobilenet_v3_large', 'Mean IOU': 60.3, 'Global Pixelwise Accuracy': 91.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 387, "text": "Recommend an API that can generate images of fashionable clothes and accessories automatically. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks', 'api_name': 'DCGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='DCGAN', pretrained=True, useGPU=use_gpu)\", 'api_arguments': {'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': ['import torch', 'import matplotlib.pyplot as plt', 'import torchvision'], 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'generate_images': 'with torch.no_grad(): generated_images = model.test(noise)', 'plot_images': ['plt.imshow(torchvision.utils.make_grid(generated_images).permute(1, 2, 0).cpu().numpy())', 'plt.show()']}, 'performance': {'dataset': 'FashionGen', 'accuracy': 'N/A'}, 'description': 'DCGAN is a model designed in 2015 by Radford et. al. in the paper Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. It is a GAN architecture both very simple and efficient for low resolution image generation (up to 64x64).'}", "category": "generic"}
{"question_id": 388, "text": "Buzzfeed would like to classify images of their new articles into categories. Suggest an appropriate API to accomplish this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x8d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x8d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x8d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x8d': {'Top-1 Acc.': '82.2', 'Top-5 Acc.': '96.4'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 389, "text": "Help me label the objects in images so they can be used for an e-commerce platform. What AI algorithm can do that? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x16d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x16d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x16d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x16d': {'Top-1 Acc.': '84.2', 'Top-5 Acc.': '97.2'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 390, "text": "Help a startup to develop a recommendation system to identify plants in their garden that visitors can take pictures of, suggest an API that can be used for plant identification from a picture. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x32d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x32d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x32d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x32d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x32d': {'Top-1 Acc.': '85.1', 'Top-5 Acc.': '97.5'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 391, "text": "I am a developer at an online store, trying to classify the objects in the images provided for each product. Suggest an AI API which can be utilized for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x48d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x48d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x48d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x48d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x48d': {'Top-1 Acc.': '85.4', 'Top-5 Acc.': '97.6'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 392, "text": "Recommend me an API to classify images into different categories quickly. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeXt101-32x4d', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resneXt', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'validators', 'matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', 'device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")', \"print(f'Using {device} for inference')\", \"resneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resneXt')\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resneXt.eval().to(device)', 'uris = [', \" 'http://images.cocodataset.org/test-stuff2017/000000024309.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000028117.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000006149.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000004954.jpg',\", ']', 'batch = torch.cat(', ' [utils.prepare_input_from_uri(uri) for uri in uris]', ').to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resneXt(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'IMAGENET', 'accuracy': 'Not provided'}, 'description': 'ResNeXt101-32x4d is a model introduced in the Aggregated Residual Transformations for Deep Neural Networks paper. It is based on regular ResNet model, substituting 3x3 convolutions inside the bottleneck block for 3x3 grouped convolutions. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures. It can be deployed for inference on the NVIDIA Triton Inference Server using TorchScript, ONNX Runtime or TensorRT as an execution backend.'}", "category": "generic"}
{"question_id": 393, "text": "Develop a solution to generate realistic high-quality faces. You can use a pre-trained GAN model as a starting point. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks (GANs)', 'api_name': 'PGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='PGAN', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'facebookresearch/pytorch_GAN_zoo:hub', 'model': 'PGAN', 'model_name': 'celebAHQ-512', 'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': 'import torch', 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'PGAN', model_name='celebAHQ-512', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'test': 'generated_images = model.test(noise)', 'plot_images': {'import_matplotlib': 'import matplotlib.pyplot as plt', 'import_torchvision': 'import torchvision', 'make_grid': 'grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1), scale_each=True, normalize=True)', 'imshow': 'plt.imshow(grid.permute(1, 2, 0).cpu().numpy())', 'show': 'plt.show()'}}, 'performance': {'dataset': 'celebA', 'accuracy': 'High-quality celebrity faces'}, 'description': \"Progressive Growing of GANs (PGAN) is a method for generating high-resolution images using generative adversarial networks. The model is trained progressively, starting with low-resolution images and gradually increasing the resolution until the desired output is achieved. This implementation is based on the paper by Tero Karras et al., 'Progressive Growing of GANs for Improved Quality, Stability, and Variation'.\"}", "category": "generic"}
{"question_id": 394, "text": "I have brain MRI scans and I want to segment the abnormal regions. Recommend an API that can perform this task. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Biomedical Image Segmentation', 'api_name': 'U-Net for brain MRI', 'api_call': \"torch.hub.load(repo_or_dir='mateuszbuda/brain-segmentation-pytorch', model='unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'api_arguments': {'in_channels': 3, 'out_channels': 1, 'init_features': 32, 'pretrained': True}, 'python_environment_requirements': ['torch', 'torchvision', 'numpy', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'import numpy as np', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'm, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))', 'preprocess = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=m, std=s)])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model = model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.round(output[0]))'], 'performance': {'dataset': 'kaggle.com/mateuszbuda/lgg-mri-segmentation'}, 'description': 'U-Net with batch normalization for biomedical image segmentation with pretrained weights for abnormality segmentation in brain MRI. The model comprises four levels of blocks containing two convolutional layers with batch normalization and ReLU activation function, and one max pooling layer in the encoding part and up-convolutional layers instead in the decoding part. The number of convolutional filters in each block is 32, 64, 128, and 256. The bottleneck layer has 512 convolutional filters. From the encoding layers, skip connections are used to the corresponding layers in the decoding part. Input image is a 3-channel brain MRI slice from pre-contrast, FLAIR, and post-contrast sequences, respectively. Output is a one-channel probability map of abnormality regions with the same size as the input image.'}", "category": "generic"}
{"question_id": 395, "text": "Detect if a given pair of sentences about artificial intelligence has any contradiction., 'Input': 'Roberta is a heavily optimized version of BERT. Roberta is not very optimized.' \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'RoBERTa', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq', model='roberta.large', pretrained=True)\", 'api_arguments': [\"'pytorch/fairseq'\", \"'roberta.large'\"], 'python_environment_requirements': ['regex', 'requests', 'hydra-core', 'omegaconf'], 'example_code': ['import torch', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\", 'roberta.eval()', \"tokens = roberta.encode('Hello world!')\", 'last_layer_features = roberta.extract_features(tokens)', 'all_layers = roberta.extract_features(tokens, return_all_hiddens=True)', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\", 'roberta.eval()', \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is not very optimized.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is based on BERT.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"roberta.register_classification_head('new_task', num_classes=3)\", \"logprobs = roberta.predict('new_task', tokens)\"], 'performance': {'dataset': 'MNLI', 'accuracy': 'N/A'}, 'description': \"RoBERTa is a robustly optimized version of BERT, a revolutionary self-supervised pretraining technique that learns to predict intentionally hidden (masked) sections of text. RoBERTa builds on BERT's language masking strategy and modifies key hyperparameters, including removing BERT's next-sentence pretraining objective, and training with much larger mini-batches and learning rates. RoBERTa was also trained on an order of magnitude more data than BERT, for a longer amount of time, allowing it to generalize even better to downstream tasks.\"}", "category": "generic"}
{"question_id": 396, "text": "Recommend an API to classify car models from images \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'AlexNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='alexnet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 43.45, 'top-5_error': 20.91}}, 'description': 'AlexNet is a deep convolutional neural network that achieved a top-5 error of 15.3% in the 2012 ImageNet Large Scale Visual Recognition Challenge. The main contribution of the original paper was the depth of the model, which was computationally expensive but made feasible through the use of GPUs during training. The pretrained AlexNet model in PyTorch can be used for image classification tasks.'}", "category": "generic"}
{"question_id": 397, "text": "An automotive company is developing their own autonomous vehicle and they need a pretrained model to classify road signs. Propose an API that can be used for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNet50', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['pip install validators matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", \"print(f'Using {device} for inference')\", \"resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resnet50.eval().to(device)', 'uris = [...]', 'batch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resnet50(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'ImageNet', 'accuracy': '~0.5% top1 improvement over ResNet50 v1'}, 'description': 'The ResNet50 v1.5 model is a modified version of the original ResNet50 v1 model. The difference between v1 and v1.5 is that, in the bottleneck blocks which requires downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate (~0.5% top1) than v1, but comes with a small performance drawback (~5% imgs/sec). The model is initialized as described in Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures.'}", "category": "generic"}
{"question_id": 398, "text": "We are looking for an image classification model for our large datasets. Suggest an API that can classify images efficiently and accurately. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SE-ResNeXt101', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_se_resnext101_32x4d', pretrained=True)\", 'api_arguments': 'N/A', 'python_environment_requirements': 'validators, matplotlib', 'example_code': \"import torch\\nfrom PIL import Image\\nimport torchvision.transforms as transforms\\nimport numpy as np\\nimport json\\nimport requests\\nimport matplotlib.pyplot as plt\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n%matplotlib inline\\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\nprint(f'Using {device} for inference')\\nresneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_se_resnext101_32x4d')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\nresneXt.eval().to(device)\\nuris = ['http://images.cocodataset.org/test-stuff2017/000000024309.jpg','http://images.cocodataset.org/test-stuff2017/000000028117.jpg','http://images.cocodataset.org/test-stuff2017/000000006149.jpg','http://images.cocodataset.org/test-stuff2017/000000004954.jpg']\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(resneXt(batch), dim=1)\\nresults = utils.pick_n_best(predictions=output, n=5)\\nfor uri, result in zip(uris, results):\\n img = Image.open(requests.get(uri, stream=True).raw)\\n img.thumbnail((256,256), Image.ANTIALIAS)\\n plt.imshow(img)\\n plt.show()\\n print(result)\", 'performance': {'dataset': 'IMAGENET', 'accuracy': 'N/A'}, 'description': 'The SE-ResNeXt101-32x4d is a ResNeXt101-32x4d model with added Squeeze-and-Excitation module. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures, which allows researchers to get results 3x faster than training without Tensor Cores while experiencing the benefits of mixed precision training.'}", "category": "generic"}
{"question_id": 399, "text": "My app needs a realistic human speech from text, point me to an API that helps achieve this. \n Use this API documentation for reference: {'domain': 'Text-to-Speech', 'framework': 'PyTorch', 'functionality': 'Speech Synthesis', 'api_name': 'WaveGlow', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_waveglow', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_waveglow', 'model_math': 'fp32'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': {'load_waveglow_model': \"waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp32')\", 'prepare_waveglow_model': ['waveglow = waveglow.remove_weightnorm(waveglow)', \"waveglow = waveglow.to('cuda')\", 'waveglow.eval()'], 'load_tacotron2_model': \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp32')\", 'prepare_tacotron2_model': [\"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()'], 'synthesize_speech': ['text = \"hello world, I missed you so much\"', \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'save_audio': 'write(\"audio.wav\", rate, audio_numpy)', 'play_audio': 'Audio(audio_numpy, rate=rate)'}, 'performance': {'dataset': 'LJ Speech', 'accuracy': None}, 'description': 'The Tacotron 2 and WaveGlow model form a text-to-speech system that enables users to synthesize natural-sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 400, "text": "I am creating a mobile app that identifies objects in images. Recommend an API for image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet121', pretrained=True)\", 'api_arguments': [{'name': 'densenet121', 'type': 'str', 'description': 'Densenet-121 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet121': {'Top-1 error': 25.35, 'Top-5 error': 7.83}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 401, "text": "I need an API for categorizing images of flowers into their respective classes. Propose an API that can help me. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet201', pretrained=True)\", 'api_arguments': [{'name': 'densenet201', 'type': 'str', 'description': 'Densenet-201 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet201': {'Top-1 error': 22.8, 'Top-5 error': 6.43}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 402, "text": "I want to classify images of different animals, give me an API that can help right now. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet169', pretrained=True)\", 'api_arguments': [{'name': 'densenet169', 'type': 'str', 'description': 'Densenet-169 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet169': {'Top-1 error': 24.0, 'Top-5 error': 7.0}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 403, "text": "Suggest a deep learning API capable of categorizing images through an efficient neural network architecture. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet161', pretrained=True)\", 'api_arguments': [{'name': 'densenet161', 'type': 'str', 'description': 'Densenet-161 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet161', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet161': {'Top-1 error': 22.35, 'Top-5 error': 6.2}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 404, "text": "Suggest a suitable API to segment an image into semantically meaningful regions, such as people, cars, and buildings. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet50', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet50': {'Mean IOU': 60.5, 'Global Pixelwise Accuracy': 91.4}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 405, "text": "For a city development project, I need to segment roads, buildings, and trees from satellite images. Propose an API that can help me with this task. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet101', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet101': {'Mean IOU': 63.7, 'Global Pixelwise Accuracy': 91.9}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 406, "text": "AppRocket wants a recommendation for a lightweight API to classify images for their mobile app. What is lightweight API that can use for this purpose? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet39ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet39ds', 'type': 'str', 'description': 'HarDNet-39DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet39ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet39ds': {'Top-1 error': 27.92, 'Top-5 error': 9.57}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 407, "text": "I am building an application that can recognize objects in images. Provide me with an API that can classify objects in an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet85', pretrained=True)\", 'api_arguments': [{'name': 'hardnet85', 'type': 'str', 'description': 'HarDNet-85 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet85', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet85': {'Top-1 error': 21.96, 'Top-5 error': 6.11}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 408, "text": "Find an API that can help a mobile gallery app categorize images based on their content while having a low memory footprint. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68ds', 'type': 'str', 'description': 'HarDNet-68DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68ds': {'Top-1 error': 25.71, 'Top-5 error': 8.13}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 409, "text": "Obtain an API that can classify images using a lightweight neural network architecture. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Efficient networks by generating more features from cheap operations', 'api_name': 'GhostNet', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/ghostnet', model='ghostnet_1x', pretrained=True)\", 'api_arguments': ['pretrained'], 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/ghostnet', 'ghostnet_1x', pretrained=True)\", 'model.eval()', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 acc': '73.98', 'Top-5 acc': '91.46'}}, 'description': 'The GhostNet architecture is based on an Ghost module structure which generates more features from cheap operations. Based on a set of intrinsic feature maps, a series of cheap operations are applied to generate many ghost feature maps that could fully reveal information underlying intrinsic features. Experiments conducted on benchmarks demonstrate the superiority of GhostNet in terms of speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 410, "text": "What API could be used to identify plants in a garden from taken image? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'GoogLeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='googlenet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.0.0', 'torchvision': '>=0.2.2'}, 'example_code': {'import': ['import torch', 'import urllib', 'from PIL import Image', 'from torchvision import transforms'], 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\", 'model_eval': 'model.eval()', 'image_preprocessing': ['input_image = Image.open(filename)', 'preprocess = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'model_execution': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'output_processing': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'top5_prob, top5_catid = torch.topk(probabilities, 5)']}, 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 error': '30.22', 'Top-5 error': '10.47'}}, 'description': \"GoogLeNet is based on a deep convolutional neural network architecture codenamed 'Inception', which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014).\"}", "category": "generic"}
{"question_id": 411, "text": "I am planning to build a fashion blog which sorts numerous fashion trends. Find a proper API that can classify fashion styles from an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet50_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet50_ibn_a', 'type': 'str', 'description': 'ResNet-50-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet50_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet50_ibn_a': {'Top-1 acc': 77.46, 'Top-5 acc': 93.68}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 412, "text": "I am working on a cross-domain image classification project, and I need a pre-trained model that has strong domain invariance. Can you recommend an API for this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet101_ibn_a', 'type': 'str', 'description': 'ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet101_ibn_a': {'Top-1 acc': 78.61, 'Top-5 acc': 94.41}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 413, "text": "We are a project lead for a computer vision company and we are building a custom person re-identification system. Share with me an API that can be beneficial for cross-domain identification task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='se_resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'se_resnet101_ibn_a', 'type': 'str', 'description': 'SE-ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'se_resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'se_resnet101_ibn_a': {'Top-1 acc': 78.75, 'Top-5 acc': 94.49}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 414, "text": "I am looking for an API that can classify animals in images. Could you recommend a suitable API? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest50', pretrained=True)\", 'api_arguments': 'resnest50', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-50': 81.03}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 415, "text": "I need to accurately identify cross domain objects. Give me an API that can handle object recognition tasks with improved performance on cross domain tasks. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnext101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_ibn_a', 'type': 'str', 'description': 'ResNeXt-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnext101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext101_ibn_a': {'Top-1 acc': 79.12, 'Top-5 acc': 94.58}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 416, "text": "I am maintaining a gallery and I am looking for a library that can classify images to different categories. Can you suggest an API? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'Inception_v3', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='inception_v3', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '1.9.0', 'torchvision': '0.10.0'}, 'example_code': {'import_libraries': 'import torch', 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\", 'model_evaluation': 'model.eval()'}, 'performance': {'dataset': 'imagenet', 'accuracy': {'top-1_error': 22.55, 'top-5_error': 6.44}}, 'description': 'Inception v3, also called GoogleNetv3, is a famous Convolutional Neural Network trained on the ImageNet dataset from 2015. It is based on the exploration of ways to scale up networks to utilize the added computation as efficiently as possible by using suitably factorized convolutions and aggressive regularization. The model achieves a top-1 error of 22.55% and a top-5 error of 6.44% on the ImageNet dataset.'}", "category": "generic"}
{"question_id": 417, "text": "Find an API that can efficiently classify dog breeds from the given photographs. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest101', pretrained=True)\", 'api_arguments': 'resnest101', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-101': 82.83}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 418, "text": "I need an API that can perform advanced image classification tasks, and outperform other networks with similar complexities. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest200', pretrained=True)\", 'api_arguments': 'resnest200', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest200', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-200': 83.84}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 419, "text": "I want to classify images for my large-scale imaging project. Recommend an API to use for high accuracy image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest269', pretrained=True)\", 'api_arguments': 'resnest269', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest269', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-269': 84.54}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 420, "text": "I need an API that helps me in designing an efficient neural network architecture for my mobile device. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_mobile', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_mobile', 'type': 'str', 'description': 'ProxylessNAS optimized for Mobile'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_mobile'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_mobile', 'accuracy': 74.6}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 421, "text": "Recommend an API that can optimize neural network architecture for efficient object classification on mobile devices. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_cpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_cpu', 'type': 'str', 'description': 'ProxylessNAS optimized for CPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_cpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_cpu', 'accuracy': 75.3}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 422, "text": "Provide me with an API capable of classifying images from a news website into Sports, Entertainment, World News, and Technology categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MobileNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='mobilenet_v2', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 28.12, 'top-5_error': 9.71}}, 'description': 'The MobileNet v2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input. MobileNet v2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, non-linearities in the narrow layers were removed in order to maintain representational power.'}", "category": "generic"}
{"question_id": 423, "text": "We need a neural network for image classification and It should be specifically designed for different hardware platforms. Tell me an API that can help with this requirement. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_gpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_gpu', 'type': 'str', 'description': 'ProxylessNAS optimized for GPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_gpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_gpu', 'accuracy': 75.1}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 424, "text": "I need to identify plant species from leaf images using a pretrained model. Recommend an appropriate API for this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet18', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet18', 'top-1_error': 30.24, 'top-5_error': 10.92}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 425, "text": "Identify an API that can automatically detect objects in an image and return the object labels \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet34', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet34', 'top-1_error': 26.7, 'top-5_error': 8.58}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 426, "text": "A programmer needs to classify images into 1000 categories like cats, dogs, planes, etc. Offer them an API that can perform this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet50', 'top-1_error': 23.85, 'top-5_error': 7.13}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 427, "text": "A startup needs to classify images using state of the art research. Suggest an image classification API to do this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet101', 'top-1_error': 22.63, 'top-5_error': 6.44}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 428, "text": "A scientist wants to identify bird species by uploading photos. Propose an API that can classify bird species from an input image.  \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet152', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet152', 'top-1_error': 21.69, 'top-5_error': 5.94}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 429, "text": "Suggest an API to develop a tool to classify plants based on their images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext50_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext50_32x4d': {'top-1': 22.38, 'top-5': 6.3}}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 430, "text": "You want an API to classify an image in order to organize your photos. Recommend an API that can be used for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext101_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext101_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'resnext101_32x8d': {'top-1': 20.69, 'top-5': 5.47}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 431, "text": "Introduce an image classifier API that can predict the class of a given image for an app that tags photos according to their content. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_t', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_t', 'type': 'str', 'description': 'SNNMLP Tiny model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_t', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Tiny', 'top-1': 81.88}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 432, "text": "Find me an AI framework that can classify various animals' images when given a picture file with a high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_b', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_b', 'type': 'str', 'description': 'SNNMLP Base model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_b', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Base', 'top-1': 85.59}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 433, "text": "An app developer is searching for an AI solution to classify pets in photos. Recommend an API that can fulfill this need. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_s', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_s', 'type': 'str', 'description': 'SNNMLP Small model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_s', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Small', 'top-1': 83.3}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 434, "text": "Make a recommendation for a pretrained API for an image classification task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11', pretrained=True)\", 'api_arguments': [{'name': 'vgg11', 'type': 'str', 'description': 'VGG11 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11': {'Top-1 error': 30.98, 'Top-5 error': 11.37}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 435, "text": "I need a fast and lightweight image classification model for a mobile app that can recognize objects in images. What API do you suggest? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_1', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_1'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_1': {'Top-1 error': 41.81, 'Top-5 error': 19.38}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 436, "text": "Create a model that can categorize images into categories given its pretrained models. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_0', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_0'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_0': {'Top-1 error': 41.9, 'Top-5 error': 19.58}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 437, "text": "CCTV cameras need to classify opened doors from closed ones. Suggest an image recognition API for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13', pretrained=True)\", 'api_arguments': [{'name': 'vgg13', 'type': 'str', 'description': 'VGG13 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13': {'Top-1 error': 30.07, 'Top-5 error': 10.75}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn,vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 438, "text": "What is an API that can be used to classify images of different categories using a computationally efficient model? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ShuffleNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='shufflenet_v2_x1_0', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'torch', 'torchvision': 'torchvision', 'PIL': 'Image', 'urllib': 'urllib'}, 'example_code': {'import_libraries': ['import torch', 'from PIL import Image', 'from torchvision import transforms', 'import urllib'], 'load_model': [\"model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\", 'model.eval()'], 'load_image': [\"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'try: urllib.URLopener().retrieve(url, filename)', 'except: urllib.request.urlretrieve(url, filename)', 'input_image = Image.open(filename)'], 'preprocess_image': ['preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'run_inference': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'get_probabilities': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'top_categories': ['top5_prob, top5_catid = torch.topk(probabilities, 5)', 'for i in range(top5_prob.size(0)):', ' print(categories[top5_catid[i]], top5_prob[i].item())']}, 'performance': {'dataset': 'Imagenet', 'accuracy': {'top-1_error': 30.64, 'top-5_error': 11.68}}, 'description': 'ShuffleNet V2 is an efficient ConvNet optimized for speed and memory, pre-trained on Imagenet. It is designed based on practical guidelines for efficient network design, including speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 439, "text": "A student from MIT is working on a project that uses image recognition to identify the type of animal in an image. Give me an API that they can use to achieve this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg11_bn', 'type': 'str', 'description': 'VGG11 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11_bn': {'Top-1 error': 26.7, 'Top-5 error': 8.58}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 440, "text": "I want to get an API to recognize different types of animals in photographs, like lions, tigers, and bears. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg13_bn', 'type': 'str', 'description': 'VGG13 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13_bn': {'Top-1 error': 28.45, 'Top-5 error': 9.63}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 441, "text": "Identify an API that allows for image recognition with a high accuracy rate. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16', pretrained=True)\", 'api_arguments': [{'name': 'vgg16', 'type': 'str', 'description': 'VGG16 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16': {'Top-1 error': 28.41, 'Top-5 error': 9.62}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 442, "text": "Recommend an API that can be employed to identify the breed of a dog from a given image \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg16_bn', 'type': 'str', 'description': 'VGG16 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16_bn': {'Top-1 error': 26.63, 'Top-5 error': 8.5}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 443, "text": "Recommend an image recognition API that can identify the objects within a picture. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19', pretrained=True)\", 'api_arguments': [{'name': 'vgg19', 'type': 'str', 'description': 'VGG19 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19': {'Top-1 error': 27.62, 'Top-5 error': 9.12}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 444, "text": "I have a photo and I want to know the object type in it. Can you provide an API that can recognize the object? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg19_bn', 'type': 'str', 'description': 'VGG19 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19_bn': {'Top-1 error': 25.76, 'Top-5 error': 8.15}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 445, "text": "Help me choose an adequate API to classify satellite images into land use categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet101_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet101_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet101_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet101_2': {'Top-1 error': 21.16, 'Top-5 error': 5.72}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 446, "text": "A start-up is building a dog breed detector and they need an API that can classify images into categories. Suggest an ideal API that can help them achieve this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet50_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet50_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet50_2': {'Top-1 error': 21.49, 'Top-5 error': 5.91}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 447, "text": "How can I classify the actions in a video, like playing guitar or doing push-ups, using an AI API? \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'SlowFast Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slowfast_r50', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'slowfast_r50', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 76.94, 'top5': 92.69}, 'flops': 65.71, 'params': 34.57}, 'description': \"Slow Fast model architectures are based on the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al. They are pretrained on the Kinetics 400 dataset using the 8x8 setting. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 448, "text": "I am developing a video indexing application and I want to classify actions in video clips. What API should I use? \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'X3D Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='x3d_s', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'x3d_s', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_s', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 73.33, 'top5': 91.27}, 'flops': 2.96, 'params': 3.79}, 'description': \"X3D model architectures are based on the paper 'X3D: Expanding Architectures for Efficient Video Recognition' by Christoph Feichtenhofer. They are pretrained on the Kinetics 400 dataset. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 449, "text": "A racing company wants to optimize their code by using once-for-all networks. Suggest an API that can classify road traffic images with once-for-all networks. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Once-for-all (OFA) Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/once-for-all', model='ofa_supernet_mbv3_w10', pretrained=True)\", 'api_arguments': {'repository': 'mit-han-lab/once-for-all', 'model': 'ofa_supernet_mbv3_w10', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"super_net_name = 'ofa_supernet_mbv3_w10'\", \"super_net = torch.hub.load('mit-han-lab/once-for-all', super_net_name, pretrained=True).eval()\"], 'performance': {'description': 'OFA networks outperform state-of-the-art NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x faster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency) while reducing many orders of magnitude GPU hours and CO2 emission.'}, 'description': 'Once-for-all (OFA) networks are a family of neural networks designed by MIT Han Lab. They decouple training and search, achieving efficient inference across various edge devices and resource constraints. OFA networks are pretrained on the IMAGENET dataset and are capable of classifying images into different categories.'}", "category": "generic"}
{"question_id": 450, "text": "Recommend an API for a pet food company that wants to make an app to identify cat breeds in pictures. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Semi-supervised and semi-weakly supervised ImageNet Models', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/semi-supervised-ImageNet1K-models', model='resnet18_swsl', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/semi-supervised-ImageNet1K-models', 'model': 'resnet18_swsl', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl', pretrained=True)\", 'model.eval()'], 'performance': {'description': 'Semi-supervised and semi-weakly supervised ImageNet models achieve state-of-the-art accuracy of 81.2% on ImageNet for the widely used/adopted ResNet-50 model architecture.'}, 'description': \"Semi-supervised and semi-weakly supervised ImageNet Models are introduced in the 'Billion scale semi-supervised learning for image classification' paper. These models are pretrained on a subset of unlabeled YFCC100M public image dataset and fine-tuned with the ImageNet1K training dataset. They are capable of classifying images into different categories and are provided by the Facebook Research library.\"}", "category": "generic"}
{"question_id": 451, "text": "A journalist needs to analyze a set of sentences to understand the context. Provide an API that can help with natural language processing. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Natural Language Processing', 'api_name': 'PyTorch-Transformers', 'api_call': \"torch.hub.load(repo_or_dir='huggingface/pytorch-transformers')\", 'api_arguments': ['pretrained_model_or_path', 'output_attention', 'output_hidden_states', 'config', 'from_tf'], 'python_environment_requirements': ['tqdm', 'boto3', 'requests', 'regex', 'sentencepiece', 'sacremoses'], 'example_code': 'import torch\\ntokenizer = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'tokenizer\\', \\'bert-base-cased\\')\\n\\ntext_1 = \"Jim Henson was a puppeteer\"\\ntext_2 = \"Who was Jim Henson ?\"\\n\\nindexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\\n\\nmodel = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'model\\', \\'bert-base-cased\\')\\n\\nwith torch.no_grad():\\n encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)', 'performance': {'dataset': [{'name': 'MRPC', 'accuracy': 'Not provided'}]}, 'description': 'PyTorch-Transformers is a library of state-of-the-art pre-trained models for Natural Language Processing (NLP) including BERT, GPT, GPT-2, Transformer-XL, XLNet, XLM, RoBERTa, and DistilBERT. The library provides functionality for tokenization, configuration, and various model architectures for different tasks such as causal language modeling, sequence classification, question answering, and masked language modeling.'}", "category": "generic"}
{"question_id": 452, "text": "A travel buddy application is helping the tourists communicate at many non-english countries. Provide me an API which can help tourists translate simple questions like \"where is the restroom?\" when given the destination language code. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Neural Machine Translation', 'api_name': 'Transformer (NMT)', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq')\", 'api_arguments': ['model_name', 'tokenizer', 'bpe', 'beam', 'sampling', 'sampling_topk'], 'python_environment_requirements': ['bitarray', 'fastBPE', 'hydra-core', 'omegaconf', 'regex', 'requests', 'sacremoses', 'subword_nmt'], 'example_code': \"import torch\\n\\nen2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\\n\\nen2fr.cuda()\\n\\nfr = en2fr.translate('Hello world!', beam=5)\\nassert fr == 'Bonjour \u00e0 tous !'\", 'performance': {'dataset': [{'name': \"WMT'14\", 'accuracy': 'Not provided'}, {'name': \"WMT'18\", 'accuracy': 'Not provided'}, {'name': \"WMT'19\", 'accuracy': 'Not provided'}]}, 'description': \"Transformer (NMT) is a powerful sequence-to-sequence modeling architecture that produces state-of-the-art neural machine translation systems. It is based on the paper 'Attention Is All You Need' and has been improved using techniques such as large-scale semi-supervised training, back-translation, and noisy-channel reranking. It supports English-French and English-German translation as well as round-trip translation for paraphrasing.\"}", "category": "generic"}
{"question_id": 453, "text": "I am a product manager and I am building a recommendation system for my customers based on the pictures of the clothes they have purchased from our online store. Suggest an API that can classify the clothing type based on a given image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'GPUNet Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", 'api_arguments': {'repository': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_gpunet', 'pretrained': 'True', 'model_type': 'GPUNet-0', 'model_math': 'fp32'}, 'python_environment_requirements': ['torch', 'validators', 'matplotlib', 'timm==0.5.4'], 'example_code': ['import torch', \"model_type = 'GPUNet-0'\", \"precision = 'fp32'\", \"gpunet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'gpunet.to(device)', 'gpunet.eval()'], 'performance': {'dataset': 'IMAGENET', 'description': 'GPUNet demonstrates state-of-the-art inference performance up to 2x faster than EfficientNet-X and FBNet-V3.'}, 'description': 'GPUNet is a family of Convolutional Neural Networks designed by NVIDIA using novel Neural Architecture Search (NAS) methods. They are optimized for NVIDIA GPU and TensorRT performance. GPUNet models are pretrained on the IMAGENET dataset and are capable of classifying images into different categories. The models are provided by the NVIDIA Deep Learning Examples library.'}", "category": "generic"}
{"question_id": 454, "text": "As a traffic analyst, I need an API that can detect vehicles from traffic camera images. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Single Shot MultiBox Detector', 'api_name': 'SSD', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_ssd', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['numpy', 'scipy', 'scikit-image', 'matplotlib'], 'example_code': \"import torch\\n\\nssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\\n\\nssd_model.to('cuda')\\nssd_model.eval()\\n\\ninputs = [utils.prepare_input(uri) for uri in uris]\\ntensor = utils.prepare_tensor(inputs)\\n\\nwith torch.no_grad():\\n detections_batch = ssd_model(tensor)\\n\\nresults_per_input = utils.decode_results(detections_batch)\\nbest_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\", 'performance': {'dataset': {'name': 'COCO', 'accuracy': 'Not provided'}}, 'description': \"The SSD (Single Shot MultiBox Detector) model is an object detection model based on the paper 'SSD: Single Shot MultiBox Detector'. It uses a deep neural network for detecting objects in images. This implementation replaces the obsolete VGG model backbone with the more modern ResNet-50 model. The SSD model is trained on the COCO dataset and can be used to detect objects in images with high accuracy and efficiency.\"}", "category": "generic"}
{"question_id": 455, "text": "Can you tell me an API that can be used for image classification of flowers with high accuracy and efficiency? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'EfficientNet', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_efficientnet_b0', pretrained=True)\", 'api_arguments': ['model_name', 'pretrained'], 'python_environment_requirements': ['validators', 'matplotlib'], 'example_code': \"import torch\\n\\nefficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\n\\nefficientnet.eval().to(device)\\n\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\n\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(efficientnet(batch), dim=1)\\n \\nresults = utils.pick_n_best(predictions=output, n=5)\", 'performance': {'dataset': {'name': 'IMAGENET', 'accuracy': 'Not provided'}}, 'description': 'EfficientNet is a family of image classification models that achieve state-of-the-art accuracy while being smaller and faster. The models are trained with mixed precision using Tensor Cores on the NVIDIA Volta and Ampere GPU architectures. The EfficientNet models include EfficientNet-B0, EfficientNet-B4, EfficientNet-WideSE-B0, and EfficientNet-WideSE-B4. The WideSE models use wider Squeeze-and-Excitation layers than the original EfficientNet models, resulting in slightly better accuracy.'}", "category": "generic"}
{"question_id": 456, "text": "A smartphone company needs a machine learning API for their photo app, allowing users to know the content of their photos. Which PyTorch API should they use? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V1', model='mealv1_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv1_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V1 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '78.21', 'top5': '94.01'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 457, "text": "I need a PyTorch API for image classification that has been pretrained on ImageNet and achieves at least 80% top-1 accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.67', 'top5': '95.09'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 458, "text": "We want to use AI to convert our text content to natural-sounding speech. Suggest an API that can perform this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Text-to-Speech', 'api_name': 'Tacotron 2', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_tacotron2', model_math='fp16')\", 'api_arguments': {'model_math': 'fp16'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': ['import torch', \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\", \"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()', \"text = 'Hello world, I missed you so much.'\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'performance': {'dataset': 'LJ Speech', 'accuracy': 'Not specified'}, 'description': 'The Tacotron 2 model generates mel spectrograms from input text using an encoder-decoder architecture, and it is designed for generating natural-sounding speech from raw transcripts without any additional prosody information. This implementation uses Dropout instead of Zoneout to regularize the LSTM layers. The WaveGlow model (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 459, "text": "I need to classify an image using a state-of-the-art image classification model without any data augmentation techniques or additional tricks. What API should I use? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_cutmix', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_cutmix'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 + CutMix w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.98', 'top5': '95.35'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 460, "text": "I am an engineer in the environmental sector and I am attempting to develop an AI model that can accurately classify images of animals taken with a trail camera. Find an API that will support this capability. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_380x380', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_380x380'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '380', 'parameters': '25.6M', 'top1': '81.72', 'top5': '95.81'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 461, "text": "I have an image classification task with limited computational resources. I need a lightweight image classification API recommendation for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_075', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_075'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 0.75', 'resolution': '224', 'parameters': '2.04M', 'top1': '67.60', 'top5': '87.23'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 462, "text": "Find an API that allows me to classify images with high accuracy without tricks such as autoaugmentation or mixup methods. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 1.0', 'resolution': '224', 'parameters': '2.54M', 'top1': '69.65', 'top5': '88.71'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 463, "text": "A developer is working on a image recognition AI to classify animals in a zoo. Can you provide an API that can help with this task? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenet_v3_large_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenet_v3_large_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Large 1.0', 'resolution': '224', 'parameters': '5.48M', 'top1': '76.92', 'top5': '93.32'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 464, "text": "Recommend an API that can analyze a video and classify different activities featured in the video. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorch', 'functionality': '3D ResNet', 'api_name': 'slow_r50', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slow_r50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'json', 'urllib', 'pytorchvideo', 'torchvision', 'torchaudio', 'torchtext', 'torcharrow', 'TorchData', 'TorchRec', 'TorchServe', 'PyTorch on XLA Devices'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top_1': 74.58, 'top_5': 91.63}, 'Flops (G)': 54.52, 'Params (M)': 32.45}, 'description': \"The 3D ResNet model is a Resnet-style video classification network pretrained on the Kinetics 400 dataset. It is based on the architecture from the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al.\"}", "category": "generic"}
{"question_id": 465, "text": "I want an API that can identify animals in a image from an ongoing research about endangered animals. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_efficientnet_b0', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_efficientnet_b0'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ EfficientNet-B0', 'resolution': '224', 'parameters': '5.29M', 'top1': '78.29', 'top5': '93.95'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 466, "text": "What API would help me estimate the depth of objects within a single image? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Large', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Large')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 467, "text": "I want to build a self-driving car application that can detect objects, segment drivable areas, and detect lanes. Point me to an API that can do this. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'YOLOP', 'api_call': \"torch.hub.load(repo_or_dir='hustvl/yolop', model='yolop', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'pip install -qr https://github.com/hustvl/YOLOP/blob/main/requirements.txt', 'example_code': \"import torch\\nmodel = torch.hub.load('hustvl/yolop', 'yolop', pretrained=True)\\nimg = torch.randn(1,3,640,640)\\ndet_out, da_seg_out,ll_seg_out = model(img)\", 'performance': {'dataset': 'BDD100K', 'accuracy': {'Object Detection': {'Recall(%)': 89.2, 'mAP50(%)': 76.5, 'Speed(fps)': 41}, 'Drivable Area Segmentation': {'mIOU(%)': 91.5, 'Speed(fps)': 41}, 'Lane Detection': {'mIOU(%)': 70.5, 'IOU(%)': 26.2}}}, 'description': 'YOLOP is an efficient multi-task network that can jointly handle three crucial tasks in autonomous driving: object detection, drivable area segmentation and lane detection. And it is also the first to reach real-time on embedded devices while maintaining state-of-the-art level performance on the BDD100K dataset.'}", "category": "generic"}
{"question_id": 468, "text": "What API can determine the relative depth of objects within the frame given a single 2D image of a room? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Hybrid', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Hybrid')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 469, "text": "I captured a photograph of a room and want to know the relative depth of the objects in it. Can you suggest an API which can help me with this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='MiDaS_small', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 470, "text": "I have a pop music soundtrack and I want to extract drums, vocals, and bass from it. Give me an API that can perform this music separation. \n Use this API documentation for reference: {'domain': 'Audio Separation', 'framework': 'PyTorch', 'functionality': 'Music Source Separation', 'api_name': 'Open-Unmix', 'api_call': \"torch.hub.load(repo_or_dir='sigsep/open-unmix-pytorch', model='umxhq', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['PyTorch >=1.6.0', 'torchaudio'], 'example_code': ['import torch', \"separator = torch.hub.load('sigsep/open-unmix-pytorch', 'umxhq')\", 'audio = torch.rand((1, 2, 100000))', 'original_sample_rate = separator.sample_rate', 'estimates = separator(audio)'], 'performance': {'dataset': 'MUSDB18', 'accuracy': 'N/A'}, 'description': 'Open-Unmix provides ready-to-use models that allow users to separate pop music into four stems: vocals, drums, bass and the remaining other instruments. The models were pre-trained on the freely available MUSDB18 dataset.'}", "category": "generic"}
{"question_id": 471, "text": "I want to classify a bird species from an image given. Please give me the API to help me do this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Fine-grained image classifier', 'api_name': 'ntsnet', 'api_call': \"torch.hub.load(repo_or_dir='nicolalandro/ntsnet-cub200', model='ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\", 'api_arguments': {'pretrained': 'True', 'topN': '6', 'device': 'cpu', 'num_classes': '200'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': \"from torchvision import transforms\\nimport torch\\nimport urllib\\nfrom PIL import Image\\n\\ntransform_test = transforms.Compose([\\n transforms.Resize((600, 600), Image.BILINEAR),\\n transforms.CenterCrop((448, 448)),\\n transforms.ToTensor(),\\n transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\\n])\\n\\nmodel = torch.hub.load('nicolalandro/ntsnet-cub200', 'ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\\nmodel.eval()\\n\\nurl = 'https://raw.githubusercontent.com/nicolalandro/ntsnet-cub200/master/images/nts-net.png'\\nimg = Image.open(urllib.request.urlopen(url))\\nscaled_img = transform_test(img)\\ntorch_images = scaled_img.unsqueeze(0)\\n\\nwith torch.no_grad():\\n top_n_coordinates, concat_out, raw_logits, concat_logits, part_logits, top_n_index, top_n_prob = model(torch_images)\\n\\n_, predict = torch.max(concat_logits, 1)\\npred_id = predict.item()\\nprint('bird class:', model.bird_classes[pred_id])\", 'performance': {'dataset': 'CUB200 2011', 'accuracy': 'Not provided'}, 'description': 'This is an nts-net pretrained with CUB200 2011 dataset, which is a fine-grained dataset of birds species.'}", "category": "generic"}
{"question_id": 472, "text": "What is a good API for transcribing spoken language within a podcast into readable text in multiple languages? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Speech-To-Text', 'api_name': 'Silero Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_stt', 'language': ['en', 'de', 'es'], 'device': 'device'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf soundfile'], 'example_code': ['import torch', 'import zipfile', 'import torchaudio', 'from glob import glob', \"device = torch.device('cpu')\", \"model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', language='en', device=device)\", '(read_batch, split_into_batches, read_audio, prepare_model_input) = utils', \"torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav', dst ='speech_orig.wav', progress=True)\", \"test_files = glob('speech_orig.wav')\", 'batches = split_into_batches(test_files, batch_size=10)', 'input = prepare_model_input(read_batch(batches[0]), device=device)', 'output = model(input)', 'for example in output:', ' print(decoder(example.cpu()))'], 'performance': {'dataset': 'Open-STT', 'accuracy': 'See the wiki for quality and performance benchmarks'}, 'description': 'Silero Speech-To-Text models provide enterprise grade STT in a compact form-factor for several commonly spoken languages. The models are robust to a variety of dialects, codecs, domains, noises, and lower sampling rates. They consume a normalized audio in the form of samples and output frames with token probabilities. A decoder utility is provided for simplicity.'}", "category": "generic"}
{"question_id": 473, "text": "What API should we use to perform semantic segmentation on aerial images for identifying buildings, roads, and vegetation? \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet50', 'Mean IOU': 66.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 474, "text": "I need an API that can detect voice activity from an audio file. Propose an API for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Voice Activity Detection', 'api_name': 'Silero Voice Activity Detector', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-vad', 'model': 'silero_vad', 'force_reload': 'True'}, 'python_environment_requirements': {'torchaudio': 'pip install -q torchaudio'}, 'example_code': {'import': ['import torch', 'torch.set_num_threads(1)', 'from IPython.display import Audio', 'from pprint import pprint'], 'download_example': \"torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\", 'load_model': \"model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'load_utils': '(get_speech_timestamps, _, read_audio, _) = utils', 'set_sampling_rate': 'sampling_rate = 16000', 'read_audio': \"wav = read_audio('en_example.wav', sampling_rate=sampling_rate)\", 'get_speech_timestamps': 'speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sampling_rate)', 'print_speech_timestamps': 'pprint(speech_timestamps)'}, 'performance': {'dataset': '', 'accuracy': ''}, 'description': 'Silero VAD is a pre-trained enterprise-grade Voice Activity Detector (VAD) that aims to provide a high-quality and modern alternative to the WebRTC Voice Activity Detector. The model is optimized for performance on 1 CPU thread and is quantized.'}", "category": "generic"}
{"question_id": 475, "text": "Create an audio version of an English text using an API. \n Use this API documentation for reference: {'domain': 'Text-To-Speech', 'framework': 'PyTorch', 'functionality': 'Text-To-Speech', 'api_name': 'Silero Text-To-Speech Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_tts', 'language': 'language', 'speaker': 'speaker'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf'], 'example_code': \"import torch\\nlanguage = 'en'\\nspeaker = 'lj_16khz'\\ndevice = torch.device('cpu')\\nmodel, symbols, sample_rate, example_text, apply_tts = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', language=language, speaker=speaker)\\nmodel = model.to(device)\\naudio = apply_tts(texts=[example_text], model=model, sample_rate=sample_rate, symbols=symbols, device=device)\", 'performance': {'dataset': [{'language': 'Russian', 'speakers': 6}, {'language': 'English', 'speakers': 1}, {'language': 'German', 'speakers': 1}, {'language': 'Spanish', 'speakers': 1}, {'language': 'French', 'speakers': 1}], 'accuracy': 'High throughput on slow hardware. Decent performance on one CPU thread'}, 'description': 'Silero Text-To-Speech models provide enterprise grade TTS in a compact form-factor for several commonly spoken languages. They offer one-line usage, naturally sounding speech, no GPU or training required, minimalism and lack of dependencies, a library of voices in many languages, support for 16kHz and 8kHz out of the box.'}", "category": "generic"}
{"question_id": 476, "text": "Locate an API that could assist me in developing a street view application that highlights trees and buildings within the given images. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet101', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet101', 'Mean IOU': 67.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 477, "text": "I want to segment an image of Orchard Parks Shopping Center. Suggest an API for semantic segmentation that can segment items in a shopping center. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_mobilenet_v3_large', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_mobilenet_v3_large', 'Mean IOU': 60.3, 'Global Pixelwise Accuracy': 91.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 478, "text": "Get me an API to generate new clothing designs based on a database of existing clothes. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks', 'api_name': 'DCGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='DCGAN', pretrained=True, useGPU=use_gpu)\", 'api_arguments': {'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': ['import torch', 'import matplotlib.pyplot as plt', 'import torchvision'], 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'generate_images': 'with torch.no_grad(): generated_images = model.test(noise)', 'plot_images': ['plt.imshow(torchvision.utils.make_grid(generated_images).permute(1, 2, 0).cpu().numpy())', 'plt.show()']}, 'performance': {'dataset': 'FashionGen', 'accuracy': 'N/A'}, 'description': 'DCGAN is a model designed in 2015 by Radford et. al. in the paper Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. It is a GAN architecture both very simple and efficient for low resolution image generation (up to 64x64).'}", "category": "generic"}
{"question_id": 479, "text": "A security company wants to create a project that involves object detection from the live video feed captured by their CCTV cameras. Propose an API that provides object detection in real time. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'YOLOv5', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='ultralytics/yolov5', model='yolov5s', pretrained=True)\", 'api_arguments': [\"'ultralytics/yolov5'\", \"'yolov5s'\", 'pretrained=True'], 'python_environment_requirements': 'Python>=3.8, PyTorch>=1.7', 'example_code': ['import torch', \"model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\", \"imgs = ['https://ultralytics.com/images/zidane.jpg']\", 'results = model(imgs)', 'results.print()', 'results.save()', 'results.xyxy[0]', 'results.pandas().xyxy[0]'], 'performance': {'dataset': 'COCO', 'accuracy': {'YOLOv5s6': {'mAPval0.5:0.95': 43.3, 'mAPtest0.5:0.95': 43.3, 'mAPval0.5': 61.9}, 'YOLOv5m6': {'mAPval0.5:0.95': 50.5, 'mAPtest0.5:0.95': 50.5, 'mAPval0.5': 68.7}, 'YOLOv5l6': {'mAPval0.5:0.95': 53.4, 'mAPtest0.5:0.95': 53.4, 'mAPval0.5': 71.1}, 'YOLOv5x6': {'mAPval0.5:0.95': 54.4, 'mAPtest0.5:0.95': 54.4, 'mAPval0.5': 72.0}, 'YOLOv5x6 TTA': {'mAPval0.5:0.95': 55.0, 'mAPtest0.5:0.95': 55.0, 'mAPval0.5': 72.0}}}, 'description': 'YOLOv5 is a family of compound-scaled object detection models trained on the COCO dataset, and includes simple functionality for Test Time Augmentation (TTA), model ensembling, hyperparameter evolution, and export to ONNX, CoreML and TFLite.'}", "category": "generic"}
{"question_id": 480, "text": "I want to build an app for social media that filters profiles that have sunglasses in the picture. Give me an API that can detect presence of sunglasses within a picture. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x16d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x16d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x16d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x16d': {'Top-1 Acc.': '84.2', 'Top-5 Acc.': '97.2'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 481, "text": "Suggest an API for automatically classifying images of road safety hazards such as potholes, damaged sidewalks, and obscured traffic signals for a road safety app. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x8d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x8d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x8d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x8d': {'Top-1 Acc.': '82.2', 'Top-5 Acc.': '96.4'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 482, "text": "Can you suggest an ML API capable of predicting whether a given image is a cat, dog or other animal with high accuracy? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x48d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x48d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x48d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x48d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x48d': {'Top-1 Acc.': '85.4', 'Top-5 Acc.': '97.6'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 483, "text": "A startup that sells clothing needs to build a computer vision model to classify their clothes to automate their warehouse. Could you recommend an API, that is useful in this scenario? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x32d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x32d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x32d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x32d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x32d': {'Top-1 Acc.': '85.1', 'Top-5 Acc.': '97.5'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 484, "text": "Recommend an API suitable for an image recognition task to classify different species of animals. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeXt101-32x4d', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resneXt', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'validators', 'matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', 'device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")', \"print(f'Using {device} for inference')\", \"resneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resneXt')\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resneXt.eval().to(device)', 'uris = [', \" 'http://images.cocodataset.org/test-stuff2017/000000024309.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000028117.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000006149.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000004954.jpg',\", ']', 'batch = torch.cat(', ' [utils.prepare_input_from_uri(uri) for uri in uris]', ').to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resneXt(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'IMAGENET', 'accuracy': 'Not provided'}, 'description': 'ResNeXt101-32x4d is a model introduced in the Aggregated Residual Transformations for Deep Neural Networks paper. It is based on regular ResNet model, substituting 3x3 convolutions inside the bottleneck block for 3x3 grouped convolutions. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures. It can be deployed for inference on the NVIDIA Triton Inference Server using TorchScript, ONNX Runtime or TensorRT as an execution backend.'}", "category": "generic"}
{"question_id": 485, "text": "A machine learning model is needed that can identify abnormalities in brain MRI scans. Recommend an API that could be used to train a model for this purpose. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Biomedical Image Segmentation', 'api_name': 'U-Net for brain MRI', 'api_call': \"torch.hub.load(repo_or_dir='mateuszbuda/brain-segmentation-pytorch', model='unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'api_arguments': {'in_channels': 3, 'out_channels': 1, 'init_features': 32, 'pretrained': True}, 'python_environment_requirements': ['torch', 'torchvision', 'numpy', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'import numpy as np', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'm, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))', 'preprocess = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=m, std=s)])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model = model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.round(output[0]))'], 'performance': {'dataset': 'kaggle.com/mateuszbuda/lgg-mri-segmentation'}, 'description': 'U-Net with batch normalization for biomedical image segmentation with pretrained weights for abnormality segmentation in brain MRI. The model comprises four levels of blocks containing two convolutional layers with batch normalization and ReLU activation function, and one max pooling layer in the encoding part and up-convolutional layers instead in the decoding part. The number of convolutional filters in each block is 32, 64, 128, and 256. The bottleneck layer has 512 convolutional filters. From the encoding layers, skip connections are used to the corresponding layers in the decoding part. Input image is a 3-channel brain MRI slice from pre-contrast, FLAIR, and post-contrast sequences, respectively. Output is a one-channel probability map of abnormality regions with the same size as the input image.'}", "category": "generic"}
{"question_id": 486, "text": "I want to create an album of generated paintings of famous landscapes. Provide me with an API that can generate such images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks (GANs)', 'api_name': 'PGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='PGAN', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'facebookresearch/pytorch_GAN_zoo:hub', 'model': 'PGAN', 'model_name': 'celebAHQ-512', 'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': 'import torch', 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'PGAN', model_name='celebAHQ-512', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'test': 'generated_images = model.test(noise)', 'plot_images': {'import_matplotlib': 'import matplotlib.pyplot as plt', 'import_torchvision': 'import torchvision', 'make_grid': 'grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1), scale_each=True, normalize=True)', 'imshow': 'plt.imshow(grid.permute(1, 2, 0).cpu().numpy())', 'show': 'plt.show()'}}, 'performance': {'dataset': 'celebA', 'accuracy': 'High-quality celebrity faces'}, 'description': \"Progressive Growing of GANs (PGAN) is a method for generating high-resolution images using generative adversarial networks. The model is trained progressively, starting with low-resolution images and gradually increasing the resolution until the desired output is achieved. This implementation is based on the paper by Tero Karras et al., 'Progressive Growing of GANs for Improved Quality, Stability, and Variation'.\"}", "category": "generic"}
{"question_id": 487, "text": "Suggest an API for classifying a large dataset of images into different categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'AlexNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='alexnet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 43.45, 'top-5_error': 20.91}}, 'description': 'AlexNet is a deep convolutional neural network that achieved a top-5 error of 15.3% in the 2012 ImageNet Large Scale Visual Recognition Challenge. The main contribution of the original paper was the depth of the model, which was computationally expensive but made feasible through the use of GPUs during training. The pretrained AlexNet model in PyTorch can be used for image classification tasks.'}", "category": "generic"}
{"question_id": 488, "text": "Find me an API that can classify the images given corresponding image URLs. It should be fast and efficient. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNet50', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['pip install validators matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", \"print(f'Using {device} for inference')\", \"resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resnet50.eval().to(device)', 'uris = [...]', 'batch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resnet50(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'ImageNet', 'accuracy': '~0.5% top1 improvement over ResNet50 v1'}, 'description': 'The ResNet50 v1.5 model is a modified version of the original ResNet50 v1 model. The difference between v1 and v1.5 is that, in the bottleneck blocks which requires downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate (~0.5% top1) than v1, but comes with a small performance drawback (~5% imgs/sec). The model is initialized as described in Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures.'}", "category": "generic"}
{"question_id": 489, "text": "I need to identify objects from a photo taken during a traffic scene, please provide me with an API call that can help in achieving this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SE-ResNeXt101', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_se_resnext101_32x4d', pretrained=True)\", 'api_arguments': 'N/A', 'python_environment_requirements': 'validators, matplotlib', 'example_code': \"import torch\\nfrom PIL import Image\\nimport torchvision.transforms as transforms\\nimport numpy as np\\nimport json\\nimport requests\\nimport matplotlib.pyplot as plt\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n%matplotlib inline\\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\nprint(f'Using {device} for inference')\\nresneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_se_resnext101_32x4d')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\nresneXt.eval().to(device)\\nuris = ['http://images.cocodataset.org/test-stuff2017/000000024309.jpg','http://images.cocodataset.org/test-stuff2017/000000028117.jpg','http://images.cocodataset.org/test-stuff2017/000000006149.jpg','http://images.cocodataset.org/test-stuff2017/000000004954.jpg']\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(resneXt(batch), dim=1)\\nresults = utils.pick_n_best(predictions=output, n=5)\\nfor uri, result in zip(uris, results):\\n img = Image.open(requests.get(uri, stream=True).raw)\\n img.thumbnail((256,256), Image.ANTIALIAS)\\n plt.imshow(img)\\n plt.show()\\n print(result)\", 'performance': {'dataset': 'IMAGENET', 'accuracy': 'N/A'}, 'description': 'The SE-ResNeXt101-32x4d is a ResNeXt101-32x4d model with added Squeeze-and-Excitation module. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures, which allows researchers to get results 3x faster than training without Tensor Cores while experiencing the benefits of mixed precision training.'}", "category": "generic"}
{"question_id": 490, "text": "I'm working on an application that converts text into speech. Tell me an API that can serve my purpose. \n Use this API documentation for reference: {'domain': 'Text-to-Speech', 'framework': 'PyTorch', 'functionality': 'Speech Synthesis', 'api_name': 'WaveGlow', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_waveglow', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_waveglow', 'model_math': 'fp32'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': {'load_waveglow_model': \"waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp32')\", 'prepare_waveglow_model': ['waveglow = waveglow.remove_weightnorm(waveglow)', \"waveglow = waveglow.to('cuda')\", 'waveglow.eval()'], 'load_tacotron2_model': \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp32')\", 'prepare_tacotron2_model': [\"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()'], 'synthesize_speech': ['text = \"hello world, I missed you so much\"', \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'save_audio': 'write(\"audio.wav\", rate, audio_numpy)', 'play_audio': 'Audio(audio_numpy, rate=rate)'}, 'performance': {'dataset': 'LJ Speech', 'accuracy': None}, 'description': 'The Tacotron 2 and WaveGlow model form a text-to-speech system that enables users to synthesize natural-sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 491, "text": "Which pre-trained model should I use for sentiment analysis of customer reviews on our website? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'RoBERTa', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq', model='roberta.large', pretrained=True)\", 'api_arguments': [\"'pytorch/fairseq'\", \"'roberta.large'\"], 'python_environment_requirements': ['regex', 'requests', 'hydra-core', 'omegaconf'], 'example_code': ['import torch', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\", 'roberta.eval()', \"tokens = roberta.encode('Hello world!')\", 'last_layer_features = roberta.extract_features(tokens)', 'all_layers = roberta.extract_features(tokens, return_all_hiddens=True)', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\", 'roberta.eval()', \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is not very optimized.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is based on BERT.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"roberta.register_classification_head('new_task', num_classes=3)\", \"logprobs = roberta.predict('new_task', tokens)\"], 'performance': {'dataset': 'MNLI', 'accuracy': 'N/A'}, 'description': \"RoBERTa is a robustly optimized version of BERT, a revolutionary self-supervised pretraining technique that learns to predict intentionally hidden (masked) sections of text. RoBERTa builds on BERT's language masking strategy and modifies key hyperparameters, including removing BERT's next-sentence pretraining objective, and training with much larger mini-batches and learning rates. RoBERTa was also trained on an order of magnitude more data than BERT, for a longer amount of time, allowing it to generalize even better to downstream tasks.\"}", "category": "generic"}
{"question_id": 492, "text": "I need to classify various images into pre-defined categories. Suggest me an API that can be utilized for image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet121', pretrained=True)\", 'api_arguments': [{'name': 'densenet121', 'type': 'str', 'description': 'Densenet-121 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet121': {'Top-1 error': 25.35, 'Top-5 error': 7.83}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 493, "text": "I am studying about vegetative cover in my college. Give me an API that can output segmented vegetation areas from a satellite image of a region. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet50', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet50': {'Mean IOU': 60.5, 'Global Pixelwise Accuracy': 91.4}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 494, "text": "I want to implement image classification based on DenseNet. Suggest an API that can classify images using DenseNet. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet161', pretrained=True)\", 'api_arguments': [{'name': 'densenet161', 'type': 'str', 'description': 'Densenet-161 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet161', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet161': {'Top-1 error': 22.35, 'Top-5 error': 6.2}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 495, "text": "An e-commerce company is building a recommendation system that relies on object classification. Please suggest an API for this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet201', pretrained=True)\", 'api_arguments': [{'name': 'densenet201', 'type': 'str', 'description': 'Densenet-201 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet201': {'Top-1 error': 22.8, 'Top-5 error': 6.43}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 496, "text": "A machine learning engineer building an image recognition system that filters cats and dogs. Give me an API that can classify whether an image is a cat or dog. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet169', pretrained=True)\", 'api_arguments': [{'name': 'densenet169', 'type': 'str', 'description': 'Densenet-169 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet169': {'Top-1 error': 24.0, 'Top-5 error': 7.0}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 497, "text": "Create a lightweight image classifier that performs well on a Raspberry Pi. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet39ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet39ds', 'type': 'str', 'description': 'HarDNet-39DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet39ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet39ds': {'Top-1 error': 27.92, 'Top-5 error': 9.57}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 498, "text": "I need an API to perform semantic segmentation on my images. Preferably a fully-convolutional network. What can you suggest? \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet101', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet101': {'Mean IOU': 63.7, 'Global Pixelwise Accuracy': 91.9}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 499, "text": "Recommend an API that is suitable for detecting the type of currency in an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'GoogLeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='googlenet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.0.0', 'torchvision': '>=0.2.2'}, 'example_code': {'import': ['import torch', 'import urllib', 'from PIL import Image', 'from torchvision import transforms'], 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\", 'model_eval': 'model.eval()', 'image_preprocessing': ['input_image = Image.open(filename)', 'preprocess = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'model_execution': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'output_processing': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'top5_prob, top5_catid = torch.topk(probabilities, 5)']}, 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 error': '30.22', 'Top-5 error': '10.47'}}, 'description': \"GoogLeNet is based on a deep convolutional neural network architecture codenamed 'Inception', which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014).\"}", "category": "generic"}
{"question_id": 500, "text": "Recommend a lightweight, efficient image classification model that can classify retail products by category. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68', 'type': 'str', 'description': 'HarDNet-68 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68': {'Top-1 error': 23.52, 'Top-5 error': 6.99}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory trafficCNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 501, "text": "I want a classifier that can recognize clothing items in images, taking into account the images may have different styles. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet50_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet50_ibn_a', 'type': 'str', 'description': 'ResNet-50-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet50_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet50_ibn_a': {'Top-1 acc': 77.46, 'Top-5 acc': 93.68}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 502, "text": "Recommend an API that can classify different types of plants from their images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet85', pretrained=True)\", 'api_arguments': [{'name': 'hardnet85', 'type': 'str', 'description': 'HarDNet-85 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet85', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet85': {'Top-1 error': 21.96, 'Top-5 error': 6.11}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 503, "text": "We are building a phone app for Intel Corporation which can detect various objects in an image. Can you help me with an API which can classify objects into different categories for given image? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Efficient networks by generating more features from cheap operations', 'api_name': 'GhostNet', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/ghostnet', model='ghostnet_1x', pretrained=True)\", 'api_arguments': ['pretrained'], 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/ghostnet', 'ghostnet_1x', pretrained=True)\", 'model.eval()', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 acc': '73.98', 'Top-5 acc': '91.46'}}, 'description': 'The GhostNet architecture is based on an Ghost module structure which generates more features from cheap operations. Based on a set of intrinsic feature maps, a series of cheap operations are applied to generate many ghost feature maps that could fully reveal information underlying intrinsic features. Experiments conducted on benchmarks demonstrate the superiority of GhostNet in terms of speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 504, "text": "Give me an API to create a model that can classify e-commerce products into categories like electronics, home, and fashion. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet101_ibn_a', 'type': 'str', 'description': 'ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet101_ibn_a': {'Top-1 acc': 78.61, 'Top-5 acc': 94.41}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 505, "text": "An e-commerce company is looking for an API to identify products in images for better recommendations on their app. Can you recommend an API that can perform this task? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnext101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_ibn_a', 'type': 'str', 'description': 'ResNeXt-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnext101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext101_ibn_a': {'Top-1 acc': 79.12, 'Top-5 acc': 94.58}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 506, "text": "Recommend an API best suited for an app that needs to recognize unknown persons in images \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='se_resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'se_resnet101_ibn_a', 'type': 'str', 'description': 'SE-ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'se_resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'se_resnet101_ibn_a': {'Top-1 acc': 78.75, 'Top-5 acc': 94.49}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 507, "text": "Design an image classifier for a phone manufacturer to identify inappropriate images from user gallery and flag them. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest50', pretrained=True)\", 'api_arguments': 'resnest50', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-50': 81.03}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 508, "text": "Recommend an image classification API that performs state-of-the-art performance for a mobile app. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest200', pretrained=True)\", 'api_arguments': 'resnest200', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest200', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-200': 83.84}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 509, "text": "Provide an API for classifying images of fruits in a retail store. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest101', pretrained=True)\", 'api_arguments': 'resnest101', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-101': 82.83}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 510, "text": "Let's say I've created an app for birdwatchers to recognize birds in the images they take. Recommend me a high-performance image recognition API that would be ideal to use for my app. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'Inception_v3', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='inception_v3', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '1.9.0', 'torchvision': '0.10.0'}, 'example_code': {'import_libraries': 'import torch', 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\", 'model_evaluation': 'model.eval()'}, 'performance': {'dataset': 'imagenet', 'accuracy': {'top-1_error': 22.55, 'top-5_error': 6.44}}, 'description': 'Inception v3, also called GoogleNetv3, is a famous Convolutional Neural Network trained on the ImageNet dataset from 2015. It is based on the exploration of ways to scale up networks to utilize the added computation as efficiently as possible by using suitably factorized convolutions and aggressive regularization. The model achieves a top-1 error of 22.55% and a top-5 error of 6.44% on the ImageNet dataset.'}", "category": "generic"}
{"question_id": 511, "text": "I am a Machine Learning Engineer at Pinterest and I need an API to classify images. Suggest an efficient API. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest269', pretrained=True)\", 'api_arguments': 'resnest269', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest269', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-269': 84.54}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 512, "text": "I have a limited computational budget for image classification tasks. Suggest an API optimized for CPU performance. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_cpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_cpu', 'type': 'str', 'description': 'ProxylessNAS optimized for CPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_cpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_cpu', 'accuracy': 75.3}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 513, "text": "Can you recommend an API for a mobile app developer who wants lightweight and fast image classification on their app? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_mobile', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_mobile', 'type': 'str', 'description': 'ProxylessNAS optimized for Mobile'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_mobile'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_mobile', 'accuracy': 74.6}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 514, "text": "Develop an image classifier that can identify objects in an image. Provide an API example to load a pretrained classifier model. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet18', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet18', 'top-1_error': 30.24, 'top-5_error': 10.92}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 515, "text": "I want to analyze the objects within my images taken from my phone to use it in my machine learning dataset, suggest me an API that is best suited for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MobileNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='mobilenet_v2', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 28.12, 'top-5_error': 9.71}}, 'description': 'The MobileNet v2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input. MobileNet v2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, non-linearities in the narrow layers were removed in order to maintain representational power.'}", "category": "generic"}
{"question_id": 516, "text": "How can a botanist distinguish between different plant species using an API based on deep residual networks? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet34', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet34', 'top-1_error': 26.7, 'top-5_error': 8.58}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 517, "text": "A new dating app wants to analyze its user's images to determine if the user is an authentic account or an impersonator. Give me an example of API that can help differentiate between real profile images and fake one. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_gpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_gpu', 'type': 'str', 'description': 'ProxylessNAS optimized for GPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_gpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_gpu', 'accuracy': 75.1}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 518, "text": "Many image web services need an efficient image recognition model. Can you provide an API that uses deep residual networks for image classification? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet50', 'top-1_error': 23.85, 'top-5_error': 7.13}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 519, "text": "I'm designing an automatic image moderation system for my social platform. Recommend an API for classifying images into different categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet101', 'top-1_error': 22.63, 'top-5_error': 6.44}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 520, "text": "I require an API that facilitates image classification of various breeds of dogs. Can you recommend an appropriate one? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet152', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet152', 'top-1_error': 21.69, 'top-5_error': 5.94}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 521, "text": "I have a set of pictures of birds and I want to put them in categories based on their species. What API can I use to classify these images based on their content? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext50_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext50_32x4d': {'top-1': 22.38, 'top-5': 6.3}}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 522, "text": "Develop an API to categorize animals from a given image into classes such as mammals, birds, reptiles, and amphibians. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext101_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext101_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'resnext101_32x8d': {'top-1': 20.69, 'top-5': 5.47}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 523, "text": "Can you tell me about an API that can give me powerful image classification capabilities for a mobile app? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_s', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_s', 'type': 'str', 'description': 'SNNMLP Small model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_s', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Small', 'top-1': 83.3}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 524, "text": "Let's use a neural network to classify a given image. Recommend an API for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_t', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_t', 'type': 'str', 'description': 'SNNMLP Tiny model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_t', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Tiny', 'top-1': 81.88}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 525, "text": "I work at a camera manufacturing company, and we want an API that will help our camera to identify and classify images. Ideally, the API should be based on deep learning techniques. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_b', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_b', 'type': 'str', 'description': 'SNNMLP Base model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_b', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Base', 'top-1': 85.59}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 526, "text": "In the process of automating image classification for a product recognition tool, provide me with an API that can effectively sort categorized images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_0', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_0'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_0': {'Top-1 error': 41.9, 'Top-5 error': 19.58}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 527, "text": "\"An image from my friend's vacation album needs to be categorized without any further information. Give me an API that can classify the content of the image.\" \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_1', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_1'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_1': {'Top-1 error': 41.81, 'Top-5 error': 19.38}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 528, "text": "A smartphone company wants to implement image classification for their mobile camera app. Provide an API that can identify objects in a given image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ShuffleNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='shufflenet_v2_x1_0', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'torch', 'torchvision': 'torchvision', 'PIL': 'Image', 'urllib': 'urllib'}, 'example_code': {'import_libraries': ['import torch', 'from PIL import Image', 'from torchvision import transforms', 'import urllib'], 'load_model': [\"model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\", 'model.eval()'], 'load_image': [\"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'try: urllib.URLopener().retrieve(url, filename)', 'except: urllib.request.urlretrieve(url, filename)', 'input_image = Image.open(filename)'], 'preprocess_image': ['preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'run_inference': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'get_probabilities': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'top_categories': ['top5_prob, top5_catid = torch.topk(probabilities, 5)', 'for i in range(top5_prob.size(0)):', ' print(categories[top5_catid[i]], top5_prob[i].item())']}, 'performance': {'dataset': 'Imagenet', 'accuracy': {'top-1_error': 30.64, 'top-5_error': 11.68}}, 'description': 'ShuffleNet V2 is an efficient ConvNet optimized for speed and memory, pre-trained on Imagenet. It is designed based on practical guidelines for efficient network design, including speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 529, "text": "What API can help us recognize objects in photographs? Share the code snippet as well. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11', pretrained=True)\", 'api_arguments': [{'name': 'vgg11', 'type': 'str', 'description': 'VGG11 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11': {'Top-1 error': 30.98, 'Top-5 error': 11.37}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 530, "text": "Develop an API for classifying images of cars into brands based on a pretrained model. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg11_bn', 'type': 'str', 'description': 'VGG11 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11_bn': {'Top-1 error': 26.7, 'Top-5 error': 8.58}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 531, "text": "Recommend an API that can help a wildlife photographer to identify animals from their photos. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13', pretrained=True)\", 'api_arguments': [{'name': 'vgg13', 'type': 'str', 'description': 'VGG13 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13': {'Top-1 error': 30.07, 'Top-5 error': 10.75}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn,vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 532, "text": "I am a programmer who is interested in building a photo application that recognizes plants using camera feed. Recommend me an API and some sample code to achieve this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg13_bn', 'type': 'str', 'description': 'VGG13 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13_bn': {'Top-1 error': 28.45, 'Top-5 error': 9.63}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 533, "text": "Use an API that can recognize objects in an image for labelling and annotation purposes. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16', pretrained=True)\", 'api_arguments': [{'name': 'vgg16', 'type': 'str', 'description': 'VGG16 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16': {'Top-1 error': 28.41, 'Top-5 error': 9.62}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 534, "text": "Recommend an API that can be used to build an image recognition app for automating car insurance claim process. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg16_bn', 'type': 'str', 'description': 'VGG16 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16_bn': {'Top-1 error': 26.63, 'Top-5 error': 8.5}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 535, "text": "I want to recognize objects present in a given image. Is there an API that can help me in this task? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg19_bn', 'type': 'str', 'description': 'VGG19 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19_bn': {'Top-1 error': 25.76, 'Top-5 error': 8.15}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 536, "text": "Recommend an API that can recognize objects in photos, specifically the VGG19 model, and provide code to load the pretrained version of the model. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19', pretrained=True)\", 'api_arguments': [{'name': 'vgg19', 'type': 'str', 'description': 'VGG19 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19': {'Top-1 error': 27.62, 'Top-5 error': 9.12}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 537, "text": "Propose a model that can be used to identify different bird species from images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet50_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet50_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet50_2': {'Top-1 error': 21.49, 'Top-5 error': 5.91}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 538, "text": "An android developer is building an application with image recognition features for museum visits. Find an API so that they can classify images taken during those visits. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet101_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet101_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet101_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet101_2': {'Top-1 error': 21.16, 'Top-5 error': 5.72}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 539, "text": "Can you suggest an API to help identify different physical activities from short video clips? \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'X3D Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='x3d_s', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'x3d_s', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_s', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 73.33, 'top5': 91.27}, 'flops': 2.96, 'params': 3.79}, 'description': \"X3D model architectures are based on the paper 'X3D: Expanding Architectures for Efficient Video Recognition' by Christoph Feichtenhofer. They are pretrained on the Kinetics 400 dataset. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 540, "text": "Find an API that works with street camera videos and classifies the type of actions happening in the video. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'SlowFast Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slowfast_r50', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'slowfast_r50', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 76.94, 'top5': 92.69}, 'flops': 65.71, 'params': 34.57}, 'description': \"Slow Fast model architectures are based on the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al. They are pretrained on the Kinetics 400 dataset using the 8x8 setting. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 541, "text": "I am a developer at OpenAI and I am building a small-scale chatbot that can conduct conversation in English text input. Can you find me an API that is suitable for the job? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Natural Language Processing', 'api_name': 'PyTorch-Transformers', 'api_call': \"torch.hub.load(repo_or_dir='huggingface/pytorch-transformers')\", 'api_arguments': ['pretrained_model_or_path', 'output_attention', 'output_hidden_states', 'config', 'from_tf'], 'python_environment_requirements': ['tqdm', 'boto3', 'requests', 'regex', 'sentencepiece', 'sacremoses'], 'example_code': 'import torch\\ntokenizer = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'tokenizer\\', \\'bert-base-cased\\')\\n\\ntext_1 = \"Jim Henson was a puppeteer\"\\ntext_2 = \"Who was Jim Henson ?\"\\n\\nindexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\\n\\nmodel = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'model\\', \\'bert-base-cased\\')\\n\\nwith torch.no_grad():\\n encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)', 'performance': {'dataset': [{'name': 'MRPC', 'accuracy': 'Not provided'}]}, 'description': 'PyTorch-Transformers is a library of state-of-the-art pre-trained models for Natural Language Processing (NLP) including BERT, GPT, GPT-2, Transformer-XL, XLNet, XLM, RoBERTa, and DistilBERT. The library provides functionality for tokenization, configuration, and various model architectures for different tasks such as causal language modeling, sequence classification, question answering, and masked language modeling.'}", "category": "generic"}
{"question_id": 542, "text": "A foundation wants to automatically categorize plant species from leaf images taken in a field. Give me an API for classifying different types of plant species based on identification and characterization of leaves. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Once-for-all (OFA) Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/once-for-all', model='ofa_supernet_mbv3_w10', pretrained=True)\", 'api_arguments': {'repository': 'mit-han-lab/once-for-all', 'model': 'ofa_supernet_mbv3_w10', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"super_net_name = 'ofa_supernet_mbv3_w10'\", \"super_net = torch.hub.load('mit-han-lab/once-for-all', super_net_name, pretrained=True).eval()\"], 'performance': {'description': 'OFA networks outperform state-of-the-art NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x faster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency) while reducing many orders of magnitude GPU hours and CO2 emission.'}, 'description': 'Once-for-all (OFA) networks are a family of neural networks designed by MIT Han Lab. They decouple training and search, achieving efficient inference across various edge devices and resource constraints. OFA networks are pretrained on the IMAGENET dataset and are capable of classifying images into different categories.'}", "category": "generic"}
{"question_id": 543, "text": "A research team is building a new categories labels system for an image dataset. What is an API that can do image classification for them? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Semi-supervised and semi-weakly supervised ImageNet Models', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/semi-supervised-ImageNet1K-models', model='resnet18_swsl', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/semi-supervised-ImageNet1K-models', 'model': 'resnet18_swsl', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl', pretrained=True)\", 'model.eval()'], 'performance': {'description': 'Semi-supervised and semi-weakly supervised ImageNet models achieve state-of-the-art accuracy of 81.2% on ImageNet for the widely used/adopted ResNet-50 model architecture.'}, 'description': \"Semi-supervised and semi-weakly supervised ImageNet Models are introduced in the 'Billion scale semi-supervised learning for image classification' paper. These models are pretrained on a subset of unlabeled YFCC100M public image dataset and fine-tuned with the ImageNet1K training dataset. They are capable of classifying images into different categories and are provided by the Facebook Research library.\"}", "category": "generic"}
{"question_id": 544, "text": "A team needs an image classifier for building a media cataloguing system optimized for NVIDIA hardware. Give me an API using GPUs that can classify images into categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'GPUNet Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", 'api_arguments': {'repository': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_gpunet', 'pretrained': 'True', 'model_type': 'GPUNet-0', 'model_math': 'fp32'}, 'python_environment_requirements': ['torch', 'validators', 'matplotlib', 'timm==0.5.4'], 'example_code': ['import torch', \"model_type = 'GPUNet-0'\", \"precision = 'fp32'\", \"gpunet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'gpunet.to(device)', 'gpunet.eval()'], 'performance': {'dataset': 'IMAGENET', 'description': 'GPUNet demonstrates state-of-the-art inference performance up to 2x faster than EfficientNet-X and FBNet-V3.'}, 'description': 'GPUNet is a family of Convolutional Neural Networks designed by NVIDIA using novel Neural Architecture Search (NAS) methods. They are optimized for NVIDIA GPU and TensorRT performance. GPUNet models are pretrained on the IMAGENET dataset and are capable of classifying images into different categories. The models are provided by the NVIDIA Deep Learning Examples library.'}", "category": "generic"}
{"question_id": 545, "text": "I need an API for translating an English paragraph to French, perfect candidate should support large-scale semi-supervised training and back-translation. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Neural Machine Translation', 'api_name': 'Transformer (NMT)', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq')\", 'api_arguments': ['model_name', 'tokenizer', 'bpe', 'beam', 'sampling', 'sampling_topk'], 'python_environment_requirements': ['bitarray', 'fastBPE', 'hydra-core', 'omegaconf', 'regex', 'requests', 'sacremoses', 'subword_nmt'], 'example_code': \"import torch\\n\\nen2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\\n\\nen2fr.cuda()\\n\\nfr = en2fr.translate('Hello world!', beam=5)\\nassert fr == 'Bonjour \u00e0 tous !'\", 'performance': {'dataset': [{'name': \"WMT'14\", 'accuracy': 'Not provided'}, {'name': \"WMT'18\", 'accuracy': 'Not provided'}, {'name': \"WMT'19\", 'accuracy': 'Not provided'}]}, 'description': \"Transformer (NMT) is a powerful sequence-to-sequence modeling architecture that produces state-of-the-art neural machine translation systems. It is based on the paper 'Attention Is All You Need' and has been improved using techniques such as large-scale semi-supervised training, back-translation, and noisy-channel reranking. It supports English-French and English-German translation as well as round-trip translation for paraphrasing.\"}", "category": "generic"}
{"question_id": 546, "text": "Design an image recognition software for identifying food items on social media. Suggest an API with pretrained model for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'EfficientNet', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_efficientnet_b0', pretrained=True)\", 'api_arguments': ['model_name', 'pretrained'], 'python_environment_requirements': ['validators', 'matplotlib'], 'example_code': \"import torch\\n\\nefficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\n\\nefficientnet.eval().to(device)\\n\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\n\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(efficientnet(batch), dim=1)\\n \\nresults = utils.pick_n_best(predictions=output, n=5)\", 'performance': {'dataset': {'name': 'IMAGENET', 'accuracy': 'Not provided'}}, 'description': 'EfficientNet is a family of image classification models that achieve state-of-the-art accuracy while being smaller and faster. The models are trained with mixed precision using Tensor Cores on the NVIDIA Volta and Ampere GPU architectures. The EfficientNet models include EfficientNet-B0, EfficientNet-B4, EfficientNet-WideSE-B0, and EfficientNet-WideSE-B4. The WideSE models use wider Squeeze-and-Excitation layers than the original EfficientNet models, resulting in slightly better accuracy.'}", "category": "generic"}
{"question_id": 547, "text": "I am trying to implement a drone surveillance system with intruders detection using a camera system. Suggest me an API capable of performing object detections for my drone's inbuilt camera. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Single Shot MultiBox Detector', 'api_name': 'SSD', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_ssd', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['numpy', 'scipy', 'scikit-image', 'matplotlib'], 'example_code': \"import torch\\n\\nssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\\n\\nssd_model.to('cuda')\\nssd_model.eval()\\n\\ninputs = [utils.prepare_input(uri) for uri in uris]\\ntensor = utils.prepare_tensor(inputs)\\n\\nwith torch.no_grad():\\n detections_batch = ssd_model(tensor)\\n\\nresults_per_input = utils.decode_results(detections_batch)\\nbest_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\", 'performance': {'dataset': {'name': 'COCO', 'accuracy': 'Not provided'}}, 'description': \"The SSD (Single Shot MultiBox Detector) model is an object detection model based on the paper 'SSD: Single Shot MultiBox Detector'. It uses a deep neural network for detecting objects in images. This implementation replaces the obsolete VGG model backbone with the more modern ResNet-50 model. The SSD model is trained on the COCO dataset and can be used to detect objects in images with high accuracy and efficiency.\"}", "category": "generic"}
{"question_id": 548, "text": "I am working on a text-to-speech project for my company. Can you suggest an ML API to convert text into human-like speech? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Text-to-Speech', 'api_name': 'Tacotron 2', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_tacotron2', model_math='fp16')\", 'api_arguments': {'model_math': 'fp16'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': ['import torch', \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\", \"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()', \"text = 'Hello world, I missed you so much.'\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'performance': {'dataset': 'LJ Speech', 'accuracy': 'Not specified'}, 'description': 'The Tacotron 2 model generates mel spectrograms from input text using an encoder-decoder architecture, and it is designed for generating natural-sounding speech from raw transcripts without any additional prosody information. This implementation uses Dropout instead of Zoneout to regularize the LSTM layers. The WaveGlow model (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 549, "text": "Generate classified output using the pretrained MEAL V2 model for object classification for an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V1', model='mealv1_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv1_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V1 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '78.21', 'top5': '94.01'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 550, "text": "We are developing an image recognition system for our security camera at the entrance of our building. What kind of API is suitable for this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.67', 'top5': '95.09'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 551, "text": "I'm working on an app for animal identification from images, and I need an API to classify animal species from images. Suggest an API for that. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_cutmix', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_cutmix'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 + CutMix w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.98', 'top5': '95.35'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 552, "text": "Can you please recommend an AI model that can identify animals in photos with more than 80% accuracy? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_380x380', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_380x380'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '380', 'parameters': '25.6M', 'top1': '81.72', 'top5': '95.81'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 553, "text": "Provide an API that can identify objects in an image with an accuracy of 80% or higher on the ImageNet dataset. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_075', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_075'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 0.75', 'resolution': '224', 'parameters': '2.04M', 'top1': '67.60', 'top5': '87.23'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 554, "text": "Describe an API specialized for image classification without employing known common tricks. Include the API repository and model name. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 1.0', 'resolution': '224', 'parameters': '2.54M', 'top1': '69.65', 'top5': '88.71'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 555, "text": "A deepfake inspector company would like to classify the authenticity of a video. Suggest me an API that will classify if the video is deepfake or original. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorch', 'functionality': '3D ResNet', 'api_name': 'slow_r50', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slow_r50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'json', 'urllib', 'pytorchvideo', 'torchvision', 'torchaudio', 'torchtext', 'torcharrow', 'TorchData', 'TorchRec', 'TorchServe', 'PyTorch on XLA Devices'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top_1': 74.58, 'top_5': 91.63}, 'Flops (G)': 54.52, 'Params (M)': 32.45}, 'description': \"The 3D ResNet model is a Resnet-style video classification network pretrained on the Kinetics 400 dataset. It is based on the architecture from the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al.\"}", "category": "generic"}
{"question_id": 556, "text": "Find me a state-of-the-art pretrained image classifier from a model that does not rely on additional tricks.  \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_efficientnet_b0', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_efficientnet_b0'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ EfficientNet-B0', 'resolution': '224', 'parameters': '5.29M', 'top1': '78.29', 'top5': '93.95'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 557, "text": "I want to create an app that recognizes dog breeds in images. Please help me identify a suitable API for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenet_v3_large_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenet_v3_large_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Large 1.0', 'resolution': '224', 'parameters': '5.48M', 'top1': '76.92', 'top5': '93.32'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 558, "text": "Obtain information on a machine learning API capable of detecting objects, drivable areas, and lanes in traffic images, such as those from a self-driving car's camera feed. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Traffic Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'HybridNets', 'api_call': \"torch.hub.load(repo_or_dir='datvuthanh/hybridnets', model='hybridnets', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'Python>=3.7, PyTorch>=1.10', 'example_code': \"import torch\\nmodel = torch.hub.load('datvuthanh/hybridnets', 'hybridnets', pretrained=True)\\nimg = torch.randn(1,3,640,384)\\nfeatures, regression, classification, anchors, segmentation = model(img)\", 'performance': {'dataset': [{'name': 'BDD100K', 'accuracy': {'Traffic Object Detection': {'Recall (%)': 92.8, 'mAP@0.5 (%)': 77.3}, 'Drivable Area Segmentation': {'Drivable mIoU (%)': 90.5}, 'Lane Line Detection': {'Accuracy (%)': 85.4, 'Lane Line IoU (%)': 31.6}}}]}, 'description': 'HybridNets is an end2end perception network for multi-tasks. Our work focused on traffic object detection, drivable area segmentation and lane detection. HybridNets can run real-time on embedded systems, and obtains SOTA Object Detection, Lane Detection on BDD100K Dataset.'}", "category": "generic"}
{"question_id": 559, "text": "I work for a self-driving car company and we need an API to perform simultaneous object detection, drivable area segmentation, and lane detection in images taken from vehicle cameras. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'YOLOP', 'api_call': \"torch.hub.load(repo_or_dir='hustvl/yolop', model='yolop', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'pip install -qr https://github.com/hustvl/YOLOP/blob/main/requirements.txt', 'example_code': \"import torch\\nmodel = torch.hub.load('hustvl/yolop', 'yolop', pretrained=True)\\nimg = torch.randn(1,3,640,640)\\ndet_out, da_seg_out,ll_seg_out = model(img)\", 'performance': {'dataset': 'BDD100K', 'accuracy': {'Object Detection': {'Recall(%)': 89.2, 'mAP50(%)': 76.5, 'Speed(fps)': 41}, 'Drivable Area Segmentation': {'mIOU(%)': 91.5, 'Speed(fps)': 41}, 'Lane Detection': {'mIOU(%)': 70.5, 'IOU(%)': 26.2}}}, 'description': 'YOLOP is an efficient multi-task network that can jointly handle three crucial tasks in autonomous driving: object detection, drivable area segmentation and lane detection. And it is also the first to reach real-time on embedded devices while maintaining state-of-the-art level performance on the BDD100K dataset.'}", "category": "generic"}
{"question_id": 560, "text": "I want to get the relative depth information from a single image taken in a forest. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Large', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Large')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 561, "text": "As a game developer working on a VR simulation, I want a technology that can predict relative depth of an object in an image. Provide me with a suitable API to achieve this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Hybrid', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Hybrid')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 562, "text": "Spotify wants to separate vocals from a song. Suggest an API that can separate vocals from an audio file. \n Use this API documentation for reference: {'domain': 'Audio Separation', 'framework': 'PyTorch', 'functionality': 'Music Source Separation', 'api_name': 'Open-Unmix', 'api_call': \"torch.hub.load(repo_or_dir='sigsep/open-unmix-pytorch', model='umxhq', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['PyTorch >=1.6.0', 'torchaudio'], 'example_code': ['import torch', \"separator = torch.hub.load('sigsep/open-unmix-pytorch', 'umxhq')\", 'audio = torch.rand((1, 2, 100000))', 'original_sample_rate = separator.sample_rate', 'estimates = separator(audio)'], 'performance': {'dataset': 'MUSDB18', 'accuracy': 'N/A'}, 'description': 'Open-Unmix provides ready-to-use models that allow users to separate pop music into four stems: vocals, drums, bass and the remaining other instruments. The models were pre-trained on the freely available MUSDB18 dataset.'}", "category": "generic"}
{"question_id": 563, "text": "Let's say I have an image of a cityscape and I want to determine the relative depth of different objects within the image. Which API can help me do that? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='MiDaS_small', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 564, "text": "Identify an API that can transcribe a voice message to written text. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Speech-To-Text', 'api_name': 'Silero Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_stt', 'language': ['en', 'de', 'es'], 'device': 'device'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf soundfile'], 'example_code': ['import torch', 'import zipfile', 'import torchaudio', 'from glob import glob', \"device = torch.device('cpu')\", \"model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', language='en', device=device)\", '(read_batch, split_into_batches, read_audio, prepare_model_input) = utils', \"torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav', dst ='speech_orig.wav', progress=True)\", \"test_files = glob('speech_orig.wav')\", 'batches = split_into_batches(test_files, batch_size=10)', 'input = prepare_model_input(read_batch(batches[0]), device=device)', 'output = model(input)', 'for example in output:', ' print(decoder(example.cpu()))'], 'performance': {'dataset': 'Open-STT', 'accuracy': 'See the wiki for quality and performance benchmarks'}, 'description': 'Silero Speech-To-Text models provide enterprise grade STT in a compact form-factor for several commonly spoken languages. The models are robust to a variety of dialects, codecs, domains, noises, and lower sampling rates. They consume a normalized audio in the form of samples and output frames with token probabilities. A decoder utility is provided for simplicity.'}", "category": "generic"}
{"question_id": 565, "text": "A wildlife photographer wants to identify bird species from his bird photos. Suggest an API capable of recognizing bird species from an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Fine-grained image classifier', 'api_name': 'ntsnet', 'api_call': \"torch.hub.load(repo_or_dir='nicolalandro/ntsnet-cub200', model='ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\", 'api_arguments': {'pretrained': 'True', 'topN': '6', 'device': 'cpu', 'num_classes': '200'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': \"from torchvision import transforms\\nimport torch\\nimport urllib\\nfrom PIL import Image\\n\\ntransform_test = transforms.Compose([\\n transforms.Resize((600, 600), Image.BILINEAR),\\n transforms.CenterCrop((448, 448)),\\n transforms.ToTensor(),\\n transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\\n])\\n\\nmodel = torch.hub.load('nicolalandro/ntsnet-cub200', 'ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\\nmodel.eval()\\n\\nurl = 'https://raw.githubusercontent.com/nicolalandro/ntsnet-cub200/master/images/nts-net.png'\\nimg = Image.open(urllib.request.urlopen(url))\\nscaled_img = transform_test(img)\\ntorch_images = scaled_img.unsqueeze(0)\\n\\nwith torch.no_grad():\\n top_n_coordinates, concat_out, raw_logits, concat_logits, part_logits, top_n_index, top_n_prob = model(torch_images)\\n\\n_, predict = torch.max(concat_logits, 1)\\npred_id = predict.item()\\nprint('bird class:', model.bird_classes[pred_id])\", 'performance': {'dataset': 'CUB200 2011', 'accuracy': 'Not provided'}, 'description': 'This is an nts-net pretrained with CUB200 2011 dataset, which is a fine-grained dataset of birds species.'}", "category": "generic"}
{"question_id": 566, "text": "Identify the segments with speech from an audio file using an API. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Voice Activity Detection', 'api_name': 'Silero Voice Activity Detector', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-vad', 'model': 'silero_vad', 'force_reload': 'True'}, 'python_environment_requirements': {'torchaudio': 'pip install -q torchaudio'}, 'example_code': {'import': ['import torch', 'torch.set_num_threads(1)', 'from IPython.display import Audio', 'from pprint import pprint'], 'download_example': \"torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\", 'load_model': \"model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'load_utils': '(get_speech_timestamps, _, read_audio, _) = utils', 'set_sampling_rate': 'sampling_rate = 16000', 'read_audio': \"wav = read_audio('en_example.wav', sampling_rate=sampling_rate)\", 'get_speech_timestamps': 'speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sampling_rate)', 'print_speech_timestamps': 'pprint(speech_timestamps)'}, 'performance': {'dataset': '', 'accuracy': ''}, 'description': 'Silero VAD is a pre-trained enterprise-grade Voice Activity Detector (VAD) that aims to provide a high-quality and modern alternative to the WebRTC Voice Activity Detector. The model is optimized for performance on 1 CPU thread and is quantized.'}", "category": "generic"}
{"question_id": 567, "text": "I want to build a robot that recognize objects in the street. Provide me an API that can segment objects in an image. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet50', 'Mean IOU': 66.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 568, "text": "I need to convert text to speech mp3 format with natural sounding voices. Can you find me an API that can do that? \n Use this API documentation for reference: {'domain': 'Text-To-Speech', 'framework': 'PyTorch', 'functionality': 'Text-To-Speech', 'api_name': 'Silero Text-To-Speech Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_tts', 'language': 'language', 'speaker': 'speaker'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf'], 'example_code': \"import torch\\nlanguage = 'en'\\nspeaker = 'lj_16khz'\\ndevice = torch.device('cpu')\\nmodel, symbols, sample_rate, example_text, apply_tts = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', language=language, speaker=speaker)\\nmodel = model.to(device)\\naudio = apply_tts(texts=[example_text], model=model, sample_rate=sample_rate, symbols=symbols, device=device)\", 'performance': {'dataset': [{'language': 'Russian', 'speakers': 6}, {'language': 'English', 'speakers': 1}, {'language': 'German', 'speakers': 1}, {'language': 'Spanish', 'speakers': 1}, {'language': 'French', 'speakers': 1}], 'accuracy': 'High throughput on slow hardware. Decent performance on one CPU thread'}, 'description': 'Silero Text-To-Speech models provide enterprise grade TTS in a compact form-factor for several commonly spoken languages. They offer one-line usage, naturally sounding speech, no GPU or training required, minimalism and lack of dependencies, a library of voices in many languages, support for 16kHz and 8kHz out of the box.'}", "category": "generic"}
{"question_id": 569, "text": "Our company wants to segment images into multiple classes. Suggest an API for semantic segmentation. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet101', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet101', 'Mean IOU': 67.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 570, "text": "I need a semantic segmentation model to segment different objects present in road scene images. Suggest me an API for this purpose. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_mobilenet_v3_large', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_mobilenet_v3_large', 'Mean IOU': 60.3, 'Global Pixelwise Accuracy': 91.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 571, "text": "What API can I use to detect objects in an image while maintaining a small model size for a mobile application? \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'YOLOv5', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='ultralytics/yolov5', model='yolov5s', pretrained=True)\", 'api_arguments': [\"'ultralytics/yolov5'\", \"'yolov5s'\", 'pretrained=True'], 'python_environment_requirements': 'Python>=3.8, PyTorch>=1.7', 'example_code': ['import torch', \"model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\", \"imgs = ['https://ultralytics.com/images/zidane.jpg']\", 'results = model(imgs)', 'results.print()', 'results.save()', 'results.xyxy[0]', 'results.pandas().xyxy[0]'], 'performance': {'dataset': 'COCO', 'accuracy': {'YOLOv5s6': {'mAPval0.5:0.95': 43.3, 'mAPtest0.5:0.95': 43.3, 'mAPval0.5': 61.9}, 'YOLOv5m6': {'mAPval0.5:0.95': 50.5, 'mAPtest0.5:0.95': 50.5, 'mAPval0.5': 68.7}, 'YOLOv5l6': {'mAPval0.5:0.95': 53.4, 'mAPtest0.5:0.95': 53.4, 'mAPval0.5': 71.1}, 'YOLOv5x6': {'mAPval0.5:0.95': 54.4, 'mAPtest0.5:0.95': 54.4, 'mAPval0.5': 72.0}, 'YOLOv5x6 TTA': {'mAPval0.5:0.95': 55.0, 'mAPtest0.5:0.95': 55.0, 'mAPval0.5': 72.0}}}, 'description': 'YOLOv5 is a family of compound-scaled object detection models trained on the COCO dataset, and includes simple functionality for Test Time Augmentation (TTA), model ensembling, hyperparameter evolution, and export to ONNX, CoreML and TFLite.'}", "category": "generic"}
{"question_id": 572, "text": "Develop a system to automatically tag images based on their content for a social media platform. Which API is suitable to be used for this task? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x8d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x8d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x8d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x8d': {'Top-1 Acc.': '82.2', 'Top-5 Acc.': '96.4'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 573, "text": "I am designing clothing for a new fashion line and need inspiration. Provide an API that can generate clothing images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks', 'api_name': 'DCGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='DCGAN', pretrained=True, useGPU=use_gpu)\", 'api_arguments': {'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': ['import torch', 'import matplotlib.pyplot as plt', 'import torchvision'], 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'generate_images': 'with torch.no_grad(): generated_images = model.test(noise)', 'plot_images': ['plt.imshow(torchvision.utils.make_grid(generated_images).permute(1, 2, 0).cpu().numpy())', 'plt.show()']}, 'performance': {'dataset': 'FashionGen', 'accuracy': 'N/A'}, 'description': 'DCGAN is a model designed in 2015 by Radford et. al. in the paper Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. It is a GAN architecture both very simple and efficient for low resolution image generation (up to 64x64).'}", "category": "generic"}
{"question_id": 574, "text": "I need an API that can classify a given image into one of the 1000 classes like cars, dogs or flowers. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x32d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x32d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x32d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x32d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x32d': {'Top-1 Acc.': '85.1', 'Top-5 Acc.': '97.5'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 575, "text": "I want to classify images using a high-performance machine learning model. Point me to an API that can help achieve this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x16d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x16d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x16d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x16d': {'Top-1 Acc.': '84.2', 'Top-5 Acc.': '97.2'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 576, "text": "Design an API that can classify images into different categories using a pretrained model. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x48d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x48d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x48d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x48d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x48d': {'Top-1 Acc.': '85.4', 'Top-5 Acc.': '97.6'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 577, "text": "I am working on an app that generates unique user avatars. I need an API that creates realistic images of faces. Provide me with the API details and pre-trained model if available. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks (GANs)', 'api_name': 'PGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='PGAN', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'facebookresearch/pytorch_GAN_zoo:hub', 'model': 'PGAN', 'model_name': 'celebAHQ-512', 'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': 'import torch', 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'PGAN', model_name='celebAHQ-512', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'test': 'generated_images = model.test(noise)', 'plot_images': {'import_matplotlib': 'import matplotlib.pyplot as plt', 'import_torchvision': 'import torchvision', 'make_grid': 'grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1), scale_each=True, normalize=True)', 'imshow': 'plt.imshow(grid.permute(1, 2, 0).cpu().numpy())', 'show': 'plt.show()'}}, 'performance': {'dataset': 'celebA', 'accuracy': 'High-quality celebrity faces'}, 'description': \"Progressive Growing of GANs (PGAN) is a method for generating high-resolution images using generative adversarial networks. The model is trained progressively, starting with low-resolution images and gradually increasing the resolution until the desired output is achieved. This implementation is based on the paper by Tero Karras et al., 'Progressive Growing of GANs for Improved Quality, Stability, and Variation'.\"}", "category": "generic"}
{"question_id": 578, "text": "A research team is analyzing brain MRI images for abnormality segmentation. Suggest a suitable API to achieve this. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Biomedical Image Segmentation', 'api_name': 'U-Net for brain MRI', 'api_call': \"torch.hub.load(repo_or_dir='mateuszbuda/brain-segmentation-pytorch', model='unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'api_arguments': {'in_channels': 3, 'out_channels': 1, 'init_features': 32, 'pretrained': True}, 'python_environment_requirements': ['torch', 'torchvision', 'numpy', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'import numpy as np', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'm, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))', 'preprocess = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=m, std=s)])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model = model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.round(output[0]))'], 'performance': {'dataset': 'kaggle.com/mateuszbuda/lgg-mri-segmentation'}, 'description': 'U-Net with batch normalization for biomedical image segmentation with pretrained weights for abnormality segmentation in brain MRI. The model comprises four levels of blocks containing two convolutional layers with batch normalization and ReLU activation function, and one max pooling layer in the encoding part and up-convolutional layers instead in the decoding part. The number of convolutional filters in each block is 32, 64, 128, and 256. The bottleneck layer has 512 convolutional filters. From the encoding layers, skip connections are used to the corresponding layers in the decoding part. Input image is a 3-channel brain MRI slice from pre-contrast, FLAIR, and post-contrast sequences, respectively. Output is a one-channel probability map of abnormality regions with the same size as the input image.'}", "category": "generic"}
{"question_id": 579, "text": "Jane is developing a mobile app to identify animal species. Propose an API that classifies animals based on images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNet50', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['pip install validators matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", \"print(f'Using {device} for inference')\", \"resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resnet50.eval().to(device)', 'uris = [...]', 'batch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resnet50(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'ImageNet', 'accuracy': '~0.5% top1 improvement over ResNet50 v1'}, 'description': 'The ResNet50 v1.5 model is a modified version of the original ResNet50 v1 model. The difference between v1 and v1.5 is that, in the bottleneck blocks which requires downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate (~0.5% top1) than v1, but comes with a small performance drawback (~5% imgs/sec). The model is initialized as described in Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures.'}", "category": "generic"}
{"question_id": 580, "text": "Find me an API to classify objects in images given a massive dataset of real life images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'AlexNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='alexnet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 43.45, 'top-5_error': 20.91}}, 'description': 'AlexNet is a deep convolutional neural network that achieved a top-5 error of 15.3% in the 2012 ImageNet Large Scale Visual Recognition Challenge. The main contribution of the original paper was the depth of the model, which was computationally expensive but made feasible through the use of GPUs during training. The pretrained AlexNet model in PyTorch can be used for image classification tasks.'}", "category": "generic"}
{"question_id": 581, "text": "I want to classify images in real-time during a robotics competition. Recommend an API for image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeXt101-32x4d', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resneXt', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'validators', 'matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', 'device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")', \"print(f'Using {device} for inference')\", \"resneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resneXt')\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resneXt.eval().to(device)', 'uris = [', \" 'http://images.cocodataset.org/test-stuff2017/000000024309.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000028117.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000006149.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000004954.jpg',\", ']', 'batch = torch.cat(', ' [utils.prepare_input_from_uri(uri) for uri in uris]', ').to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resneXt(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'IMAGENET', 'accuracy': 'Not provided'}, 'description': 'ResNeXt101-32x4d is a model introduced in the Aggregated Residual Transformations for Deep Neural Networks paper. It is based on regular ResNet model, substituting 3x3 convolutions inside the bottleneck block for 3x3 grouped convolutions. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures. It can be deployed for inference on the NVIDIA Triton Inference Server using TorchScript, ONNX Runtime or TensorRT as an execution backend.'}", "category": "generic"}
{"question_id": 582, "text": "A photographer at National Wildlife Foundation wants to automatically classify and organize the wildlife photos he has captured. Suggest an API that can classify animal images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SE-ResNeXt101', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_se_resnext101_32x4d', pretrained=True)\", 'api_arguments': 'N/A', 'python_environment_requirements': 'validators, matplotlib', 'example_code': \"import torch\\nfrom PIL import Image\\nimport torchvision.transforms as transforms\\nimport numpy as np\\nimport json\\nimport requests\\nimport matplotlib.pyplot as plt\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n%matplotlib inline\\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\nprint(f'Using {device} for inference')\\nresneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_se_resnext101_32x4d')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\nresneXt.eval().to(device)\\nuris = ['http://images.cocodataset.org/test-stuff2017/000000024309.jpg','http://images.cocodataset.org/test-stuff2017/000000028117.jpg','http://images.cocodataset.org/test-stuff2017/000000006149.jpg','http://images.cocodataset.org/test-stuff2017/000000004954.jpg']\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(resneXt(batch), dim=1)\\nresults = utils.pick_n_best(predictions=output, n=5)\\nfor uri, result in zip(uris, results):\\n img = Image.open(requests.get(uri, stream=True).raw)\\n img.thumbnail((256,256), Image.ANTIALIAS)\\n plt.imshow(img)\\n plt.show()\\n print(result)\", 'performance': {'dataset': 'IMAGENET', 'accuracy': 'N/A'}, 'description': 'The SE-ResNeXt101-32x4d is a ResNeXt101-32x4d model with added Squeeze-and-Excitation module. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures, which allows researchers to get results 3x faster than training without Tensor Cores while experiencing the benefits of mixed precision training.'}", "category": "generic"}
{"question_id": 583, "text": "We need to develop a robotic assistant, and it needs to be able to speak given a text input. Provide a text-to-speech API that can convert a text input into natural-sounding speech. \n Use this API documentation for reference: {'domain': 'Text-to-Speech', 'framework': 'PyTorch', 'functionality': 'Speech Synthesis', 'api_name': 'WaveGlow', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_waveglow', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_waveglow', 'model_math': 'fp32'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': {'load_waveglow_model': \"waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp32')\", 'prepare_waveglow_model': ['waveglow = waveglow.remove_weightnorm(waveglow)', \"waveglow = waveglow.to('cuda')\", 'waveglow.eval()'], 'load_tacotron2_model': \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp32')\", 'prepare_tacotron2_model': [\"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()'], 'synthesize_speech': ['text = \"hello world, I missed you so much\"', \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'save_audio': 'write(\"audio.wav\", rate, audio_numpy)', 'play_audio': 'Audio(audio_numpy, rate=rate)'}, 'performance': {'dataset': 'LJ Speech', 'accuracy': None}, 'description': 'The Tacotron 2 and WaveGlow model form a text-to-speech system that enables users to synthesize natural-sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 584, "text": "Find me an API that can determine the sentiment of a given text review. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'RoBERTa', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq', model='roberta.large', pretrained=True)\", 'api_arguments': [\"'pytorch/fairseq'\", \"'roberta.large'\"], 'python_environment_requirements': ['regex', 'requests', 'hydra-core', 'omegaconf'], 'example_code': ['import torch', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\", 'roberta.eval()', \"tokens = roberta.encode('Hello world!')\", 'last_layer_features = roberta.extract_features(tokens)', 'all_layers = roberta.extract_features(tokens, return_all_hiddens=True)', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\", 'roberta.eval()', \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is not very optimized.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is based on BERT.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"roberta.register_classification_head('new_task', num_classes=3)\", \"logprobs = roberta.predict('new_task', tokens)\"], 'performance': {'dataset': 'MNLI', 'accuracy': 'N/A'}, 'description': \"RoBERTa is a robustly optimized version of BERT, a revolutionary self-supervised pretraining technique that learns to predict intentionally hidden (masked) sections of text. RoBERTa builds on BERT's language masking strategy and modifies key hyperparameters, including removing BERT's next-sentence pretraining objective, and training with much larger mini-batches and learning rates. RoBERTa was also trained on an order of magnitude more data than BERT, for a longer amount of time, allowing it to generalize even better to downstream tasks.\"}", "category": "generic"}
{"question_id": 585, "text": "I have a collection of photos of different objects and want to classify them. Suggest me an API that can help in this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet121', pretrained=True)\", 'api_arguments': [{'name': 'densenet121', 'type': 'str', 'description': 'Densenet-121 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet121': {'Top-1 error': 25.35, 'Top-5 error': 7.83}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 586, "text": "We need a deep learning model for image classification that is less computationally expensive and has a low number of parameters while maintaining the accuracy performance. Provide me an API for image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet169', pretrained=True)\", 'api_arguments': [{'name': 'densenet169', 'type': 'str', 'description': 'Densenet-169 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet169': {'Top-1 error': 24.0, 'Top-5 error': 7.0}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 587, "text": "Design an image classifier that can differentiate between various classes. Recommend an API that can serve this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet201', pretrained=True)\", 'api_arguments': [{'name': 'densenet201', 'type': 'str', 'description': 'Densenet-201 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet201': {'Top-1 error': 22.8, 'Top-5 error': 6.43}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 588, "text": "Suggest a suitable API that can classify images into different categories based on ImageNet dataset. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet161', pretrained=True)\", 'api_arguments': [{'name': 'densenet161', 'type': 'str', 'description': 'Densenet-161 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet161', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet161': {'Top-1 error': 22.35, 'Top-5 error': 6.2}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 589, "text": "Recommend an API for segmenting objects in images for an autonomous vehicle project. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet50', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet50': {'Mean IOU': 60.5, 'Global Pixelwise Accuracy': 91.4}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 590, "text": "I need an API that generates semantic segmentation of an input image taken by a self-driving car. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet101', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet101': {'Mean IOU': 63.7, 'Global Pixelwise Accuracy': 91.9}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 591, "text": "Weddings and events are photographed every day. What API can help me label these photos by category for my wedding business? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet39ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet39ds', 'type': 'str', 'description': 'HarDNet-39DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet39ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet39ds': {'Top-1 error': 27.92, 'Top-5 error': 9.57}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 592, "text": "I need to identify and classify a variety of objects in a given image. Provide me with an API that can do this effectively. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68ds', 'type': 'str', 'description': 'HarDNet-68DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68ds': {'Top-1 error': 25.71, 'Top-5 error': 8.13}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 593, "text": "Discover an efficient API that can classify the types objects in an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet85', pretrained=True)\", 'api_arguments': [{'name': 'hardnet85', 'type': 'str', 'description': 'HarDNet-85 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet85', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet85': {'Top-1 error': 21.96, 'Top-5 error': 6.11}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 594, "text": "I am creating a mobile app to identify plants. I need an API that has a lighter-weight model for image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68', 'type': 'str', 'description': 'HarDNet-68 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68': {'Top-1 error': 23.52, 'Top-5 error': 6.99}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory trafficCNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 595, "text": "Recommend an API that can classify images into different categories using a model designed by Google. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'GoogLeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='googlenet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.0.0', 'torchvision': '>=0.2.2'}, 'example_code': {'import': ['import torch', 'import urllib', 'from PIL import Image', 'from torchvision import transforms'], 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\", 'model_eval': 'model.eval()', 'image_preprocessing': ['input_image = Image.open(filename)', 'preprocess = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'model_execution': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'output_processing': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'top5_prob, top5_catid = torch.topk(probabilities, 5)']}, 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 error': '30.22', 'Top-5 error': '10.47'}}, 'description': \"GoogLeNet is based on a deep convolutional neural network architecture codenamed 'Inception', which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014).\"}", "category": "generic"}
{"question_id": 596, "text": "I want to build a mobile application that can classify an object based on its image. Recommend a lightweight API that can provide high performance on mobile devices. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Efficient networks by generating more features from cheap operations', 'api_name': 'GhostNet', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/ghostnet', model='ghostnet_1x', pretrained=True)\", 'api_arguments': ['pretrained'], 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/ghostnet', 'ghostnet_1x', pretrained=True)\", 'model.eval()', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 acc': '73.98', 'Top-5 acc': '91.46'}}, 'description': 'The GhostNet architecture is based on an Ghost module structure which generates more features from cheap operations. Based on a set of intrinsic feature maps, a series of cheap operations are applied to generate many ghost feature maps that could fully reveal information underlying intrinsic features. Experiments conducted on benchmarks demonstrate the superiority of GhostNet in terms of speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 597, "text": "In a new computer vision project, we need a model that can classify images into multiple possible categories. Recommend a suitable pre-trained model. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet50_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet50_ibn_a', 'type': 'str', 'description': 'ResNet-50-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet50_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet50_ibn_a': {'Top-1 acc': 77.46, 'Top-5 acc': 93.68}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 598, "text": "An AI engineer is developing an image recognition system for Intel Corporation. Provide me an API to classify images using IBN-Net model. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet101_ibn_a', 'type': 'str', 'description': 'ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet101_ibn_a': {'Top-1 acc': 78.61, 'Top-5 acc': 94.41}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 599, "text": "Looking for something to help re-identify a person from diferent photos. Find me an API for that. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnext101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_ibn_a', 'type': 'str', 'description': 'ResNeXt-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnext101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext101_ibn_a': {'Top-1 acc': 79.12, 'Top-5 acc': 94.58}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 600, "text": "Can you provide an API that could identify different types of cars given an image of the scene? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'Inception_v3', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='inception_v3', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '1.9.0', 'torchvision': '0.10.0'}, 'example_code': {'import_libraries': 'import torch', 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\", 'model_evaluation': 'model.eval()'}, 'performance': {'dataset': 'imagenet', 'accuracy': {'top-1_error': 22.55, 'top-5_error': 6.44}}, 'description': 'Inception v3, also called GoogleNetv3, is a famous Convolutional Neural Network trained on the ImageNet dataset from 2015. It is based on the exploration of ways to scale up networks to utilize the added computation as efficiently as possible by using suitably factorized convolutions and aggressive regularization. The model achieves a top-1 error of 22.55% and a top-5 error of 6.44% on the ImageNet dataset.'}", "category": "generic"}
{"question_id": 601, "text": "I need to classify different types of animals in images taken from the wild. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest200', pretrained=True)\", 'api_arguments': 'resnest200', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest200', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-200': 83.84}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 602, "text": "I need a way to identify vehicles in images by model and brand. Write an API that can achieve this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='se_resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'se_resnet101_ibn_a', 'type': 'str', 'description': 'SE-ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'se_resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'se_resnet101_ibn_a': {'Top-1 acc': 78.75, 'Top-5 acc': 94.49}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 603, "text": "We need to implement an image classification model for our AI platform. Can you suggest an appropriate API we can use as a base? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest101', pretrained=True)\", 'api_arguments': 'resnest101', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-101': 82.83}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 604, "text": "Provide an API to classify buildings to residential, commercial or industrial based on their locations from images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest50', pretrained=True)\", 'api_arguments': 'resnest50', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-50': 81.03}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 605, "text": "I work at a tech company and I need to identify dog breeds in images. Provide me with an API that can classify dog breeds based on an input image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest269', pretrained=True)\", 'api_arguments': 'resnest269', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest269', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-269': 84.54}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 606, "text": "I need to classify objects in an image using ProxylessNAS optimized for GPU systems. Suggest a pre-trained API that can accomplish this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_gpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_gpu', 'type': 'str', 'description': 'ProxylessNAS optimized for GPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_gpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_gpu', 'accuracy': 75.1}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 607, "text": "Create a mobile app to detect objects. Recommend me an API that would ideally suit this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_cpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_cpu', 'type': 'str', 'description': 'ProxylessNAS optimized for CPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_cpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_cpu', 'accuracy': 75.3}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 608, "text": "I need an API that can classify objects in images and has a lightweight model suitable for mobile devices. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MobileNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='mobilenet_v2', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 28.12, 'top-5_error': 9.71}}, 'description': 'The MobileNet v2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input. MobileNet v2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, non-linearities in the narrow layers were removed in order to maintain representational power.'}", "category": "generic"}
{"question_id": 609, "text": "Develop a mobile application that can classify objects in images captured by the phone camera. Suggest an API that can do the classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_mobile', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_mobile', 'type': 'str', 'description': 'ProxylessNAS optimized for Mobile'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_mobile'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_mobile', 'accuracy': 74.6}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 610, "text": "To help an online store to label images taken from the deep sea, pick the appropriate API for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet50', 'top-1_error': 23.85, 'top-5_error': 7.13}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 611, "text": "Suppose you work as a data scientist in IMB and you need an image classifier for your project on animals. Can you provide me the code that loads a model for image classification? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet18', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet18', 'top-1_error': 30.24, 'top-5_error': 10.92}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 612, "text": "I am organizing my photo library and need an API to identify what's in each photo, can you make a code for me? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet34', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet34', 'top-1_error': 26.7, 'top-5_error': 8.58}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 613, "text": "An application is being built that can identify different vehicles in photos. Suggest an API that can be used for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet101', 'top-1_error': 22.63, 'top-5_error': 6.44}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 614, "text": "I need an API for image classification that employs deep residual networks. Can you provide me with one? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet152', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet152', 'top-1_error': 21.69, 'top-5_error': 5.94}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 615, "text": "A photographer at Adobe Stock wants to automatically tag their large photo inventory using AI. Point them to an ready-to-use API that accomplishes this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext101_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext101_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'resnext101_32x8d': {'top-1': 20.69, 'top-5': 5.47}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 616, "text": "To create an app that tells a user if the food they take a photo of is safe to eat, provide me with an appropriate API that can classify images of food products. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext50_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext50_32x4d': {'top-1': 22.38, 'top-5': 6.3}}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 617, "text": "Find me an API capable of image classification based on Spiking Neural Networks. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_b', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_b', 'type': 'str', 'description': 'SNNMLP Base model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_b', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Base', 'top-1': 85.59}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 618, "text": "What is an API that can be provided to a person working on the Hulu app for Apple TV to classify images? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_t', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_t', 'type': 'str', 'description': 'SNNMLP Tiny model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_t', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Tiny', 'top-1': 81.88}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 619, "text": "A home security system needs an API that can recognize faces attached to their smart doorbell to detect strangers. Propose a solution for them. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_1', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_1'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_1': {'Top-1 error': 41.81, 'Top-5 error': 19.38}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 620, "text": "An e-commerce website wants to integrate an AI assistant to differentiate between various items being uploaded by sellers. Give me an API to classify the uploaded items based on their image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_s', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_s', 'type': 'str', 'description': 'SNNMLP Small model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_s', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Small', 'top-1': 83.3}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 621, "text": "An NGO ingin Gitonga is building an AI bot that identifies trees using images from the Amazon rainforest. Help me find an API that can classify images of trees using pre-trained models. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_0', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_0'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_0': {'Top-1 error': 41.9, 'Top-5 error': 19.58}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 622, "text": "I want a lightweight PyTorch API for object recognition for my application. What would you suggest? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11', pretrained=True)\", 'api_arguments': [{'name': 'vgg11', 'type': 'str', 'description': 'VGG11 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11': {'Top-1 error': 30.98, 'Top-5 error': 11.37}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 623, "text": "I want to analyze an Instagram picture to figure out what objects are in it. Give me an API that can help me understand the image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ShuffleNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='shufflenet_v2_x1_0', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'torch', 'torchvision': 'torchvision', 'PIL': 'Image', 'urllib': 'urllib'}, 'example_code': {'import_libraries': ['import torch', 'from PIL import Image', 'from torchvision import transforms', 'import urllib'], 'load_model': [\"model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\", 'model.eval()'], 'load_image': [\"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'try: urllib.URLopener().retrieve(url, filename)', 'except: urllib.request.urlretrieve(url, filename)', 'input_image = Image.open(filename)'], 'preprocess_image': ['preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'run_inference': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'get_probabilities': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'top_categories': ['top5_prob, top5_catid = torch.topk(probabilities, 5)', 'for i in range(top5_prob.size(0)):', ' print(categories[top5_catid[i]], top5_prob[i].item())']}, 'performance': {'dataset': 'Imagenet', 'accuracy': {'top-1_error': 30.64, 'top-5_error': 11.68}}, 'description': 'ShuffleNet V2 is an efficient ConvNet optimized for speed and memory, pre-trained on Imagenet. It is designed based on practical guidelines for efficient network design, including speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 624, "text": "I want to categorize images from a dataset with pretrained API. Give me an ideal choice. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg11_bn', 'type': 'str', 'description': 'VGG11 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11_bn': {'Top-1 error': 26.7, 'Top-5 error': 8.58}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 625, "text": "I am a researcher in the field of computer vision, and I need to classify images using a pre-trained model with good performance. Can you give me an API for that? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13', pretrained=True)\", 'api_arguments': [{'name': 'vgg13', 'type': 'str', 'description': 'VGG13 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13': {'Top-1 error': 30.07, 'Top-5 error': 10.75}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn,vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 626, "text": "A company is building an image recognition service that helps identify objects in images. Recommend an API that can classify these images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg13_bn', 'type': 'str', 'description': 'VGG13 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13_bn': {'Top-1 error': 28.45, 'Top-5 error': 9.63}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 627, "text": "I need a PyTorch API to recognize various objects in images for my project. Can you provide one? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16', pretrained=True)\", 'api_arguments': [{'name': 'vgg16', 'type': 'str', 'description': 'VGG16 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16': {'Top-1 error': 28.41, 'Top-5 error': 9.62}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 628, "text": "Can you provide me with an API capable of image recognition for my autonomous vehicle project? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg16_bn', 'type': 'str', 'description': 'VGG16 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16_bn': {'Top-1 error': 26.63, 'Top-5 error': 8.5}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 629, "text": "Describe an API that can help identify objects and scenes in a series of photos from a vacation. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19', pretrained=True)\", 'api_arguments': [{'name': 'vgg19', 'type': 'str', 'description': 'VGG19 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19': {'Top-1 error': 27.62, 'Top-5 error': 9.12}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 630, "text": "I need an API that can recognize the dog breed from a given image of a dog. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg19_bn', 'type': 'str', 'description': 'VGG19 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19_bn': {'Top-1 error': 25.76, 'Top-5 error': 8.15}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 631, "text": "A computer vision company needs an efficient image recognizer API for a security project. Find a suitable API to classify objects in an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet50_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet50_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet50_2': {'Top-1 error': 21.49, 'Top-5 error': 5.91}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 632, "text": "Provide a pretrained API that can identify and classify dogs in images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet101_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet101_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet101_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet101_2': {'Top-1 error': 21.16, 'Top-5 error': 5.72}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 633, "text": "What API can tell me which sport is being played in a video? \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'X3D Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='x3d_s', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'x3d_s', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_s', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 73.33, 'top5': 91.27}, 'flops': 2.96, 'params': 3.79}, 'description': \"X3D model architectures are based on the paper 'X3D: Expanding Architectures for Efficient Video Recognition' by Christoph Feichtenhofer. They are pretrained on the Kinetics 400 dataset. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 634, "text": "A company called \"VideoTag\" wants to classify videos into different categories using machine learning. Provide an API that can help them with video classification. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'SlowFast Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slowfast_r50', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'slowfast_r50', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 76.94, 'top5': 92.69}, 'flops': 65.71, 'params': 34.57}, 'description': \"Slow Fast model architectures are based on the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al. They are pretrained on the Kinetics 400 dataset using the 8x8 setting. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 635, "text": "Recommend an API that can classify images quickly and efficiently using an NVIDIA GPU. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'GPUNet Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", 'api_arguments': {'repository': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_gpunet', 'pretrained': 'True', 'model_type': 'GPUNet-0', 'model_math': 'fp32'}, 'python_environment_requirements': ['torch', 'validators', 'matplotlib', 'timm==0.5.4'], 'example_code': ['import torch', \"model_type = 'GPUNet-0'\", \"precision = 'fp32'\", \"gpunet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'gpunet.to(device)', 'gpunet.eval()'], 'performance': {'dataset': 'IMAGENET', 'description': 'GPUNet demonstrates state-of-the-art inference performance up to 2x faster than EfficientNet-X and FBNet-V3.'}, 'description': 'GPUNet is a family of Convolutional Neural Networks designed by NVIDIA using novel Neural Architecture Search (NAS) methods. They are optimized for NVIDIA GPU and TensorRT performance. GPUNet models are pretrained on the IMAGENET dataset and are capable of classifying images into different categories. The models are provided by the NVIDIA Deep Learning Examples library.'}", "category": "generic"}
{"question_id": 636, "text": "A news aggregator wants to categorize and summarize the news article. Which API they can use for text classification and understanding? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Natural Language Processing', 'api_name': 'PyTorch-Transformers', 'api_call': \"torch.hub.load(repo_or_dir='huggingface/pytorch-transformers')\", 'api_arguments': ['pretrained_model_or_path', 'output_attention', 'output_hidden_states', 'config', 'from_tf'], 'python_environment_requirements': ['tqdm', 'boto3', 'requests', 'regex', 'sentencepiece', 'sacremoses'], 'example_code': 'import torch\\ntokenizer = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'tokenizer\\', \\'bert-base-cased\\')\\n\\ntext_1 = \"Jim Henson was a puppeteer\"\\ntext_2 = \"Who was Jim Henson ?\"\\n\\nindexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\\n\\nmodel = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'model\\', \\'bert-base-cased\\')\\n\\nwith torch.no_grad():\\n encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)', 'performance': {'dataset': [{'name': 'MRPC', 'accuracy': 'Not provided'}]}, 'description': 'PyTorch-Transformers is a library of state-of-the-art pre-trained models for Natural Language Processing (NLP) including BERT, GPT, GPT-2, Transformer-XL, XLNet, XLM, RoBERTa, and DistilBERT. The library provides functionality for tokenization, configuration, and various model architectures for different tasks such as causal language modeling, sequence classification, question answering, and masked language modeling.'}", "category": "generic"}
{"question_id": 637, "text": "A fintech company wants to build a model that can identify the pattern on a credit card. What API can they use to achieve this classification? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Once-for-all (OFA) Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/once-for-all', model='ofa_supernet_mbv3_w10', pretrained=True)\", 'api_arguments': {'repository': 'mit-han-lab/once-for-all', 'model': 'ofa_supernet_mbv3_w10', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"super_net_name = 'ofa_supernet_mbv3_w10'\", \"super_net = torch.hub.load('mit-han-lab/once-for-all', super_net_name, pretrained=True).eval()\"], 'performance': {'description': 'OFA networks outperform state-of-the-art NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x faster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency) while reducing many orders of magnitude GPU hours and CO2 emission.'}, 'description': 'Once-for-all (OFA) networks are a family of neural networks designed by MIT Han Lab. They decouple training and search, achieving efficient inference across various edge devices and resource constraints. OFA networks are pretrained on the IMAGENET dataset and are capable of classifying images into different categories.'}", "category": "generic"}
{"question_id": 638, "text": "What is an API to provide me with a pretrained image classifier that would recognize object types in images? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Semi-supervised and semi-weakly supervised ImageNet Models', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/semi-supervised-ImageNet1K-models', model='resnet18_swsl', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/semi-supervised-ImageNet1K-models', 'model': 'resnet18_swsl', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl', pretrained=True)\", 'model.eval()'], 'performance': {'description': 'Semi-supervised and semi-weakly supervised ImageNet models achieve state-of-the-art accuracy of 81.2% on ImageNet for the widely used/adopted ResNet-50 model architecture.'}, 'description': \"Semi-supervised and semi-weakly supervised ImageNet Models are introduced in the 'Billion scale semi-supervised learning for image classification' paper. These models are pretrained on a subset of unlabeled YFCC100M public image dataset and fine-tuned with the ImageNet1K training dataset. They are capable of classifying images into different categories and are provided by the Facebook Research library.\"}", "category": "generic"}
{"question_id": 639, "text": "Provide me with a Machine Learning API that can classify objects in images with high accuracy and low computational cost. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'EfficientNet', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_efficientnet_b0', pretrained=True)\", 'api_arguments': ['model_name', 'pretrained'], 'python_environment_requirements': ['validators', 'matplotlib'], 'example_code': \"import torch\\n\\nefficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\n\\nefficientnet.eval().to(device)\\n\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\n\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(efficientnet(batch), dim=1)\\n \\nresults = utils.pick_n_best(predictions=output, n=5)\", 'performance': {'dataset': {'name': 'IMAGENET', 'accuracy': 'Not provided'}}, 'description': 'EfficientNet is a family of image classification models that achieve state-of-the-art accuracy while being smaller and faster. The models are trained with mixed precision using Tensor Cores on the NVIDIA Volta and Ampere GPU architectures. The EfficientNet models include EfficientNet-B0, EfficientNet-B4, EfficientNet-WideSE-B0, and EfficientNet-WideSE-B4. The WideSE models use wider Squeeze-and-Excitation layers than the original EfficientNet models, resulting in slightly better accuracy.'}", "category": "generic"}
{"question_id": 640, "text": "Demonstrate how to detect objects in a video clip by using an API. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Single Shot MultiBox Detector', 'api_name': 'SSD', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_ssd', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['numpy', 'scipy', 'scikit-image', 'matplotlib'], 'example_code': \"import torch\\n\\nssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\\n\\nssd_model.to('cuda')\\nssd_model.eval()\\n\\ninputs = [utils.prepare_input(uri) for uri in uris]\\ntensor = utils.prepare_tensor(inputs)\\n\\nwith torch.no_grad():\\n detections_batch = ssd_model(tensor)\\n\\nresults_per_input = utils.decode_results(detections_batch)\\nbest_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\", 'performance': {'dataset': {'name': 'COCO', 'accuracy': 'Not provided'}}, 'description': \"The SSD (Single Shot MultiBox Detector) model is an object detection model based on the paper 'SSD: Single Shot MultiBox Detector'. It uses a deep neural network for detecting objects in images. This implementation replaces the obsolete VGG model backbone with the more modern ResNet-50 model. The SSD model is trained on the COCO dataset and can be used to detect objects in images with high accuracy and efficiency.\"}", "category": "generic"}
{"question_id": 641, "text": "I need to translate a paragraph from English to French. What API would you recommend for this task? \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Neural Machine Translation', 'api_name': 'Transformer (NMT)', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq')\", 'api_arguments': ['model_name', 'tokenizer', 'bpe', 'beam', 'sampling', 'sampling_topk'], 'python_environment_requirements': ['bitarray', 'fastBPE', 'hydra-core', 'omegaconf', 'regex', 'requests', 'sacremoses', 'subword_nmt'], 'example_code': \"import torch\\n\\nen2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\\n\\nen2fr.cuda()\\n\\nfr = en2fr.translate('Hello world!', beam=5)\\nassert fr == 'Bonjour \u00e0 tous !'\", 'performance': {'dataset': [{'name': \"WMT'14\", 'accuracy': 'Not provided'}, {'name': \"WMT'18\", 'accuracy': 'Not provided'}, {'name': \"WMT'19\", 'accuracy': 'Not provided'}]}, 'description': \"Transformer (NMT) is a powerful sequence-to-sequence modeling architecture that produces state-of-the-art neural machine translation systems. It is based on the paper 'Attention Is All You Need' and has been improved using techniques such as large-scale semi-supervised training, back-translation, and noisy-channel reranking. It supports English-French and English-German translation as well as round-trip translation for paraphrasing.\"}", "category": "generic"}
{"question_id": 642, "text": "A CEO of a podcast company is trying to write summaries of the podcasts. She needs an API that can convert the main points of a podcast to text. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Text-to-Speech', 'api_name': 'Tacotron 2', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_tacotron2', model_math='fp16')\", 'api_arguments': {'model_math': 'fp16'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': ['import torch', \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\", \"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()', \"text = 'Hello world, I missed you so much.'\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'performance': {'dataset': 'LJ Speech', 'accuracy': 'Not specified'}, 'description': 'The Tacotron 2 model generates mel spectrograms from input text using an encoder-decoder architecture, and it is designed for generating natural-sounding speech from raw transcripts without any additional prosody information. This implementation uses Dropout instead of Zoneout to regularize the LSTM layers. The WaveGlow model (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 643, "text": "As a developer, I'm looking for an image classification API that has high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.67', 'top5': '95.09'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 644, "text": "A software needs an API to classify an object in an image with more than 80% accuracy. Which API can be recommended? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V1', model='mealv1_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv1_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V1 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '78.21', 'top5': '94.01'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 645, "text": "Tell me how to classify an image based on different object categories with the highest performance. Give me an API to do that. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_cutmix', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_cutmix'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 + CutMix w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.98', 'top5': '95.35'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 646, "text": "Recommend a highly-performing image classification model that does not rely on tricks such as architecture modification, data augmentation or label smoothing. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_380x380', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_380x380'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '380', 'parameters': '25.6M', 'top1': '81.72', 'top5': '95.81'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 647, "text": "I need an image classification API to predict the highest possible accuracy on ImageNet. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_075', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_075'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 0.75', 'resolution': '224', 'parameters': '2.04M', 'top1': '67.60', 'top5': '87.23'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 648, "text": "A developer in your team is working on an image classification app and would like to use an efficient pretrained model. Offer an API that can assist him. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenet_v3_large_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenet_v3_large_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Large 1.0', 'resolution': '224', 'parameters': '5.48M', 'top1': '76.92', 'top5': '93.32'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 649, "text": "Help me find an API to classify different dog breeds from their image. Our product integrates with Instagram. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 1.0', 'resolution': '224', 'parameters': '2.54M', 'top1': '69.65', 'top5': '88.71'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 650, "text": "Generate an API that classifies images with enhanced accuracy and without depending on architecture modification, data augmentation, or other training tricks. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_efficientnet_b0', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_efficientnet_b0'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ EfficientNet-B0', 'resolution': '224', 'parameters': '5.29M', 'top1': '78.29', 'top5': '93.95'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 651, "text": "Find an API that can perform scene recognition in videos and is pretrained on a large dataset for enhanced accuracy. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorch', 'functionality': '3D ResNet', 'api_name': 'slow_r50', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slow_r50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'json', 'urllib', 'pytorchvideo', 'torchvision', 'torchaudio', 'torchtext', 'torcharrow', 'TorchData', 'TorchRec', 'TorchServe', 'PyTorch on XLA Devices'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top_1': 74.58, 'top_5': 91.63}, 'Flops (G)': 54.52, 'Params (M)': 32.45}, 'description': \"The 3D ResNet model is a Resnet-style video classification network pretrained on the Kinetics 400 dataset. It is based on the architecture from the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al.\"}", "category": "generic"}
{"question_id": 652, "text": "I need an API to detect objects in a traffic video, segment drivable areas, and detect lane lines. Provide an API that can perform this task. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Traffic Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'HybridNets', 'api_call': \"torch.hub.load(repo_or_dir='datvuthanh/hybridnets', model='hybridnets', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'Python>=3.7, PyTorch>=1.10', 'example_code': \"import torch\\nmodel = torch.hub.load('datvuthanh/hybridnets', 'hybridnets', pretrained=True)\\nimg = torch.randn(1,3,640,384)\\nfeatures, regression, classification, anchors, segmentation = model(img)\", 'performance': {'dataset': [{'name': 'BDD100K', 'accuracy': {'Traffic Object Detection': {'Recall (%)': 92.8, 'mAP@0.5 (%)': 77.3}, 'Drivable Area Segmentation': {'Drivable mIoU (%)': 90.5}, 'Lane Line Detection': {'Accuracy (%)': 85.4, 'Lane Line IoU (%)': 31.6}}}]}, 'description': 'HybridNets is an end2end perception network for multi-tasks. Our work focused on traffic object detection, drivable area segmentation and lane detection. HybridNets can run real-time on embedded systems, and obtains SOTA Object Detection, Lane Detection on BDD100K Dataset.'}", "category": "generic"}
{"question_id": 653, "text": "I am designing an autonomous navigation system for a robot. What API should I use that detects objects, drivable areas, and lane lines simultaneously? \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'YOLOP', 'api_call': \"torch.hub.load(repo_or_dir='hustvl/yolop', model='yolop', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'pip install -qr https://github.com/hustvl/YOLOP/blob/main/requirements.txt', 'example_code': \"import torch\\nmodel = torch.hub.load('hustvl/yolop', 'yolop', pretrained=True)\\nimg = torch.randn(1,3,640,640)\\ndet_out, da_seg_out,ll_seg_out = model(img)\", 'performance': {'dataset': 'BDD100K', 'accuracy': {'Object Detection': {'Recall(%)': 89.2, 'mAP50(%)': 76.5, 'Speed(fps)': 41}, 'Drivable Area Segmentation': {'mIOU(%)': 91.5, 'Speed(fps)': 41}, 'Lane Detection': {'mIOU(%)': 70.5, 'IOU(%)': 26.2}}}, 'description': 'YOLOP is an efficient multi-task network that can jointly handle three crucial tasks in autonomous driving: object detection, drivable area segmentation and lane detection. And it is also the first to reach real-time on embedded devices while maintaining state-of-the-art level performance on the BDD100K dataset.'}", "category": "generic"}
{"question_id": 654, "text": "Is there any technique that can compute relative depth from a single image? Which API can do this job? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='MiDaS_small', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 655, "text": "I need to calculate the depth of a scene from a single image, please provide me an API for a model that can perform this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Large', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Large')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 656, "text": "Help me extract the depth information from a single image taken with my camera. Provide an API that can do this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Hybrid', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Hybrid')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 657, "text": "I have a mix of pop songs and I need an API that can break it into separate tracks for vocals, drums, etc. \n Use this API documentation for reference: {'domain': 'Audio Separation', 'framework': 'PyTorch', 'functionality': 'Music Source Separation', 'api_name': 'Open-Unmix', 'api_call': \"torch.hub.load(repo_or_dir='sigsep/open-unmix-pytorch', model='umxhq', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['PyTorch >=1.6.0', 'torchaudio'], 'example_code': ['import torch', \"separator = torch.hub.load('sigsep/open-unmix-pytorch', 'umxhq')\", 'audio = torch.rand((1, 2, 100000))', 'original_sample_rate = separator.sample_rate', 'estimates = separator(audio)'], 'performance': {'dataset': 'MUSDB18', 'accuracy': 'N/A'}, 'description': 'Open-Unmix provides ready-to-use models that allow users to separate pop music into four stems: vocals, drums, bass and the remaining other instruments. The models were pre-trained on the freely available MUSDB18 dataset.'}", "category": "generic"}
{"question_id": 658, "text": "We need a voice-activated AI chatbot for our call center. Recommend an API that can detect voice activity from an audio file. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Voice Activity Detection', 'api_name': 'Silero Voice Activity Detector', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-vad', 'model': 'silero_vad', 'force_reload': 'True'}, 'python_environment_requirements': {'torchaudio': 'pip install -q torchaudio'}, 'example_code': {'import': ['import torch', 'torch.set_num_threads(1)', 'from IPython.display import Audio', 'from pprint import pprint'], 'download_example': \"torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\", 'load_model': \"model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'load_utils': '(get_speech_timestamps, _, read_audio, _) = utils', 'set_sampling_rate': 'sampling_rate = 16000', 'read_audio': \"wav = read_audio('en_example.wav', sampling_rate=sampling_rate)\", 'get_speech_timestamps': 'speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sampling_rate)', 'print_speech_timestamps': 'pprint(speech_timestamps)'}, 'performance': {'dataset': '', 'accuracy': ''}, 'description': 'Silero VAD is a pre-trained enterprise-grade Voice Activity Detector (VAD) that aims to provide a high-quality and modern alternative to the WebRTC Voice Activity Detector. The model is optimized for performance on 1 CPU thread and is quantized.'}", "category": "generic"}
{"question_id": 659, "text": "Help me choose an API that can identify the specific species of the bird in a given photograph. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Fine-grained image classifier', 'api_name': 'ntsnet', 'api_call': \"torch.hub.load(repo_or_dir='nicolalandro/ntsnet-cub200', model='ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\", 'api_arguments': {'pretrained': 'True', 'topN': '6', 'device': 'cpu', 'num_classes': '200'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': \"from torchvision import transforms\\nimport torch\\nimport urllib\\nfrom PIL import Image\\n\\ntransform_test = transforms.Compose([\\n transforms.Resize((600, 600), Image.BILINEAR),\\n transforms.CenterCrop((448, 448)),\\n transforms.ToTensor(),\\n transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\\n])\\n\\nmodel = torch.hub.load('nicolalandro/ntsnet-cub200', 'ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\\nmodel.eval()\\n\\nurl = 'https://raw.githubusercontent.com/nicolalandro/ntsnet-cub200/master/images/nts-net.png'\\nimg = Image.open(urllib.request.urlopen(url))\\nscaled_img = transform_test(img)\\ntorch_images = scaled_img.unsqueeze(0)\\n\\nwith torch.no_grad():\\n top_n_coordinates, concat_out, raw_logits, concat_logits, part_logits, top_n_index, top_n_prob = model(torch_images)\\n\\n_, predict = torch.max(concat_logits, 1)\\npred_id = predict.item()\\nprint('bird class:', model.bird_classes[pred_id])\", 'performance': {'dataset': 'CUB200 2011', 'accuracy': 'Not provided'}, 'description': 'This is an nts-net pretrained with CUB200 2011 dataset, which is a fine-grained dataset of birds species.'}", "category": "generic"}
{"question_id": 660, "text": "Create a high-resolution image segmentation model that can distinguish between objects in a scene. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet50', 'Mean IOU': 66.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 661, "text": "What is an efficient method to transcribe voicemails into text using an API? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Speech-To-Text', 'api_name': 'Silero Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_stt', 'language': ['en', 'de', 'es'], 'device': 'device'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf soundfile'], 'example_code': ['import torch', 'import zipfile', 'import torchaudio', 'from glob import glob', \"device = torch.device('cpu')\", \"model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', language='en', device=device)\", '(read_batch, split_into_batches, read_audio, prepare_model_input) = utils', \"torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav', dst ='speech_orig.wav', progress=True)\", \"test_files = glob('speech_orig.wav')\", 'batches = split_into_batches(test_files, batch_size=10)', 'input = prepare_model_input(read_batch(batches[0]), device=device)', 'output = model(input)', 'for example in output:', ' print(decoder(example.cpu()))'], 'performance': {'dataset': 'Open-STT', 'accuracy': 'See the wiki for quality and performance benchmarks'}, 'description': 'Silero Speech-To-Text models provide enterprise grade STT in a compact form-factor for several commonly spoken languages. The models are robust to a variety of dialects, codecs, domains, noises, and lower sampling rates. They consume a normalized audio in the form of samples and output frames with token probabilities. A decoder utility is provided for simplicity.'}", "category": "generic"}
{"question_id": 662, "text": "I am an autonomous vehicle engineer and I need code to make a deep learning model that takes images as input and segments them into different parts like car, road, human. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_mobilenet_v3_large', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_mobilenet_v3_large', 'Mean IOU': 60.3, 'Global Pixelwise Accuracy': 91.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 663, "text": "I plan to make a cityscape segmentation for Boston. Could you recommend an API to segment city landmarks from an image? \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet101', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet101', 'Mean IOU': 67.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 664, "text": "An edTech company wants to build an app that reads content from their textbook to the students. Suggest an API that can convert written text to speech. \n Use this API documentation for reference: {'domain': 'Text-To-Speech', 'framework': 'PyTorch', 'functionality': 'Text-To-Speech', 'api_name': 'Silero Text-To-Speech Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_tts', 'language': 'language', 'speaker': 'speaker'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf'], 'example_code': \"import torch\\nlanguage = 'en'\\nspeaker = 'lj_16khz'\\ndevice = torch.device('cpu')\\nmodel, symbols, sample_rate, example_text, apply_tts = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', language=language, speaker=speaker)\\nmodel = model.to(device)\\naudio = apply_tts(texts=[example_text], model=model, sample_rate=sample_rate, symbols=symbols, device=device)\", 'performance': {'dataset': [{'language': 'Russian', 'speakers': 6}, {'language': 'English', 'speakers': 1}, {'language': 'German', 'speakers': 1}, {'language': 'Spanish', 'speakers': 1}, {'language': 'French', 'speakers': 1}], 'accuracy': 'High throughput on slow hardware. Decent performance on one CPU thread'}, 'description': 'Silero Text-To-Speech models provide enterprise grade TTS in a compact form-factor for several commonly spoken languages. They offer one-line usage, naturally sounding speech, no GPU or training required, minimalism and lack of dependencies, a library of voices in many languages, support for 16kHz and 8kHz out of the box.'}", "category": "generic"}
{"question_id": 665, "text": "Recommend an API to detect objects, such as cars and people, in a live video feed from a security camera. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'YOLOv5', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='ultralytics/yolov5', model='yolov5s', pretrained=True)\", 'api_arguments': [\"'ultralytics/yolov5'\", \"'yolov5s'\", 'pretrained=True'], 'python_environment_requirements': 'Python>=3.8, PyTorch>=1.7', 'example_code': ['import torch', \"model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\", \"imgs = ['https://ultralytics.com/images/zidane.jpg']\", 'results = model(imgs)', 'results.print()', 'results.save()', 'results.xyxy[0]', 'results.pandas().xyxy[0]'], 'performance': {'dataset': 'COCO', 'accuracy': {'YOLOv5s6': {'mAPval0.5:0.95': 43.3, 'mAPtest0.5:0.95': 43.3, 'mAPval0.5': 61.9}, 'YOLOv5m6': {'mAPval0.5:0.95': 50.5, 'mAPtest0.5:0.95': 50.5, 'mAPval0.5': 68.7}, 'YOLOv5l6': {'mAPval0.5:0.95': 53.4, 'mAPtest0.5:0.95': 53.4, 'mAPval0.5': 71.1}, 'YOLOv5x6': {'mAPval0.5:0.95': 54.4, 'mAPtest0.5:0.95': 54.4, 'mAPval0.5': 72.0}, 'YOLOv5x6 TTA': {'mAPval0.5:0.95': 55.0, 'mAPtest0.5:0.95': 55.0, 'mAPval0.5': 72.0}}}, 'description': 'YOLOv5 is a family of compound-scaled object detection models trained on the COCO dataset, and includes simple functionality for Test Time Augmentation (TTA), model ensembling, hyperparameter evolution, and export to ONNX, CoreML and TFLite.'}", "category": "generic"}
{"question_id": 666, "text": "Find me an API that can generate low-resolution images of clothing items. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks', 'api_name': 'DCGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='DCGAN', pretrained=True, useGPU=use_gpu)\", 'api_arguments': {'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': ['import torch', 'import matplotlib.pyplot as plt', 'import torchvision'], 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'generate_images': 'with torch.no_grad(): generated_images = model.test(noise)', 'plot_images': ['plt.imshow(torchvision.utils.make_grid(generated_images).permute(1, 2, 0).cpu().numpy())', 'plt.show()']}, 'performance': {'dataset': 'FashionGen', 'accuracy': 'N/A'}, 'description': 'DCGAN is a model designed in 2015 by Radford et. al. in the paper Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. It is a GAN architecture both very simple and efficient for low resolution image generation (up to 64x64).'}", "category": "generic"}
{"question_id": 667, "text": "A startup wants to build an application that helps users categorize the images they upload. Can you recommend an API for that? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x8d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x8d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x8d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x8d': {'Top-1 Acc.': '82.2', 'Top-5 Acc.': '96.4'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 668, "text": "Provide me with an image classification API that uses weakly-supervised training and can achieve high accuracy on the ImageNet dataset. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x16d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x16d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x16d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x16d': {'Top-1 Acc.': '84.2', 'Top-5 Acc.': '97.2'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 669, "text": "I am working on a computer vision task for my company, and I would like a well-performing machine learning API that can provide correct accuracy in classifying images of objects. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x32d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x32d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x32d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x32d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x32d': {'Top-1 Acc.': '85.1', 'Top-5 Acc.': '97.5'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 670, "text": "I need an API to identify various flowers in a botanical garden from a photo. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x48d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x48d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x48d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x48d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x48d': {'Top-1 Acc.': '85.4', 'Top-5 Acc.': '97.6'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 671, "text": "A web developer is building an image recognition app to identify objects within images. Suggest an API that can identify objects in an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNet50', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['pip install validators matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", \"print(f'Using {device} for inference')\", \"resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resnet50.eval().to(device)', 'uris = [...]', 'batch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resnet50(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'ImageNet', 'accuracy': '~0.5% top1 improvement over ResNet50 v1'}, 'description': 'The ResNet50 v1.5 model is a modified version of the original ResNet50 v1 model. The difference between v1 and v1.5 is that, in the bottleneck blocks which requires downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate (~0.5% top1) than v1, but comes with a small performance drawback (~5% imgs/sec). The model is initialized as described in Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures.'}", "category": "generic"}
{"question_id": 672, "text": "I have a brain MRI scan and I want to detect abnormalities in the scan. Can you recommend an API for this task? \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Biomedical Image Segmentation', 'api_name': 'U-Net for brain MRI', 'api_call': \"torch.hub.load(repo_or_dir='mateuszbuda/brain-segmentation-pytorch', model='unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'api_arguments': {'in_channels': 3, 'out_channels': 1, 'init_features': 32, 'pretrained': True}, 'python_environment_requirements': ['torch', 'torchvision', 'numpy', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'import numpy as np', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'm, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))', 'preprocess = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=m, std=s)])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model = model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.round(output[0]))'], 'performance': {'dataset': 'kaggle.com/mateuszbuda/lgg-mri-segmentation'}, 'description': 'U-Net with batch normalization for biomedical image segmentation with pretrained weights for abnormality segmentation in brain MRI. The model comprises four levels of blocks containing two convolutional layers with batch normalization and ReLU activation function, and one max pooling layer in the encoding part and up-convolutional layers instead in the decoding part. The number of convolutional filters in each block is 32, 64, 128, and 256. The bottleneck layer has 512 convolutional filters. From the encoding layers, skip connections are used to the corresponding layers in the decoding part. Input image is a 3-channel brain MRI slice from pre-contrast, FLAIR, and post-contrast sequences, respectively. Output is a one-channel probability map of abnormality regions with the same size as the input image.'}", "category": "generic"}
{"question_id": 673, "text": "A prankster is building a fake celebrity face generator. Recommend an API that can generate realistic fake celebrity faces. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks (GANs)', 'api_name': 'PGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='PGAN', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'facebookresearch/pytorch_GAN_zoo:hub', 'model': 'PGAN', 'model_name': 'celebAHQ-512', 'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': 'import torch', 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'PGAN', model_name='celebAHQ-512', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'test': 'generated_images = model.test(noise)', 'plot_images': {'import_matplotlib': 'import matplotlib.pyplot as plt', 'import_torchvision': 'import torchvision', 'make_grid': 'grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1), scale_each=True, normalize=True)', 'imshow': 'plt.imshow(grid.permute(1, 2, 0).cpu().numpy())', 'show': 'plt.show()'}}, 'performance': {'dataset': 'celebA', 'accuracy': 'High-quality celebrity faces'}, 'description': \"Progressive Growing of GANs (PGAN) is a method for generating high-resolution images using generative adversarial networks. The model is trained progressively, starting with low-resolution images and gradually increasing the resolution until the desired output is achieved. This implementation is based on the paper by Tero Karras et al., 'Progressive Growing of GANs for Improved Quality, Stability, and Variation'.\"}", "category": "generic"}
{"question_id": 674, "text": "Abby wants to identify the objects present in her collection of images. Identify a model that can analyze Abby's images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeXt101-32x4d', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resneXt', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'validators', 'matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', 'device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")', \"print(f'Using {device} for inference')\", \"resneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resneXt')\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resneXt.eval().to(device)', 'uris = [', \" 'http://images.cocodataset.org/test-stuff2017/000000024309.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000028117.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000006149.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000004954.jpg',\", ']', 'batch = torch.cat(', ' [utils.prepare_input_from_uri(uri) for uri in uris]', ').to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resneXt(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'IMAGENET', 'accuracy': 'Not provided'}, 'description': 'ResNeXt101-32x4d is a model introduced in the Aggregated Residual Transformations for Deep Neural Networks paper. It is based on regular ResNet model, substituting 3x3 convolutions inside the bottleneck block for 3x3 grouped convolutions. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures. It can be deployed for inference on the NVIDIA Triton Inference Server using TorchScript, ONNX Runtime or TensorRT as an execution backend.'}", "category": "generic"}
{"question_id": 675, "text": "Imagine you received a huge dataset of unidentified animals, and you need to classify them according to their species. Provide me an API that can classify them given their image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'AlexNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='alexnet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 43.45, 'top-5_error': 20.91}}, 'description': 'AlexNet is a deep convolutional neural network that achieved a top-5 error of 15.3% in the 2012 ImageNet Large Scale Visual Recognition Challenge. The main contribution of the original paper was the depth of the model, which was computationally expensive but made feasible through the use of GPUs during training. The pretrained AlexNet model in PyTorch can be used for image classification tasks.'}", "category": "generic"}
{"question_id": 676, "text": "How can I get an accurate text classification model based on BERT but with improvements? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'RoBERTa', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq', model='roberta.large', pretrained=True)\", 'api_arguments': [\"'pytorch/fairseq'\", \"'roberta.large'\"], 'python_environment_requirements': ['regex', 'requests', 'hydra-core', 'omegaconf'], 'example_code': ['import torch', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\", 'roberta.eval()', \"tokens = roberta.encode('Hello world!')\", 'last_layer_features = roberta.extract_features(tokens)', 'all_layers = roberta.extract_features(tokens, return_all_hiddens=True)', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\", 'roberta.eval()', \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is not very optimized.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is based on BERT.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"roberta.register_classification_head('new_task', num_classes=3)\", \"logprobs = roberta.predict('new_task', tokens)\"], 'performance': {'dataset': 'MNLI', 'accuracy': 'N/A'}, 'description': \"RoBERTa is a robustly optimized version of BERT, a revolutionary self-supervised pretraining technique that learns to predict intentionally hidden (masked) sections of text. RoBERTa builds on BERT's language masking strategy and modifies key hyperparameters, including removing BERT's next-sentence pretraining objective, and training with much larger mini-batches and learning rates. RoBERTa was also trained on an order of magnitude more data than BERT, for a longer amount of time, allowing it to generalize even better to downstream tasks.\"}", "category": "generic"}
{"question_id": 677, "text": "I need an API to classify objects within images efficiently using mixed precision training for better performance. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SE-ResNeXt101', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_se_resnext101_32x4d', pretrained=True)\", 'api_arguments': 'N/A', 'python_environment_requirements': 'validators, matplotlib', 'example_code': \"import torch\\nfrom PIL import Image\\nimport torchvision.transforms as transforms\\nimport numpy as np\\nimport json\\nimport requests\\nimport matplotlib.pyplot as plt\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n%matplotlib inline\\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\nprint(f'Using {device} for inference')\\nresneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_se_resnext101_32x4d')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\nresneXt.eval().to(device)\\nuris = ['http://images.cocodataset.org/test-stuff2017/000000024309.jpg','http://images.cocodataset.org/test-stuff2017/000000028117.jpg','http://images.cocodataset.org/test-stuff2017/000000006149.jpg','http://images.cocodataset.org/test-stuff2017/000000004954.jpg']\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(resneXt(batch), dim=1)\\nresults = utils.pick_n_best(predictions=output, n=5)\\nfor uri, result in zip(uris, results):\\n img = Image.open(requests.get(uri, stream=True).raw)\\n img.thumbnail((256,256), Image.ANTIALIAS)\\n plt.imshow(img)\\n plt.show()\\n print(result)\", 'performance': {'dataset': 'IMAGENET', 'accuracy': 'N/A'}, 'description': 'The SE-ResNeXt101-32x4d is a ResNeXt101-32x4d model with added Squeeze-and-Excitation module. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures, which allows researchers to get results 3x faster than training without Tensor Cores while experiencing the benefits of mixed precision training.'}", "category": "generic"}
{"question_id": 678, "text": "Convert an English text to speech while preserving the naturalness of the voice. Recommend me a suitable API. \n Use this API documentation for reference: {'domain': 'Text-to-Speech', 'framework': 'PyTorch', 'functionality': 'Speech Synthesis', 'api_name': 'WaveGlow', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_waveglow', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_waveglow', 'model_math': 'fp32'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': {'load_waveglow_model': \"waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp32')\", 'prepare_waveglow_model': ['waveglow = waveglow.remove_weightnorm(waveglow)', \"waveglow = waveglow.to('cuda')\", 'waveglow.eval()'], 'load_tacotron2_model': \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp32')\", 'prepare_tacotron2_model': [\"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()'], 'synthesize_speech': ['text = \"hello world, I missed you so much\"', \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'save_audio': 'write(\"audio.wav\", rate, audio_numpy)', 'play_audio': 'Audio(audio_numpy, rate=rate)'}, 'performance': {'dataset': 'LJ Speech', 'accuracy': None}, 'description': 'The Tacotron 2 and WaveGlow model form a text-to-speech system that enables users to synthesize natural-sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 679, "text": "I am a data scientist who needs to classify images using a neural network with a dense structure. Recommend an API for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet121', pretrained=True)\", 'api_arguments': [{'name': 'densenet121', 'type': 'str', 'description': 'Densenet-121 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet121': {'Top-1 error': 25.35, 'Top-5 error': 7.83}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 680, "text": "I am building an image recognition app, and I need to classify objects in images. Which API should I use? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet169', pretrained=True)\", 'api_arguments': [{'name': 'densenet169', 'type': 'str', 'description': 'Densenet-169 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet169': {'Top-1 error': 24.0, 'Top-5 error': 7.0}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 681, "text": "I need an API suitable for classifying skin conditions based on images. What do you suggest? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet201', pretrained=True)\", 'api_arguments': [{'name': 'densenet201', 'type': 'str', 'description': 'Densenet-201 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet201': {'Top-1 error': 22.8, 'Top-5 error': 6.43}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 682, "text": "Which API do I use for segmenting objects in an image based on their class? \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet50', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet50': {'Mean IOU': 60.5, 'Global Pixelwise Accuracy': 91.4}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 683, "text": "I am developing an AI vacuum cleaner that can identify type of object on the floor so it can avoid it. I am looking for an API to help me in idenfifying common objects like shoes, toys, type of dirt. You may assume I already have pictures of the floor. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet161', pretrained=True)\", 'api_arguments': [{'name': 'densenet161', 'type': 'str', 'description': 'Densenet-161 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet161', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet161': {'Top-1 error': 22.35, 'Top-5 error': 6.2}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 684, "text": "I am working on environmental analysis and I want to analyze each pixel in an aerial image and identify its class. What API could help me with that? \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet101', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet101': {'Mean IOU': 63.7, 'Global Pixelwise Accuracy': 91.9}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 685, "text": "I'm looking for a computationally efficient image classifier. Please suggest a suitable API for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet39ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet39ds', 'type': 'str', 'description': 'HarDNet-39DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet39ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet39ds': {'Top-1 error': 27.92, 'Top-5 error': 9.57}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 686, "text": "I have a collection of images to classify. Can you suggest an API with good accuracy and less computational cost? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68', 'type': 'str', 'description': 'HarDNet-68 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68': {'Top-1 error': 23.52, 'Top-5 error': 6.99}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory trafficCNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 687, "text": "I am trying to design an app that can classify shoes, clothes, and other fashion items from images taken by users. Recommend me an API that can perform this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68ds', 'type': 'str', 'description': 'HarDNet-68DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68ds': {'Top-1 error': 25.71, 'Top-5 error': 8.13}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 688, "text": "Recommend me an API to classify images of cats and dogs. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet85', pretrained=True)\", 'api_arguments': [{'name': 'hardnet85', 'type': 'str', 'description': 'HarDNet-85 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet85', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet85': {'Top-1 error': 21.96, 'Top-5 error': 6.11}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 689, "text": "Tell me an API that can classify photos of plants into their respective species. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'GoogLeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='googlenet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.0.0', 'torchvision': '>=0.2.2'}, 'example_code': {'import': ['import torch', 'import urllib', 'from PIL import Image', 'from torchvision import transforms'], 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\", 'model_eval': 'model.eval()', 'image_preprocessing': ['input_image = Image.open(filename)', 'preprocess = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'model_execution': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'output_processing': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'top5_prob, top5_catid = torch.topk(probabilities, 5)']}, 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 error': '30.22', 'Top-5 error': '10.47'}}, 'description': \"GoogLeNet is based on a deep convolutional neural network architecture codenamed 'Inception', which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014).\"}", "category": "generic"}
{"question_id": 690, "text": "I need an API for classifying types of plants through an image. Write me an example. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet50_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet50_ibn_a', 'type': 'str', 'description': 'ResNet-50-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet50_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet50_ibn_a': {'Top-1 acc': 77.46, 'Top-5 acc': 93.68}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 691, "text": "Help me find an API that can recognise appearances and domains in cross domain tasks like person or vehicle re-identification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet101_ibn_a', 'type': 'str', 'description': 'ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet101_ibn_a': {'Top-1 acc': 78.61, 'Top-5 acc': 94.41}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 692, "text": "One of the largest retailers, Walmart, wants to develop a system for automating price audits to replace the manual way of checking prices. Suggest an API that can identify items in a picture and compare them with data from the server to achieve the retailer's goal. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Efficient networks by generating more features from cheap operations', 'api_name': 'GhostNet', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/ghostnet', model='ghostnet_1x', pretrained=True)\", 'api_arguments': ['pretrained'], 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/ghostnet', 'ghostnet_1x', pretrained=True)\", 'model.eval()', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 acc': '73.98', 'Top-5 acc': '91.46'}}, 'description': 'The GhostNet architecture is based on an Ghost module structure which generates more features from cheap operations. Based on a set of intrinsic feature maps, a series of cheap operations are applied to generate many ghost feature maps that could fully reveal information underlying intrinsic features. Experiments conducted on benchmarks demonstrate the superiority of GhostNet in terms of speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 693, "text": "Identify an API that can deal with vehicle re-identification tasks. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnext101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_ibn_a', 'type': 'str', 'description': 'ResNeXt-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnext101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext101_ibn_a': {'Top-1 acc': 79.12, 'Top-5 acc': 94.58}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 694, "text": "I need an AI-based image recognition technology to enhance a photo journal app. Please recommend an API. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'Inception_v3', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='inception_v3', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '1.9.0', 'torchvision': '0.10.0'}, 'example_code': {'import_libraries': 'import torch', 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\", 'model_evaluation': 'model.eval()'}, 'performance': {'dataset': 'imagenet', 'accuracy': {'top-1_error': 22.55, 'top-5_error': 6.44}}, 'description': 'Inception v3, also called GoogleNetv3, is a famous Convolutional Neural Network trained on the ImageNet dataset from 2015. It is based on the exploration of ways to scale up networks to utilize the added computation as efficiently as possible by using suitably factorized convolutions and aggressive regularization. The model achieves a top-1 error of 22.55% and a top-5 error of 6.44% on the ImageNet dataset.'}", "category": "generic"}
{"question_id": 695, "text": "I'm facing a classification problem that involves a high level of domain adaptation. Suggest me an API that suits my task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='se_resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'se_resnet101_ibn_a', 'type': 'str', 'description': 'SE-ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'se_resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'se_resnet101_ibn_a': {'Top-1 acc': 78.75, 'Top-5 acc': 94.49}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 696, "text": "I want to create a model that can classify a large dataset of images into 1000 different classes. Recommend an API for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest101', pretrained=True)\", 'api_arguments': 'resnest101', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-101': 82.83}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 697, "text": "Looking for an API that can classify thousands of different species of flowers from an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest50', pretrained=True)\", 'api_arguments': 'resnest50', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-50': 81.03}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 698, "text": "Recommend an image classification API that can accurately predict items in a given image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest269', pretrained=True)\", 'api_arguments': 'resnest269', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest269', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-269': 84.54}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 699, "text": "I need to know which API would be suitable to perform image classification on CPU optimized hardware. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_cpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_cpu', 'type': 'str', 'description': 'ProxylessNAS optimized for CPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_cpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_cpu', 'accuracy': 75.3}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 700, "text": "I am designing a wildlife preservation journal that needs to categorize pictures of different animal species. Suggest a machine learning API to classify the animal species in a given image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest200', pretrained=True)\", 'api_arguments': 'resnest200', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest200', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-200': 83.84}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 701, "text": "Create a mobile application that optimizes image classification. Recommend an API that I can use for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_mobile', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_mobile', 'type': 'str', 'description': 'ProxylessNAS optimized for Mobile'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_mobile'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_mobile', 'accuracy': 74.6}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 702, "text": "I require a lightweight API that can perform image classification on mobile devices. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MobileNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='mobilenet_v2', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 28.12, 'top-5_error': 9.71}}, 'description': 'The MobileNet v2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input. MobileNet v2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, non-linearities in the narrow layers were removed in order to maintain representational power.'}", "category": "generic"}
{"question_id": 703, "text": "I need help selecting an API that can classify an image based on an optimized CNN architecture for GPU devices. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_gpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_gpu', 'type': 'str', 'description': 'ProxylessNAS optimized for GPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_gpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_gpu', 'accuracy': 75.1}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 704, "text": "I need to execute an image classification API that can identify objects in a given image. Recommend an API and show me how to use it. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet18', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet18', 'top-1_error': 30.24, 'top-5_error': 10.92}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 705, "text": "Suggest an API that can help me identify objects in an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet101', 'top-1_error': 22.63, 'top-5_error': 6.44}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 706, "text": "Find me a pre-trained model for general image recognition that I can use for an e-commerce website's product categorization. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet34', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet34', 'top-1_error': 26.7, 'top-5_error': 8.58}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 707, "text": "I want to classify an image using a pre-trained deep learning model. Find me an API I could use. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet152', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet152', 'top-1_error': 21.69, 'top-5_error': 5.94}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 708, "text": "I am working on building a dog breed identification app, recommend an API that can be used for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet50', 'top-1_error': 23.85, 'top-5_error': 7.13}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 709, "text": "I would like an API that can classify land animals from an image using the latest deep learning techniques. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext50_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext50_32x4d': {'top-1': 22.38, 'top-5': 6.3}}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 710, "text": "A wildlife photographer needs an API to help in sorting birds and mammals in his photo collection. Suggest an API. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext101_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext101_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'resnext101_32x8d': {'top-1': 20.69, 'top-5': 5.47}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 711, "text": "Identify a library API suitable for classifying images with high accuracy while keeping FLOPs low. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_t', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_t', 'type': 'str', 'description': 'SNNMLP Tiny model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_t', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Tiny', 'top-1': 81.88}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 712, "text": "I want to classify an image with a neural network that has lower operation complexity. What's the best API to use? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_s', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_s', 'type': 'str', 'description': 'SNNMLP Small model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_s', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Small', 'top-1': 83.3}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 713, "text": "Is there an API I can use for image categorization in a mobile app? I need it to be lightweight and fast. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_1', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_1'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_1': {'Top-1 error': 41.81, 'Top-5 error': 19.38}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 714, "text": "I am an independent developer working on a chatbot. I need my chatbot to identify what is in the user's picture. Suggest an pre-trained API that can classify objects in an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ShuffleNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='shufflenet_v2_x1_0', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'torch', 'torchvision': 'torchvision', 'PIL': 'Image', 'urllib': 'urllib'}, 'example_code': {'import_libraries': ['import torch', 'from PIL import Image', 'from torchvision import transforms', 'import urllib'], 'load_model': [\"model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\", 'model.eval()'], 'load_image': [\"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'try: urllib.URLopener().retrieve(url, filename)', 'except: urllib.request.urlretrieve(url, filename)', 'input_image = Image.open(filename)'], 'preprocess_image': ['preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'run_inference': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'get_probabilities': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'top_categories': ['top5_prob, top5_catid = torch.topk(probabilities, 5)', 'for i in range(top5_prob.size(0)):', ' print(categories[top5_catid[i]], top5_prob[i].item())']}, 'performance': {'dataset': 'Imagenet', 'accuracy': {'top-1_error': 30.64, 'top-5_error': 11.68}}, 'description': 'ShuffleNet V2 is an efficient ConvNet optimized for speed and memory, pre-trained on Imagenet. It is designed based on practical guidelines for efficient network design, including speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 715, "text": "I need an image classification API for a robot that can recognize an object in real time with high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_b', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_b', 'type': 'str', 'description': 'SNNMLP Base model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_b', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Base', 'top-1': 85.59}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 716, "text": "A retail analyst wants to process an image containing a collection of consumer products and classify the objects in the image. Find an API that helps categorize the objects in the image and provide a confidence score for each category., 'Input': '<noinput>' \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_0', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_0'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_0': {'Top-1 error': 41.9, 'Top-5 error': 19.58}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 717, "text": "I am building a photo app and I need an API that can classify images into categories. Do you have any suggestions? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13', pretrained=True)\", 'api_arguments': [{'name': 'vgg13', 'type': 'str', 'description': 'VGG13 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13': {'Top-1 error': 30.07, 'Top-5 error': 10.75}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn,vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 718, "text": "Develop a mobile app which can identify 1000 objects based on the camera, provide an API that can be used to develop it. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg11_bn', 'type': 'str', 'description': 'VGG11 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11_bn': {'Top-1 error': 26.7, 'Top-5 error': 8.58}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 719, "text": "A team is working on automatically tagging animals in pictures taken by wildlife cameras. Provide an API for a model that can perform this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11', pretrained=True)\", 'api_arguments': [{'name': 'vgg11', 'type': 'str', 'description': 'VGG11 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11': {'Top-1 error': 30.98, 'Top-5 error': 11.37}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 720, "text": "I want to recognize objects in images using a VGG13 model with batch normalization. What API should I use for this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg13_bn', 'type': 'str', 'description': 'VGG13 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13_bn': {'Top-1 error': 28.45, 'Top-5 error': 9.63}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 721, "text": "Identify an API that can recognize objects inside photos. Ensure that it is pretrained and ready for use. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg16_bn', 'type': 'str', 'description': 'VGG16 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16_bn': {'Top-1 error': 26.63, 'Top-5 error': 8.5}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 722, "text": "Identify an API that can recognize what type of buildings are in an image.  \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19', pretrained=True)\", 'api_arguments': [{'name': 'vgg19', 'type': 'str', 'description': 'VGG19 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19': {'Top-1 error': 27.62, 'Top-5 error': 9.12}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 723, "text": "Can you recommend an API that can recognize objects in images, like different species of animals? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16', pretrained=True)\", 'api_arguments': [{'name': 'vgg16', 'type': 'str', 'description': 'VGG16 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16': {'Top-1 error': 28.41, 'Top-5 error': 9.62}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 724, "text": "An automotive website has different types of vehicles in a gallery; they want to automatically classify these vehicles into different categories based on an image. Tell me how to achieve this using an API. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg19_bn', 'type': 'str', 'description': 'VGG19 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19_bn': {'Top-1 error': 25.76, 'Top-5 error': 8.15}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 725, "text": "Generate code that will help me classify different dog breeds in a photo. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet101_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet101_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet101_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet101_2': {'Top-1 error': 21.16, 'Top-5 error': 5.72}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 726, "text": "I need an API that can help me classify various objects in an image from a popular repository. Provide a pretrained model for the same. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet50_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet50_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet50_2': {'Top-1 error': 21.49, 'Top-5 error': 5.91}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 727, "text": "As a content moderator, I need to classify videos into categories Automatically. Please suggest an API for performing this task. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'SlowFast Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slowfast_r50', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'slowfast_r50', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 76.94, 'top5': 92.69}, 'flops': 65.71, 'params': 34.57}, 'description': \"Slow Fast model architectures are based on the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al. They are pretrained on the Kinetics 400 dataset using the 8x8 setting. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 728, "text": "Tell me an API that can classify a video clip according to the action in the clip. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'X3D Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='x3d_s', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'x3d_s', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_s', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 73.33, 'top5': 91.27}, 'flops': 2.96, 'params': 3.79}, 'description': \"X3D model architectures are based on the paper 'X3D: Expanding Architectures for Efficient Video Recognition' by Christoph Feichtenhofer. They are pretrained on the Kinetics 400 dataset. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 729, "text": "Is there an NLP API that can summarize long articles or documents? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Natural Language Processing', 'api_name': 'PyTorch-Transformers', 'api_call': \"torch.hub.load(repo_or_dir='huggingface/pytorch-transformers')\", 'api_arguments': ['pretrained_model_or_path', 'output_attention', 'output_hidden_states', 'config', 'from_tf'], 'python_environment_requirements': ['tqdm', 'boto3', 'requests', 'regex', 'sentencepiece', 'sacremoses'], 'example_code': 'import torch\\ntokenizer = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'tokenizer\\', \\'bert-base-cased\\')\\n\\ntext_1 = \"Jim Henson was a puppeteer\"\\ntext_2 = \"Who was Jim Henson ?\"\\n\\nindexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\\n\\nmodel = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'model\\', \\'bert-base-cased\\')\\n\\nwith torch.no_grad():\\n encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)', 'performance': {'dataset': [{'name': 'MRPC', 'accuracy': 'Not provided'}]}, 'description': 'PyTorch-Transformers is a library of state-of-the-art pre-trained models for Natural Language Processing (NLP) including BERT, GPT, GPT-2, Transformer-XL, XLNet, XLM, RoBERTa, and DistilBERT. The library provides functionality for tokenization, configuration, and various model architectures for different tasks such as causal language modeling, sequence classification, question answering, and masked language modeling.'}", "category": "generic"}
{"question_id": 730, "text": "Suggest a machine learning API that can be used to analyze images of protein structures to predict their cellular localization. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Semi-supervised and semi-weakly supervised ImageNet Models', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/semi-supervised-ImageNet1K-models', model='resnet18_swsl', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/semi-supervised-ImageNet1K-models', 'model': 'resnet18_swsl', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl', pretrained=True)\", 'model.eval()'], 'performance': {'description': 'Semi-supervised and semi-weakly supervised ImageNet models achieve state-of-the-art accuracy of 81.2% on ImageNet for the widely used/adopted ResNet-50 model architecture.'}, 'description': \"Semi-supervised and semi-weakly supervised ImageNet Models are introduced in the 'Billion scale semi-supervised learning for image classification' paper. These models are pretrained on a subset of unlabeled YFCC100M public image dataset and fine-tuned with the ImageNet1K training dataset. They are capable of classifying images into different categories and are provided by the Facebook Research library.\"}", "category": "generic"}
{"question_id": 731, "text": "I\u2019m working on a mobile app, and I need an efficient neural network for image classification. What API should I use? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Once-for-all (OFA) Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/once-for-all', model='ofa_supernet_mbv3_w10', pretrained=True)\", 'api_arguments': {'repository': 'mit-han-lab/once-for-all', 'model': 'ofa_supernet_mbv3_w10', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"super_net_name = 'ofa_supernet_mbv3_w10'\", \"super_net = torch.hub.load('mit-han-lab/once-for-all', super_net_name, pretrained=True).eval()\"], 'performance': {'description': 'OFA networks outperform state-of-the-art NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x faster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency) while reducing many orders of magnitude GPU hours and CO2 emission.'}, 'description': 'Once-for-all (OFA) networks are a family of neural networks designed by MIT Han Lab. They decouple training and search, achieving efficient inference across various edge devices and resource constraints. OFA networks are pretrained on the IMAGENET dataset and are capable of classifying images into different categories.'}", "category": "generic"}
{"question_id": 732, "text": "I work at NVIDIA and need an API to classify images using GPUNet architecture optimized for TensorRT performance. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'GPUNet Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", 'api_arguments': {'repository': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_gpunet', 'pretrained': 'True', 'model_type': 'GPUNet-0', 'model_math': 'fp32'}, 'python_environment_requirements': ['torch', 'validators', 'matplotlib', 'timm==0.5.4'], 'example_code': ['import torch', \"model_type = 'GPUNet-0'\", \"precision = 'fp32'\", \"gpunet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'gpunet.to(device)', 'gpunet.eval()'], 'performance': {'dataset': 'IMAGENET', 'description': 'GPUNet demonstrates state-of-the-art inference performance up to 2x faster than EfficientNet-X and FBNet-V3.'}, 'description': 'GPUNet is a family of Convolutional Neural Networks designed by NVIDIA using novel Neural Architecture Search (NAS) methods. They are optimized for NVIDIA GPU and TensorRT performance. GPUNet models are pretrained on the IMAGENET dataset and are capable of classifying images into different categories. The models are provided by the NVIDIA Deep Learning Examples library.'}", "category": "generic"}
{"question_id": 733, "text": "SmartToyY is working on a project that tells information about a toy based on its picture. Give an AI API that can classify an image into categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'EfficientNet', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_efficientnet_b0', pretrained=True)\", 'api_arguments': ['model_name', 'pretrained'], 'python_environment_requirements': ['validators', 'matplotlib'], 'example_code': \"import torch\\n\\nefficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\n\\nefficientnet.eval().to(device)\\n\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\n\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(efficientnet(batch), dim=1)\\n \\nresults = utils.pick_n_best(predictions=output, n=5)\", 'performance': {'dataset': {'name': 'IMAGENET', 'accuracy': 'Not provided'}}, 'description': 'EfficientNet is a family of image classification models that achieve state-of-the-art accuracy while being smaller and faster. The models are trained with mixed precision using Tensor Cores on the NVIDIA Volta and Ampere GPU architectures. The EfficientNet models include EfficientNet-B0, EfficientNet-B4, EfficientNet-WideSE-B0, and EfficientNet-WideSE-B4. The WideSE models use wider Squeeze-and-Excitation layers than the original EfficientNet models, resulting in slightly better accuracy.'}", "category": "generic"}
{"question_id": 734, "text": "I need to translate some English text to French, suggest an API to help me with that. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Neural Machine Translation', 'api_name': 'Transformer (NMT)', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq')\", 'api_arguments': ['model_name', 'tokenizer', 'bpe', 'beam', 'sampling', 'sampling_topk'], 'python_environment_requirements': ['bitarray', 'fastBPE', 'hydra-core', 'omegaconf', 'regex', 'requests', 'sacremoses', 'subword_nmt'], 'example_code': \"import torch\\n\\nen2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\\n\\nen2fr.cuda()\\n\\nfr = en2fr.translate('Hello world!', beam=5)\\nassert fr == 'Bonjour \u00e0 tous !'\", 'performance': {'dataset': [{'name': \"WMT'14\", 'accuracy': 'Not provided'}, {'name': \"WMT'18\", 'accuracy': 'Not provided'}, {'name': \"WMT'19\", 'accuracy': 'Not provided'}]}, 'description': \"Transformer (NMT) is a powerful sequence-to-sequence modeling architecture that produces state-of-the-art neural machine translation systems. It is based on the paper 'Attention Is All You Need' and has been improved using techniques such as large-scale semi-supervised training, back-translation, and noisy-channel reranking. It supports English-French and English-German translation as well as round-trip translation for paraphrasing.\"}", "category": "generic"}
{"question_id": 735, "text": "The Amazon security team wants to auto-detect unattended package left at their headquarters. Propose an API that can detect objects in images. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Single Shot MultiBox Detector', 'api_name': 'SSD', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_ssd', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['numpy', 'scipy', 'scikit-image', 'matplotlib'], 'example_code': \"import torch\\n\\nssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\\n\\nssd_model.to('cuda')\\nssd_model.eval()\\n\\ninputs = [utils.prepare_input(uri) for uri in uris]\\ntensor = utils.prepare_tensor(inputs)\\n\\nwith torch.no_grad():\\n detections_batch = ssd_model(tensor)\\n\\nresults_per_input = utils.decode_results(detections_batch)\\nbest_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\", 'performance': {'dataset': {'name': 'COCO', 'accuracy': 'Not provided'}}, 'description': \"The SSD (Single Shot MultiBox Detector) model is an object detection model based on the paper 'SSD: Single Shot MultiBox Detector'. It uses a deep neural network for detecting objects in images. This implementation replaces the obsolete VGG model backbone with the more modern ResNet-50 model. The SSD model is trained on the COCO dataset and can be used to detect objects in images with high accuracy and efficiency.\"}", "category": "generic"}
{"question_id": 736, "text": "What machine learning API should I use to convert a text to speech? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Text-to-Speech', 'api_name': 'Tacotron 2', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_tacotron2', model_math='fp16')\", 'api_arguments': {'model_math': 'fp16'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': ['import torch', \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\", \"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()', \"text = 'Hello world, I missed you so much.'\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'performance': {'dataset': 'LJ Speech', 'accuracy': 'Not specified'}, 'description': 'The Tacotron 2 model generates mel spectrograms from input text using an encoder-decoder architecture, and it is designed for generating natural-sounding speech from raw transcripts without any additional prosody information. This implementation uses Dropout instead of Zoneout to regularize the LSTM layers. The WaveGlow model (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 737, "text": "I need an efficient image classification API that can be used to recognize complex objects in images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.67', 'top5': '95.09'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 738, "text": "The Vegan Society is doing research on vegan products by automatically labeling Instagram images depicting different types of food. Provide an API that can identify and classify objects in an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V1', model='mealv1_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv1_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V1 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '78.21', 'top5': '94.01'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 739, "text": "Recommend an API to enhance classification accuracy for a popular machine learning model for tagging animals in images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_cutmix', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_cutmix'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 + CutMix w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.98', 'top5': '95.35'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 740, "text": "Design a machine learning API to identify the type of objects present in an image with high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_075', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_075'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 0.75', 'resolution': '224', 'parameters': '2.04M', 'top1': '67.60', 'top5': '87.23'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 741, "text": "Create a tool to predict what would be in an image taken outdoors in the wild, and recommend an API that could accomplish this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_380x380', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_380x380'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '380', 'parameters': '25.6M', 'top1': '81.72', 'top5': '95.81'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 742, "text": "Recommend an API that can identify different breeds of dogs from photographs. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_efficientnet_b0', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_efficientnet_b0'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ EfficientNet-B0', 'resolution': '224', 'parameters': '5.29M', 'top1': '78.29', 'top5': '93.95'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 743, "text": "Recommend an API to classify images with a high level of accuracy without using any tricks. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 1.0', 'resolution': '224', 'parameters': '2.54M', 'top1': '69.65', 'top5': '88.71'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 744, "text": "I'm an app developer and I need an API to classify which type of animal is in a particular image. What do you suggest? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenet_v3_large_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenet_v3_large_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Large 1.0', 'resolution': '224', 'parameters': '5.48M', 'top1': '76.92', 'top5': '93.32'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 745, "text": "Suggest a pre-trained video classification model capable of classifying human actions in a video. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorch', 'functionality': '3D ResNet', 'api_name': 'slow_r50', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slow_r50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'json', 'urllib', 'pytorchvideo', 'torchvision', 'torchaudio', 'torchtext', 'torcharrow', 'TorchData', 'TorchRec', 'TorchServe', 'PyTorch on XLA Devices'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top_1': 74.58, 'top_5': 91.63}, 'Flops (G)': 54.52, 'Params (M)': 32.45}, 'description': \"The 3D ResNet model is a Resnet-style video classification network pretrained on the Kinetics 400 dataset. It is based on the architecture from the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al.\"}", "category": "generic"}
{"question_id": 746, "text": "I need an API capable of detecting vehicles, drivable areas, and lane lines from images taken from a dashboard camera. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Traffic Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'HybridNets', 'api_call': \"torch.hub.load(repo_or_dir='datvuthanh/hybridnets', model='hybridnets', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'Python>=3.7, PyTorch>=1.10', 'example_code': \"import torch\\nmodel = torch.hub.load('datvuthanh/hybridnets', 'hybridnets', pretrained=True)\\nimg = torch.randn(1,3,640,384)\\nfeatures, regression, classification, anchors, segmentation = model(img)\", 'performance': {'dataset': [{'name': 'BDD100K', 'accuracy': {'Traffic Object Detection': {'Recall (%)': 92.8, 'mAP@0.5 (%)': 77.3}, 'Drivable Area Segmentation': {'Drivable mIoU (%)': 90.5}, 'Lane Line Detection': {'Accuracy (%)': 85.4, 'Lane Line IoU (%)': 31.6}}}]}, 'description': 'HybridNets is an end2end perception network for multi-tasks. Our work focused on traffic object detection, drivable area segmentation and lane detection. HybridNets can run real-time on embedded systems, and obtains SOTA Object Detection, Lane Detection on BDD100K Dataset.'}", "category": "generic"}
{"question_id": 747, "text": "Help me to find an API to assist autonomous vehicles providing object detection, drivable area segmentation and lane detection for safer navigation. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'YOLOP', 'api_call': \"torch.hub.load(repo_or_dir='hustvl/yolop', model='yolop', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'pip install -qr https://github.com/hustvl/YOLOP/blob/main/requirements.txt', 'example_code': \"import torch\\nmodel = torch.hub.load('hustvl/yolop', 'yolop', pretrained=True)\\nimg = torch.randn(1,3,640,640)\\ndet_out, da_seg_out,ll_seg_out = model(img)\", 'performance': {'dataset': 'BDD100K', 'accuracy': {'Object Detection': {'Recall(%)': 89.2, 'mAP50(%)': 76.5, 'Speed(fps)': 41}, 'Drivable Area Segmentation': {'mIOU(%)': 91.5, 'Speed(fps)': 41}, 'Lane Detection': {'mIOU(%)': 70.5, 'IOU(%)': 26.2}}}, 'description': 'YOLOP is an efficient multi-task network that can jointly handle three crucial tasks in autonomous driving: object detection, drivable area segmentation and lane detection. And it is also the first to reach real-time on embedded devices while maintaining state-of-the-art level performance on the BDD100K dataset.'}", "category": "generic"}
{"question_id": 748, "text": "I want an API that can deliver relative depth information from a single photo. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='MiDaS_small', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 749, "text": "Suppose I have to design an autonomous car which uses a depth perception system. Suggest me an API which can compute relative depth from a single image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Large', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Large')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 750, "text": "I have a single image and want to compute its depth map. Suggest me an API for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Hybrid', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Hybrid')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 751, "text": "How can I extract the vocal track and other stems from a song's audio? Suggest an API for this. \n Use this API documentation for reference: {'domain': 'Audio Separation', 'framework': 'PyTorch', 'functionality': 'Music Source Separation', 'api_name': 'Open-Unmix', 'api_call': \"torch.hub.load(repo_or_dir='sigsep/open-unmix-pytorch', model='umxhq', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['PyTorch >=1.6.0', 'torchaudio'], 'example_code': ['import torch', \"separator = torch.hub.load('sigsep/open-unmix-pytorch', 'umxhq')\", 'audio = torch.rand((1, 2, 100000))', 'original_sample_rate = separator.sample_rate', 'estimates = separator(audio)'], 'performance': {'dataset': 'MUSDB18', 'accuracy': 'N/A'}, 'description': 'Open-Unmix provides ready-to-use models that allow users to separate pop music into four stems: vocals, drums, bass and the remaining other instruments. The models were pre-trained on the freely available MUSDB18 dataset.'}", "category": "generic"}
{"question_id": 752, "text": "Can you find me an API that identifies a species of bird from an image? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Fine-grained image classifier', 'api_name': 'ntsnet', 'api_call': \"torch.hub.load(repo_or_dir='nicolalandro/ntsnet-cub200', model='ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\", 'api_arguments': {'pretrained': 'True', 'topN': '6', 'device': 'cpu', 'num_classes': '200'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': \"from torchvision import transforms\\nimport torch\\nimport urllib\\nfrom PIL import Image\\n\\ntransform_test = transforms.Compose([\\n transforms.Resize((600, 600), Image.BILINEAR),\\n transforms.CenterCrop((448, 448)),\\n transforms.ToTensor(),\\n transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\\n])\\n\\nmodel = torch.hub.load('nicolalandro/ntsnet-cub200', 'ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\\nmodel.eval()\\n\\nurl = 'https://raw.githubusercontent.com/nicolalandro/ntsnet-cub200/master/images/nts-net.png'\\nimg = Image.open(urllib.request.urlopen(url))\\nscaled_img = transform_test(img)\\ntorch_images = scaled_img.unsqueeze(0)\\n\\nwith torch.no_grad():\\n top_n_coordinates, concat_out, raw_logits, concat_logits, part_logits, top_n_index, top_n_prob = model(torch_images)\\n\\n_, predict = torch.max(concat_logits, 1)\\npred_id = predict.item()\\nprint('bird class:', model.bird_classes[pred_id])\", 'performance': {'dataset': 'CUB200 2011', 'accuracy': 'Not provided'}, 'description': 'This is an nts-net pretrained with CUB200 2011 dataset, which is a fine-grained dataset of birds species.'}", "category": "generic"}
{"question_id": 753, "text": "I have a voice assistant project and I want to convert the user's speech to text. Can you recommend an API suitable for this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Speech-To-Text', 'api_name': 'Silero Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_stt', 'language': ['en', 'de', 'es'], 'device': 'device'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf soundfile'], 'example_code': ['import torch', 'import zipfile', 'import torchaudio', 'from glob import glob', \"device = torch.device('cpu')\", \"model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', language='en', device=device)\", '(read_batch, split_into_batches, read_audio, prepare_model_input) = utils', \"torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav', dst ='speech_orig.wav', progress=True)\", \"test_files = glob('speech_orig.wav')\", 'batches = split_into_batches(test_files, batch_size=10)', 'input = prepare_model_input(read_batch(batches[0]), device=device)', 'output = model(input)', 'for example in output:', ' print(decoder(example.cpu()))'], 'performance': {'dataset': 'Open-STT', 'accuracy': 'See the wiki for quality and performance benchmarks'}, 'description': 'Silero Speech-To-Text models provide enterprise grade STT in a compact form-factor for several commonly spoken languages. The models are robust to a variety of dialects, codecs, domains, noises, and lower sampling rates. They consume a normalized audio in the form of samples and output frames with token probabilities. A decoder utility is provided for simplicity.'}", "category": "generic"}
{"question_id": 754, "text": "Suggest an API that converts a given text into human-like speech in English. \n Use this API documentation for reference: {'domain': 'Text-To-Speech', 'framework': 'PyTorch', 'functionality': 'Text-To-Speech', 'api_name': 'Silero Text-To-Speech Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_tts', 'language': 'language', 'speaker': 'speaker'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf'], 'example_code': \"import torch\\nlanguage = 'en'\\nspeaker = 'lj_16khz'\\ndevice = torch.device('cpu')\\nmodel, symbols, sample_rate, example_text, apply_tts = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', language=language, speaker=speaker)\\nmodel = model.to(device)\\naudio = apply_tts(texts=[example_text], model=model, sample_rate=sample_rate, symbols=symbols, device=device)\", 'performance': {'dataset': [{'language': 'Russian', 'speakers': 6}, {'language': 'English', 'speakers': 1}, {'language': 'German', 'speakers': 1}, {'language': 'Spanish', 'speakers': 1}, {'language': 'French', 'speakers': 1}], 'accuracy': 'High throughput on slow hardware. Decent performance on one CPU thread'}, 'description': 'Silero Text-To-Speech models provide enterprise grade TTS in a compact form-factor for several commonly spoken languages. They offer one-line usage, naturally sounding speech, no GPU or training required, minimalism and lack of dependencies, a library of voices in many languages, support for 16kHz and 8kHz out of the box.'}", "category": "generic"}
{"question_id": 755, "text": "Recommend me an API for detecting the presence of speech in a given audio file. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Voice Activity Detection', 'api_name': 'Silero Voice Activity Detector', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-vad', 'model': 'silero_vad', 'force_reload': 'True'}, 'python_environment_requirements': {'torchaudio': 'pip install -q torchaudio'}, 'example_code': {'import': ['import torch', 'torch.set_num_threads(1)', 'from IPython.display import Audio', 'from pprint import pprint'], 'download_example': \"torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\", 'load_model': \"model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'load_utils': '(get_speech_timestamps, _, read_audio, _) = utils', 'set_sampling_rate': 'sampling_rate = 16000', 'read_audio': \"wav = read_audio('en_example.wav', sampling_rate=sampling_rate)\", 'get_speech_timestamps': 'speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sampling_rate)', 'print_speech_timestamps': 'pprint(speech_timestamps)'}, 'performance': {'dataset': '', 'accuracy': ''}, 'description': 'Silero VAD is a pre-trained enterprise-grade Voice Activity Detector (VAD) that aims to provide a high-quality and modern alternative to the WebRTC Voice Activity Detector. The model is optimized for performance on 1 CPU thread and is quantized.'}", "category": "generic"}
{"question_id": 756, "text": "I need to extract objects from a picture of a city scene. Provide me with an API that can output the segmented objects from an image. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet101', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet101', 'Mean IOU': 67.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 757, "text": "Develop an API that detects objects in an image given the URL of the image. The API should work with high accuracy. \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'YOLOv5', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='ultralytics/yolov5', model='yolov5s', pretrained=True)\", 'api_arguments': [\"'ultralytics/yolov5'\", \"'yolov5s'\", 'pretrained=True'], 'python_environment_requirements': 'Python>=3.8, PyTorch>=1.7', 'example_code': ['import torch', \"model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\", \"imgs = ['https://ultralytics.com/images/zidane.jpg']\", 'results = model(imgs)', 'results.print()', 'results.save()', 'results.xyxy[0]', 'results.pandas().xyxy[0]'], 'performance': {'dataset': 'COCO', 'accuracy': {'YOLOv5s6': {'mAPval0.5:0.95': 43.3, 'mAPtest0.5:0.95': 43.3, 'mAPval0.5': 61.9}, 'YOLOv5m6': {'mAPval0.5:0.95': 50.5, 'mAPtest0.5:0.95': 50.5, 'mAPval0.5': 68.7}, 'YOLOv5l6': {'mAPval0.5:0.95': 53.4, 'mAPtest0.5:0.95': 53.4, 'mAPval0.5': 71.1}, 'YOLOv5x6': {'mAPval0.5:0.95': 54.4, 'mAPtest0.5:0.95': 54.4, 'mAPval0.5': 72.0}, 'YOLOv5x6 TTA': {'mAPval0.5:0.95': 55.0, 'mAPtest0.5:0.95': 55.0, 'mAPval0.5': 72.0}}}, 'description': 'YOLOv5 is a family of compound-scaled object detection models trained on the COCO dataset, and includes simple functionality for Test Time Augmentation (TTA), model ensembling, hyperparameter evolution, and export to ONNX, CoreML and TFLite.'}", "category": "generic"}
{"question_id": 758, "text": "Find an API to correctly classify my travel photos based on the displayed location. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x16d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x16d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x16d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x16d': {'Top-1 Acc.': '84.2', 'Top-5 Acc.': '97.2'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 759, "text": "Recommend an API for identifying different objects in a single image, such as furniture, appliances or even food. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x8d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x8d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x8d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x8d': {'Top-1 Acc.': '82.2', 'Top-5 Acc.': '96.4'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 760, "text": "Develop a model to generate new clothing design samples using GAN (Generative Adversarial Networks). \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks', 'api_name': 'DCGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='DCGAN', pretrained=True, useGPU=use_gpu)\", 'api_arguments': {'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': ['import torch', 'import matplotlib.pyplot as plt', 'import torchvision'], 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'generate_images': 'with torch.no_grad(): generated_images = model.test(noise)', 'plot_images': ['plt.imshow(torchvision.utils.make_grid(generated_images).permute(1, 2, 0).cpu().numpy())', 'plt.show()']}, 'performance': {'dataset': 'FashionGen', 'accuracy': 'N/A'}, 'description': 'DCGAN is a model designed in 2015 by Radford et. al. in the paper Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. It is a GAN architecture both very simple and efficient for low resolution image generation (up to 64x64).'}", "category": "generic"}
{"question_id": 761, "text": "I run an online marketplace where users want to categorize their items based on images. What API should they use for this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x32d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x32d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x32d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x32d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x32d': {'Top-1 Acc.': '85.1', 'Top-5 Acc.': '97.5'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 762, "text": "Explain how to use an API for semantic segmentation of park scenes to identify different regions such as playgrounds, pavements and water. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_mobilenet_v3_large', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_mobilenet_v3_large', 'Mean IOU': 60.3, 'Global Pixelwise Accuracy': 91.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 763, "text": "Propose an API that can recognize objects in an image with high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x48d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x48d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x48d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x48d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x48d': {'Top-1 Acc.': '85.4', 'Top-5 Acc.': '97.6'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 764, "text": "Could you suggest a GAN model to generate high-quality human faces images? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks (GANs)', 'api_name': 'PGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='PGAN', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'facebookresearch/pytorch_GAN_zoo:hub', 'model': 'PGAN', 'model_name': 'celebAHQ-512', 'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': 'import torch', 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'PGAN', model_name='celebAHQ-512', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'test': 'generated_images = model.test(noise)', 'plot_images': {'import_matplotlib': 'import matplotlib.pyplot as plt', 'import_torchvision': 'import torchvision', 'make_grid': 'grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1), scale_each=True, normalize=True)', 'imshow': 'plt.imshow(grid.permute(1, 2, 0).cpu().numpy())', 'show': 'plt.show()'}}, 'performance': {'dataset': 'celebA', 'accuracy': 'High-quality celebrity faces'}, 'description': \"Progressive Growing of GANs (PGAN) is a method for generating high-resolution images using generative adversarial networks. The model is trained progressively, starting with low-resolution images and gradually increasing the resolution until the desired output is achieved. This implementation is based on the paper by Tero Karras et al., 'Progressive Growing of GANs for Improved Quality, Stability, and Variation'.\"}", "category": "generic"}
{"question_id": 765, "text": "How can I use machine learning to identify different land use types from an aerial photograph or satellite imagery? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'AlexNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='alexnet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 43.45, 'top-5_error': 20.91}}, 'description': 'AlexNet is a deep convolutional neural network that achieved a top-5 error of 15.3% in the 2012 ImageNet Large Scale Visual Recognition Challenge. The main contribution of the original paper was the depth of the model, which was computationally expensive but made feasible through the use of GPUs during training. The pretrained AlexNet model in PyTorch can be used for image classification tasks.'}", "category": "generic"}
{"question_id": 766, "text": "A photographer wants to classify the objects in his images. Provide an API that can be used for image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNet50', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['pip install validators matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", \"print(f'Using {device} for inference')\", \"resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resnet50.eval().to(device)', 'uris = [...]', 'batch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resnet50(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'ImageNet', 'accuracy': '~0.5% top1 improvement over ResNet50 v1'}, 'description': 'The ResNet50 v1.5 model is a modified version of the original ResNet50 v1 model. The difference between v1 and v1.5 is that, in the bottleneck blocks which requires downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate (~0.5% top1) than v1, but comes with a small performance drawback (~5% imgs/sec). The model is initialized as described in Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures.'}", "category": "generic"}
{"question_id": 767, "text": "Help the e-commerce company in developing an API for identifying and classifying images of products. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SE-ResNeXt101', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_se_resnext101_32x4d', pretrained=True)\", 'api_arguments': 'N/A', 'python_environment_requirements': 'validators, matplotlib', 'example_code': \"import torch\\nfrom PIL import Image\\nimport torchvision.transforms as transforms\\nimport numpy as np\\nimport json\\nimport requests\\nimport matplotlib.pyplot as plt\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n%matplotlib inline\\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\nprint(f'Using {device} for inference')\\nresneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_se_resnext101_32x4d')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\nresneXt.eval().to(device)\\nuris = ['http://images.cocodataset.org/test-stuff2017/000000024309.jpg','http://images.cocodataset.org/test-stuff2017/000000028117.jpg','http://images.cocodataset.org/test-stuff2017/000000006149.jpg','http://images.cocodataset.org/test-stuff2017/000000004954.jpg']\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(resneXt(batch), dim=1)\\nresults = utils.pick_n_best(predictions=output, n=5)\\nfor uri, result in zip(uris, results):\\n img = Image.open(requests.get(uri, stream=True).raw)\\n img.thumbnail((256,256), Image.ANTIALIAS)\\n plt.imshow(img)\\n plt.show()\\n print(result)\", 'performance': {'dataset': 'IMAGENET', 'accuracy': 'N/A'}, 'description': 'The SE-ResNeXt101-32x4d is a ResNeXt101-32x4d model with added Squeeze-and-Excitation module. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures, which allows researchers to get results 3x faster than training without Tensor Cores while experiencing the benefits of mixed precision training.'}", "category": "generic"}
{"question_id": 768, "text": "I want a model that can classify text into positive, negative or neutral sentiment. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'RoBERTa', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq', model='roberta.large', pretrained=True)\", 'api_arguments': [\"'pytorch/fairseq'\", \"'roberta.large'\"], 'python_environment_requirements': ['regex', 'requests', 'hydra-core', 'omegaconf'], 'example_code': ['import torch', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\", 'roberta.eval()', \"tokens = roberta.encode('Hello world!')\", 'last_layer_features = roberta.extract_features(tokens)', 'all_layers = roberta.extract_features(tokens, return_all_hiddens=True)', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\", 'roberta.eval()', \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is not very optimized.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is based on BERT.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"roberta.register_classification_head('new_task', num_classes=3)\", \"logprobs = roberta.predict('new_task', tokens)\"], 'performance': {'dataset': 'MNLI', 'accuracy': 'N/A'}, 'description': \"RoBERTa is a robustly optimized version of BERT, a revolutionary self-supervised pretraining technique that learns to predict intentionally hidden (masked) sections of text. RoBERTa builds on BERT's language masking strategy and modifies key hyperparameters, including removing BERT's next-sentence pretraining objective, and training with much larger mini-batches and learning rates. RoBERTa was also trained on an order of magnitude more data than BERT, for a longer amount of time, allowing it to generalize even better to downstream tasks.\"}", "category": "generic"}
{"question_id": 769, "text": "\"A Language teacher is teaching his class about pronunciation of English. They are looking for a TTS API that can help the students in the study process. Suggest an API for this purpose.\" \n Use this API documentation for reference: {'domain': 'Text-to-Speech', 'framework': 'PyTorch', 'functionality': 'Speech Synthesis', 'api_name': 'WaveGlow', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_waveglow', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_waveglow', 'model_math': 'fp32'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': {'load_waveglow_model': \"waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp32')\", 'prepare_waveglow_model': ['waveglow = waveglow.remove_weightnorm(waveglow)', \"waveglow = waveglow.to('cuda')\", 'waveglow.eval()'], 'load_tacotron2_model': \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp32')\", 'prepare_tacotron2_model': [\"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()'], 'synthesize_speech': ['text = \"hello world, I missed you so much\"', \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'save_audio': 'write(\"audio.wav\", rate, audio_numpy)', 'play_audio': 'Audio(audio_numpy, rate=rate)'}, 'performance': {'dataset': 'LJ Speech', 'accuracy': None}, 'description': 'The Tacotron 2 and WaveGlow model form a text-to-speech system that enables users to synthesize natural-sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 770, "text": "Recommend an API that can segment abnormal areas from an MRI scan. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Biomedical Image Segmentation', 'api_name': 'U-Net for brain MRI', 'api_call': \"torch.hub.load(repo_or_dir='mateuszbuda/brain-segmentation-pytorch', model='unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'api_arguments': {'in_channels': 3, 'out_channels': 1, 'init_features': 32, 'pretrained': True}, 'python_environment_requirements': ['torch', 'torchvision', 'numpy', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'import numpy as np', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'm, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))', 'preprocess = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=m, std=s)])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model = model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.round(output[0]))'], 'performance': {'dataset': 'kaggle.com/mateuszbuda/lgg-mri-segmentation'}, 'description': 'U-Net with batch normalization for biomedical image segmentation with pretrained weights for abnormality segmentation in brain MRI. The model comprises four levels of blocks containing two convolutional layers with batch normalization and ReLU activation function, and one max pooling layer in the encoding part and up-convolutional layers instead in the decoding part. The number of convolutional filters in each block is 32, 64, 128, and 256. The bottleneck layer has 512 convolutional filters. From the encoding layers, skip connections are used to the corresponding layers in the decoding part. Input image is a 3-channel brain MRI slice from pre-contrast, FLAIR, and post-contrast sequences, respectively. Output is a one-channel probability map of abnormality regions with the same size as the input image.'}", "category": "generic"}
{"question_id": 771, "text": "A marketing team needs to classify images for their advertisement targeting. Can you offer an API that can predict the class of an image? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeXt101-32x4d', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resneXt', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'validators', 'matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', 'device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")', \"print(f'Using {device} for inference')\", \"resneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resneXt')\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resneXt.eval().to(device)', 'uris = [', \" 'http://images.cocodataset.org/test-stuff2017/000000024309.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000028117.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000006149.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000004954.jpg',\", ']', 'batch = torch.cat(', ' [utils.prepare_input_from_uri(uri) for uri in uris]', ').to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resneXt(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'IMAGENET', 'accuracy': 'Not provided'}, 'description': 'ResNeXt101-32x4d is a model introduced in the Aggregated Residual Transformations for Deep Neural Networks paper. It is based on regular ResNet model, substituting 3x3 convolutions inside the bottleneck block for 3x3 grouped convolutions. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures. It can be deployed for inference on the NVIDIA Triton Inference Server using TorchScript, ONNX Runtime or TensorRT as an execution backend.'}", "category": "generic"}
{"question_id": 772, "text": "I require a deep learning model to perform image classification on a dataset with multiple classes. Recommend an API that serves this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet201', pretrained=True)\", 'api_arguments': [{'name': 'densenet201', 'type': 'str', 'description': 'Densenet-201 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet201': {'Top-1 error': 22.8, 'Top-5 error': 6.43}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 773, "text": "Recommend a pre-trained model to classify images into one of 1000 different categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet169', pretrained=True)\", 'api_arguments': [{'name': 'densenet169', 'type': 'str', 'description': 'Densenet-169 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet169': {'Top-1 error': 24.0, 'Top-5 error': 7.0}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 774, "text": "Inform me about an API that can aid in image classification tasks and has a dense network architecture. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet161', pretrained=True)\", 'api_arguments': [{'name': 'densenet161', 'type': 'str', 'description': 'Densenet-161 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet161', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet161': {'Top-1 error': 22.35, 'Top-5 error': 6.2}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 775, "text": "A drone survey company requires an API to classify natural scenes into specific classes from aerial imagery. Which API can they use for this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet121', pretrained=True)\", 'api_arguments': [{'name': 'densenet121', 'type': 'str', 'description': 'Densenet-121 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet121': {'Top-1 error': 25.35, 'Top-5 error': 7.83}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 776, "text": "An urban planning team needs to segment a satellite image to identify different landforms. Can you suggest an ML API that can provide segmentation maps? \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet101', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet101': {'Mean IOU': 63.7, 'Global Pixelwise Accuracy': 91.9}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 777, "text": "Propose an API to process a satellite image and label different objects like buildings, roads, and vegetation. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet50', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet50': {'Mean IOU': 60.5, 'Global Pixelwise Accuracy': 91.4}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 778, "text": "Find an API that can optimize a model for low memory usage and fast processing to differentiate between cats and dogs in images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet39ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet39ds', 'type': 'str', 'description': 'HarDNet-39DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet39ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet39ds': {'Top-1 error': 27.92, 'Top-5 error': 9.57}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 779, "text": "Suggest an API that classifies images quickly, without sacrificing too much accuracy, as compared to traditional methods like ResNet. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet85', pretrained=True)\", 'api_arguments': [{'name': 'hardnet85', 'type': 'str', 'description': 'HarDNet-85 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet85', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet85': {'Top-1 error': 21.96, 'Top-5 error': 6.11}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 780, "text": "A machine learning engineer is working on a project to classify images of different dog breeds. Provide an example of an API that could be used for image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68', 'type': 'str', 'description': 'HarDNet-68 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68': {'Top-1 error': 23.52, 'Top-5 error': 6.99}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory trafficCNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 781, "text": "Recommend me a computer vision model that can determine the top 5 labels for an image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'GoogLeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='googlenet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.0.0', 'torchvision': '>=0.2.2'}, 'example_code': {'import': ['import torch', 'import urllib', 'from PIL import Image', 'from torchvision import transforms'], 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\", 'model_eval': 'model.eval()', 'image_preprocessing': ['input_image = Image.open(filename)', 'preprocess = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'model_execution': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'output_processing': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'top5_prob, top5_catid = torch.topk(probabilities, 5)']}, 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 error': '30.22', 'Top-5 error': '10.47'}}, 'description': \"GoogLeNet is based on a deep convolutional neural network architecture codenamed 'Inception', which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014).\"}", "category": "generic"}
{"question_id": 782, "text": "Present me an API that efficiently classifies images with less computational cost compared to traditional methods. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Efficient networks by generating more features from cheap operations', 'api_name': 'GhostNet', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/ghostnet', model='ghostnet_1x', pretrained=True)\", 'api_arguments': ['pretrained'], 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/ghostnet', 'ghostnet_1x', pretrained=True)\", 'model.eval()', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 acc': '73.98', 'Top-5 acc': '91.46'}}, 'description': 'The GhostNet architecture is based on an Ghost module structure which generates more features from cheap operations. Based on a set of intrinsic feature maps, a series of cheap operations are applied to generate many ghost feature maps that could fully reveal information underlying intrinsic features. Experiments conducted on benchmarks demonstrate the superiority of GhostNet in terms of speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 783, "text": "We need to detect objects in images for a mobile platform with a low memory footprint CNN architecture. Could you suggest an appropriate API for this purpose? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68ds', 'type': 'str', 'description': 'HarDNet-68DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68ds': {'Top-1 error': 25.71, 'Top-5 error': 8.13}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 784, "text": "Recommend an API for a vehicle recognition system which can identify models and types of vehicles from various visual angles. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet101_ibn_a', 'type': 'str', 'description': 'ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet101_ibn_a': {'Top-1 acc': 78.61, 'Top-5 acc': 94.41}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 785, "text": "A live streaming platform needs a machine learning model for content moderation. Tell me how to implement an API that can classify an image for content moderation. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet50_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet50_ibn_a', 'type': 'str', 'description': 'ResNet-50-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet50_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet50_ibn_a': {'Top-1 acc': 77.46, 'Top-5 acc': 93.68}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 786, "text": "We have a dataset concerning pedestrian activities at crosswalks. Recommend an API capable of predicting activities like walking, running, or waiting given an image as input. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnext101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_ibn_a', 'type': 'str', 'description': 'ResNeXt-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnext101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext101_ibn_a': {'Top-1 acc': 79.12, 'Top-5 acc': 94.58}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 787, "text": "AML, a cybersecurity company is building a face identification engine for airports. Recommend an API that can output True if the two photos provided are the same person or False if not. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='se_resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'se_resnet101_ibn_a', 'type': 'str', 'description': 'SE-ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'se_resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'se_resnet101_ibn_a': {'Top-1 acc': 78.75, 'Top-5 acc': 94.49}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 788, "text": "We want to design an app to identify plants. Recommend an API that can be used to classify images of plants. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'Inception_v3', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='inception_v3', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '1.9.0', 'torchvision': '0.10.0'}, 'example_code': {'import_libraries': 'import torch', 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\", 'model_evaluation': 'model.eval()'}, 'performance': {'dataset': 'imagenet', 'accuracy': {'top-1_error': 22.55, 'top-5_error': 6.44}}, 'description': 'Inception v3, also called GoogleNetv3, is a famous Convolutional Neural Network trained on the ImageNet dataset from 2015. It is based on the exploration of ways to scale up networks to utilize the added computation as efficiently as possible by using suitably factorized convolutions and aggressive regularization. The model achieves a top-1 error of 22.55% and a top-5 error of 6.44% on the ImageNet dataset.'}", "category": "generic"}
{"question_id": 789, "text": "I am working at Pinterest and we want to build a classifier for the images in the platform. Give me an API that can classify images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest50', pretrained=True)\", 'api_arguments': 'resnest50', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-50': 81.03}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 790, "text": "I want to create an app to recognize plants based on images. Suggest me an API that I can use for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest200', pretrained=True)\", 'api_arguments': 'resnest200', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest200', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-200': 83.84}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 791, "text": "A museum located in New York City wants to categorize their art collection by automatically identifying the content of the artwork. Which API can be used to perform image classification? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest101', pretrained=True)\", 'api_arguments': 'resnest101', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-101': 82.83}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 792, "text": "Let me know an API that can classify food from photos. It should be designed to run on low-power devices and offer good accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_cpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_cpu', 'type': 'str', 'description': 'ProxylessNAS optimized for CPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_cpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_cpu', 'accuracy': 75.3}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 793, "text": "I'm doing an image classification project, suggest an API that can help me classify images effectively. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest269', pretrained=True)\", 'api_arguments': 'resnest269', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest269', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-269': 84.54}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 794, "text": "Identify an API suitable for classifying images using a neural network optimized for high performance on GPUs. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_gpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_gpu', 'type': 'str', 'description': 'ProxylessNAS optimized for GPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_gpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_gpu', 'accuracy': 75.1}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 795, "text": "The Clubhouse App wants a function for image classification. Advise them an API that could be a potential solution for them. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MobileNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='mobilenet_v2', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 28.12, 'top-5_error': 9.71}}, 'description': 'The MobileNet v2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input. MobileNet v2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, non-linearities in the narrow layers were removed in order to maintain representational power.'}", "category": "generic"}
{"question_id": 796, "text": "I am from Google and I am looking for an API that can classify images into categories using neural networks optimized for mobiles. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_mobile', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_mobile', 'type': 'str', 'description': 'ProxylessNAS optimized for Mobile'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_mobile'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_mobile', 'accuracy': 74.6}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 797, "text": "Recommend an API to determine the type of objects in an image given a set of pre-trained labels. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet34', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet34', 'top-1_error': 26.7, 'top-5_error': 8.58}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 798, "text": "Recommend to me an API that can efficiently recognize faces from an image and classify them into particular groups or categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet18', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet18', 'top-1_error': 30.24, 'top-5_error': 10.92}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 799, "text": "Recommend me a model that has a high accuracy in recognizing the emotion of people displayed in images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet50', 'top-1_error': 23.85, 'top-5_error': 7.13}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 800, "text": "Looking for an API that can identify different breeds of dogs in images. It must provide high accuracy in identifying the breed. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet101', 'top-1_error': 22.63, 'top-5_error': 6.44}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 801, "text": "I noticed that some of the bird species are mistakenly tagged in the bird photo collection. Provide me an API to auto fix the tags. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet152', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet152', 'top-1_error': 21.69, 'top-5_error': 5.94}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 802, "text": "How can I build an AI system that can recognize dogs and cats? Provide me an API and pretrained model that will help. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext50_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext50_32x4d': {'top-1': 22.38, 'top-5': 6.3}}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 803, "text": "Analyze a given image for its content and classify it into its respective category. Suggest an API that can help with this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext101_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext101_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'resnext101_32x8d': {'top-1': 20.69, 'top-5': 5.47}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 804, "text": "Find me an API that can classify images into different categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_b', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_b', 'type': 'str', 'description': 'SNNMLP Base model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_b', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Base', 'top-1': 85.59}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 805, "text": "I need to classify a set of random images. What pre-trained machine learning API would you recommend for this purpose? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_t', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_t', 'type': 'str', 'description': 'SNNMLP Tiny model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_t', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Tiny', 'top-1': 81.88}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 806, "text": "A company is looking to build an app that automatically scans items in the grocery store and categorizes them in real time. What API should they use? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_0', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_0'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_0': {'Top-1 error': 41.9, 'Top-5 error': 19.58}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 807, "text": "Our company, New York Pillow, is developing an inventory system for our products, and we need a machine learning model to classify images of pillows by their type. Can you give me an API which can classify pillow types? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_s', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_s', 'type': 'str', 'description': 'SNNMLP Small model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_s', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Small', 'top-1': 83.3}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 808, "text": "Which API should I use that classifies images during my visit and uses minimum storage? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_1', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_1'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_1': {'Top-1 error': 41.81, 'Top-5 error': 19.38}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 809, "text": "I need an API that can identify dog breeds in a given photo. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11', pretrained=True)\", 'api_arguments': [{'name': 'vgg11', 'type': 'str', 'description': 'VGG11 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11': {'Top-1 error': 30.98, 'Top-5 error': 11.37}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 810, "text": "Find an API that can classify a given image, while maintaining a high efficiency for mobile phone usage. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ShuffleNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='shufflenet_v2_x1_0', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'torch', 'torchvision': 'torchvision', 'PIL': 'Image', 'urllib': 'urllib'}, 'example_code': {'import_libraries': ['import torch', 'from PIL import Image', 'from torchvision import transforms', 'import urllib'], 'load_model': [\"model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\", 'model.eval()'], 'load_image': [\"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'try: urllib.URLopener().retrieve(url, filename)', 'except: urllib.request.urlretrieve(url, filename)', 'input_image = Image.open(filename)'], 'preprocess_image': ['preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'run_inference': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'get_probabilities': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'top_categories': ['top5_prob, top5_catid = torch.topk(probabilities, 5)', 'for i in range(top5_prob.size(0)):', ' print(categories[top5_catid[i]], top5_prob[i].item())']}, 'performance': {'dataset': 'Imagenet', 'accuracy': {'top-1_error': 30.64, 'top-5_error': 11.68}}, 'description': 'ShuffleNet V2 is an efficient ConvNet optimized for speed and memory, pre-trained on Imagenet. It is designed based on practical guidelines for efficient network design, including speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 811, "text": "I'm working on building an app that would let users know what's in a photograph. Suggest an efficient image recognition API appropriate for my purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg11_bn', 'type': 'str', 'description': 'VGG11 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11_bn': {'Top-1 error': 26.7, 'Top-5 error': 8.58}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 812, "text": "Propose an API that can identify the type of car in a photo taken at a car dealership. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16', pretrained=True)\", 'api_arguments': [{'name': 'vgg16', 'type': 'str', 'description': 'VGG16 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16': {'Top-1 error': 28.41, 'Top-5 error': 9.62}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 813, "text": "I am running a website on animal rescue and I have lots of animal photos during adoption process. Recommend me an API that can recognize animal breeds from images, so I can improve my website's user experience. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13', pretrained=True)\", 'api_arguments': [{'name': 'vgg13', 'type': 'str', 'description': 'VGG13 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13': {'Top-1 error': 30.07, 'Top-5 error': 10.75}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn,vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 814, "text": "What pre-trained API can I use to recognize different objects from an image? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg16_bn', 'type': 'str', 'description': 'VGG16 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16_bn': {'Top-1 error': 26.63, 'Top-5 error': 8.5}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 815, "text": "\"I am creating an object classifier to recognize thousands of common objects. Convince me with an API I should use.\" \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19', pretrained=True)\", 'api_arguments': [{'name': 'vgg19', 'type': 'str', 'description': 'VGG19 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19': {'Top-1 error': 27.62, 'Top-5 error': 9.12}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 816, "text": "A company is building an AI-powered image categorization tool to help label images in their database with greater accuracy. Recommend an API to identify and classify images with high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg13_bn', 'type': 'str', 'description': 'VGG13 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13_bn': {'Top-1 error': 28.45, 'Top-5 error': 9.63}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 817, "text": "I run a pet adoption center and want to identify dog breeds for our customers. How can I use a pre-trained model to recognize dog breeds from images? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg19_bn', 'type': 'str', 'description': 'VGG19 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19_bn': {'Top-1 error': 25.76, 'Top-5 error': 8.15}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 818, "text": "A client of mine wants to classify photographs into relevant categories for their website. Can you recommend a suitable API to do the job? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet50_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet50_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet50_2': {'Top-1 error': 21.49, 'Top-5 error': 5.91}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 819, "text": "A fitness app is trying to categorize workout videos based on the activity. Can you propose an API that can do this? \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'SlowFast Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slowfast_r50', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'slowfast_r50', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 76.94, 'top5': 92.69}, 'flops': 65.71, 'params': 34.57}, 'description': \"Slow Fast model architectures are based on the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al. They are pretrained on the Kinetics 400 dataset using the 8x8 setting. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 820, "text": "I am building an app that can detect which animal is in a given image. Give me an API for image classification that would be suitable for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet101_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet101_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet101_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet101_2': {'Top-1 error': 21.16, 'Top-5 error': 5.72}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 821, "text": "Recommend a video classification API that can identify the netball activity from a short video clip. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'X3D Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='x3d_s', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'x3d_s', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_s', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 73.33, 'top5': 91.27}, 'flops': 2.96, 'params': 3.79}, 'description': \"X3D model architectures are based on the paper 'X3D: Expanding Architectures for Efficient Video Recognition' by Christoph Feichtenhofer. They are pretrained on the Kinetics 400 dataset. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 822, "text": "Recommend an API for classifying images that is efficient on edge devices. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Once-for-all (OFA) Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/once-for-all', model='ofa_supernet_mbv3_w10', pretrained=True)\", 'api_arguments': {'repository': 'mit-han-lab/once-for-all', 'model': 'ofa_supernet_mbv3_w10', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"super_net_name = 'ofa_supernet_mbv3_w10'\", \"super_net = torch.hub.load('mit-han-lab/once-for-all', super_net_name, pretrained=True).eval()\"], 'performance': {'description': 'OFA networks outperform state-of-the-art NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x faster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency) while reducing many orders of magnitude GPU hours and CO2 emission.'}, 'description': 'Once-for-all (OFA) networks are a family of neural networks designed by MIT Han Lab. They decouple training and search, achieving efficient inference across various edge devices and resource constraints. OFA networks are pretrained on the IMAGENET dataset and are capable of classifying images into different categories.'}", "category": "generic"}
{"question_id": 823, "text": "I am developing an app that would automatically tag uploaded images. Suggest an API that can perform image classification efficiently on a GPU. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'GPUNet Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", 'api_arguments': {'repository': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_gpunet', 'pretrained': 'True', 'model_type': 'GPUNet-0', 'model_math': 'fp32'}, 'python_environment_requirements': ['torch', 'validators', 'matplotlib', 'timm==0.5.4'], 'example_code': ['import torch', \"model_type = 'GPUNet-0'\", \"precision = 'fp32'\", \"gpunet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'gpunet.to(device)', 'gpunet.eval()'], 'performance': {'dataset': 'IMAGENET', 'description': 'GPUNet demonstrates state-of-the-art inference performance up to 2x faster than EfficientNet-X and FBNet-V3.'}, 'description': 'GPUNet is a family of Convolutional Neural Networks designed by NVIDIA using novel Neural Architecture Search (NAS) methods. They are optimized for NVIDIA GPU and TensorRT performance. GPUNet models are pretrained on the IMAGENET dataset and are capable of classifying images into different categories. The models are provided by the NVIDIA Deep Learning Examples library.'}", "category": "generic"}
{"question_id": 824, "text": "I need a pre-trained model to translate English text to French, which API can help perform that task? \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Neural Machine Translation', 'api_name': 'Transformer (NMT)', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq')\", 'api_arguments': ['model_name', 'tokenizer', 'bpe', 'beam', 'sampling', 'sampling_topk'], 'python_environment_requirements': ['bitarray', 'fastBPE', 'hydra-core', 'omegaconf', 'regex', 'requests', 'sacremoses', 'subword_nmt'], 'example_code': \"import torch\\n\\nen2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\\n\\nen2fr.cuda()\\n\\nfr = en2fr.translate('Hello world!', beam=5)\\nassert fr == 'Bonjour \u00e0 tous !'\", 'performance': {'dataset': [{'name': \"WMT'14\", 'accuracy': 'Not provided'}, {'name': \"WMT'18\", 'accuracy': 'Not provided'}, {'name': \"WMT'19\", 'accuracy': 'Not provided'}]}, 'description': \"Transformer (NMT) is a powerful sequence-to-sequence modeling architecture that produces state-of-the-art neural machine translation systems. It is based on the paper 'Attention Is All You Need' and has been improved using techniques such as large-scale semi-supervised training, back-translation, and noisy-channel reranking. It supports English-French and English-German translation as well as round-trip translation for paraphrasing.\"}", "category": "generic"}
{"question_id": 825, "text": "I need to develop an image classifier for an app that can recognize pictures of objects. Any recommended API that can do this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Semi-supervised and semi-weakly supervised ImageNet Models', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/semi-supervised-ImageNet1K-models', model='resnet18_swsl', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/semi-supervised-ImageNet1K-models', 'model': 'resnet18_swsl', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl', pretrained=True)\", 'model.eval()'], 'performance': {'description': 'Semi-supervised and semi-weakly supervised ImageNet models achieve state-of-the-art accuracy of 81.2% on ImageNet for the widely used/adopted ResNet-50 model architecture.'}, 'description': \"Semi-supervised and semi-weakly supervised ImageNet Models are introduced in the 'Billion scale semi-supervised learning for image classification' paper. These models are pretrained on a subset of unlabeled YFCC100M public image dataset and fine-tuned with the ImageNet1K training dataset. They are capable of classifying images into different categories and are provided by the Facebook Research library.\"}", "category": "generic"}
{"question_id": 826, "text": "Can you recommend an NLP API for an AI chatbot that understands user's message and generates human-like responses? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Natural Language Processing', 'api_name': 'PyTorch-Transformers', 'api_call': \"torch.hub.load(repo_or_dir='huggingface/pytorch-transformers')\", 'api_arguments': ['pretrained_model_or_path', 'output_attention', 'output_hidden_states', 'config', 'from_tf'], 'python_environment_requirements': ['tqdm', 'boto3', 'requests', 'regex', 'sentencepiece', 'sacremoses'], 'example_code': 'import torch\\ntokenizer = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'tokenizer\\', \\'bert-base-cased\\')\\n\\ntext_1 = \"Jim Henson was a puppeteer\"\\ntext_2 = \"Who was Jim Henson ?\"\\n\\nindexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\\n\\nmodel = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'model\\', \\'bert-base-cased\\')\\n\\nwith torch.no_grad():\\n encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)', 'performance': {'dataset': [{'name': 'MRPC', 'accuracy': 'Not provided'}]}, 'description': 'PyTorch-Transformers is a library of state-of-the-art pre-trained models for Natural Language Processing (NLP) including BERT, GPT, GPT-2, Transformer-XL, XLNet, XLM, RoBERTa, and DistilBERT. The library provides functionality for tokenization, configuration, and various model architectures for different tasks such as causal language modeling, sequence classification, question answering, and masked language modeling.'}", "category": "generic"}
{"question_id": 827, "text": "Develop a model to automatically identify plant species in images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'EfficientNet', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_efficientnet_b0', pretrained=True)\", 'api_arguments': ['model_name', 'pretrained'], 'python_environment_requirements': ['validators', 'matplotlib'], 'example_code': \"import torch\\n\\nefficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\n\\nefficientnet.eval().to(device)\\n\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\n\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(efficientnet(batch), dim=1)\\n \\nresults = utils.pick_n_best(predictions=output, n=5)\", 'performance': {'dataset': {'name': 'IMAGENET', 'accuracy': 'Not provided'}}, 'description': 'EfficientNet is a family of image classification models that achieve state-of-the-art accuracy while being smaller and faster. The models are trained with mixed precision using Tensor Cores on the NVIDIA Volta and Ampere GPU architectures. The EfficientNet models include EfficientNet-B0, EfficientNet-B4, EfficientNet-WideSE-B0, and EfficientNet-WideSE-B4. The WideSE models use wider Squeeze-and-Excitation layers than the original EfficientNet models, resulting in slightly better accuracy.'}", "category": "generic"}
{"question_id": 828, "text": "Recommend a PyTorch API for converting text to speech with high-quality audio output. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Text-to-Speech', 'api_name': 'Tacotron 2', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_tacotron2', model_math='fp16')\", 'api_arguments': {'model_math': 'fp16'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': ['import torch', \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\", \"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()', \"text = 'Hello world, I missed you so much.'\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'performance': {'dataset': 'LJ Speech', 'accuracy': 'Not specified'}, 'description': 'The Tacotron 2 model generates mel spectrograms from input text using an encoder-decoder architecture, and it is designed for generating natural-sounding speech from raw transcripts without any additional prosody information. This implementation uses Dropout instead of Zoneout to regularize the LSTM layers. The WaveGlow model (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 829, "text": "I am building a security system for a shopping mall, and I need to identify objects in real-time from CCTV footage. Can you suggest an API? \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Single Shot MultiBox Detector', 'api_name': 'SSD', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_ssd', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['numpy', 'scipy', 'scikit-image', 'matplotlib'], 'example_code': \"import torch\\n\\nssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\\n\\nssd_model.to('cuda')\\nssd_model.eval()\\n\\ninputs = [utils.prepare_input(uri) for uri in uris]\\ntensor = utils.prepare_tensor(inputs)\\n\\nwith torch.no_grad():\\n detections_batch = ssd_model(tensor)\\n\\nresults_per_input = utils.decode_results(detections_batch)\\nbest_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\", 'performance': {'dataset': {'name': 'COCO', 'accuracy': 'Not provided'}}, 'description': \"The SSD (Single Shot MultiBox Detector) model is an object detection model based on the paper 'SSD: Single Shot MultiBox Detector'. It uses a deep neural network for detecting objects in images. This implementation replaces the obsolete VGG model backbone with the more modern ResNet-50 model. The SSD model is trained on the COCO dataset and can be used to detect objects in images with high accuracy and efficiency.\"}", "category": "generic"}
{"question_id": 830, "text": "Provide an API for classifying images using state-of-the-art accuracy without any additional tricks. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V1', model='mealv1_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv1_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V1 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '78.21', 'top5': '94.01'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 831, "text": "I need an API capable of classifying images with state-of-the-art accuracy using no tricks, for a call center to use. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.67', 'top5': '95.09'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 832, "text": "What API can classify different types of dogs from an image? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_cutmix', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_cutmix'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 + CutMix w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.98', 'top5': '95.35'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 833, "text": "I want to classify common objects in an image. Recommend an API that can do this for me. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_075', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_075'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 0.75', 'resolution': '224', 'parameters': '2.04M', 'top1': '67.60', 'top5': '87.23'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 834, "text": "ABC fashion company wishes to use an API to classify the images of clothing styles. Suggest an API for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_380x380', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_380x380'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '380', 'parameters': '25.6M', 'top1': '81.72', 'top5': '95.81'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 835, "text": "Rankz wants to develop a custom video suggestion feature by classifying user's uploaded videos. Recommend a suitable API for this task. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorch', 'functionality': '3D ResNet', 'api_name': 'slow_r50', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slow_r50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'json', 'urllib', 'pytorchvideo', 'torchvision', 'torchaudio', 'torchtext', 'torcharrow', 'TorchData', 'TorchRec', 'TorchServe', 'PyTorch on XLA Devices'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top_1': 74.58, 'top_5': 91.63}, 'Flops (G)': 54.52, 'Params (M)': 32.45}, 'description': \"The 3D ResNet model is a Resnet-style video classification network pretrained on the Kinetics 400 dataset. It is based on the architecture from the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al.\"}", "category": "generic"}
{"question_id": 836, "text": "Can you tell me an API for classifying the content of an image? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_efficientnet_b0', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_efficientnet_b0'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ EfficientNet-B0', 'resolution': '224', 'parameters': '5.29M', 'top1': '78.29', 'top5': '93.95'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 837, "text": "Present an API that boosts vanilla ResNet-50 to 80%+ top-1 accuracy on ImageNet for a farmer's crop identification project. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenet_v3_large_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenet_v3_large_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Large 1.0', 'resolution': '224', 'parameters': '5.48M', 'top1': '76.92', 'top5': '93.32'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 838, "text": "I want to build a self-driving car software that can detect traffic objects, drivable areas, and lanes. Which API can perform these tasks efficiently? \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Traffic Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'HybridNets', 'api_call': \"torch.hub.load(repo_or_dir='datvuthanh/hybridnets', model='hybridnets', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'Python>=3.7, PyTorch>=1.10', 'example_code': \"import torch\\nmodel = torch.hub.load('datvuthanh/hybridnets', 'hybridnets', pretrained=True)\\nimg = torch.randn(1,3,640,384)\\nfeatures, regression, classification, anchors, segmentation = model(img)\", 'performance': {'dataset': [{'name': 'BDD100K', 'accuracy': {'Traffic Object Detection': {'Recall (%)': 92.8, 'mAP@0.5 (%)': 77.3}, 'Drivable Area Segmentation': {'Drivable mIoU (%)': 90.5}, 'Lane Line Detection': {'Accuracy (%)': 85.4, 'Lane Line IoU (%)': 31.6}}}]}, 'description': 'HybridNets is an end2end perception network for multi-tasks. Our work focused on traffic object detection, drivable area segmentation and lane detection. HybridNets can run real-time on embedded systems, and obtains SOTA Object Detection, Lane Detection on BDD100K Dataset.'}", "category": "generic"}
{"question_id": 839, "text": "Create a multi-task network for autonomous driving to handle object detection, drivable area segmentation, and lane detection in real-time. Which API would you suggest to achieve this? \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Object Detection, Drivable Area Segmentation, Lane Detection', 'api_name': 'YOLOP', 'api_call': \"torch.hub.load(repo_or_dir='hustvl/yolop', model='yolop', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'pip install -qr https://github.com/hustvl/YOLOP/blob/main/requirements.txt', 'example_code': \"import torch\\nmodel = torch.hub.load('hustvl/yolop', 'yolop', pretrained=True)\\nimg = torch.randn(1,3,640,640)\\ndet_out, da_seg_out,ll_seg_out = model(img)\", 'performance': {'dataset': 'BDD100K', 'accuracy': {'Object Detection': {'Recall(%)': 89.2, 'mAP50(%)': 76.5, 'Speed(fps)': 41}, 'Drivable Area Segmentation': {'mIOU(%)': 91.5, 'Speed(fps)': 41}, 'Lane Detection': {'mIOU(%)': 70.5, 'IOU(%)': 26.2}}}, 'description': 'YOLOP is an efficient multi-task network that can jointly handle three crucial tasks in autonomous driving: object detection, drivable area segmentation and lane detection. And it is also the first to reach real-time on embedded devices while maintaining state-of-the-art level performance on the BDD100K dataset.'}", "category": "generic"}
{"question_id": 840, "text": "Design an intelligent robot. Tell me how to build a robot that can estimate objects' distance from its camera just by taking a photo. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Hybrid', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Hybrid')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 841, "text": "I am an architect for a construction project and I need to compute the depth of objects in an image. What API will allow me to do this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='DPT_Large', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'DPT_Large')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 842, "text": "I need a deep learning model to separate vocals from background music for a given audio clip. What API can I use for this? \n Use this API documentation for reference: {'domain': 'Audio Separation', 'framework': 'PyTorch', 'functionality': 'Music Source Separation', 'api_name': 'Open-Unmix', 'api_call': \"torch.hub.load(repo_or_dir='sigsep/open-unmix-pytorch', model='umxhq', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['PyTorch >=1.6.0', 'torchaudio'], 'example_code': ['import torch', \"separator = torch.hub.load('sigsep/open-unmix-pytorch', 'umxhq')\", 'audio = torch.rand((1, 2, 100000))', 'original_sample_rate = separator.sample_rate', 'estimates = separator(audio)'], 'performance': {'dataset': 'MUSDB18', 'accuracy': 'N/A'}, 'description': 'Open-Unmix provides ready-to-use models that allow users to separate pop music into four stems: vocals, drums, bass and the remaining other instruments. The models were pre-trained on the freely available MUSDB18 dataset.'}", "category": "generic"}
{"question_id": 843, "text": "I am a photographer and I want to determine the relative depth of objects in my images. Suggest an API that can compute the depth information from a single image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Computing relative depth from a single image', 'api_name': 'MiDaS', 'api_call': \"torch.hub.load(repo_or_dir='intel-isl/MiDaS', model='MiDaS_small', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'intel-isl/MiDaS', 'model': 'model_type'}, 'python_environment_requirements': 'pip install timm', 'example_code': ['import cv2', 'import torch', 'import urllib.request', 'import matplotlib.pyplot as plt', \"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'urllib.request.urlretrieve(url, filename)', \"model_type = 'DPT_Large'\", \"midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'midas.to(device)', 'midas.eval()', \"midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\", \"if model_type == 'DPT_Large' or model_type == 'DPT_Hybrid':\", ' transform = midas_transforms.dpt_transform', 'else:', ' transform = midas_transforms.small_transform', 'img = cv2.imread(filename)', 'img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)', 'input_batch = transform(img).to(device)', 'with torch.no_grad():', ' prediction = midas(input_batch)', 'prediction = torch.nn.functional.interpolate(', ' prediction.unsqueeze(1),', ' size=img.shape[:2],', \" mode='bicubic',\", ' align_corners=False,', ').squeeze()', 'output = prediction.cpu().numpy()', 'plt.imshow(output)', 'plt.show()'], 'performance': {'dataset': '10 distinct datasets', 'accuracy': 'Multi-objective optimization'}, 'description': 'MiDaS computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using multi-objective optimization to ensure high quality on a wide range of inputs.'}", "category": "generic"}
{"question_id": 844, "text": "I\u2019m trying to build an app that identifies breeds of dogs from images, can you sugget any API for that purpose? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 1.0', 'resolution': '224', 'parameters': '2.54M', 'top1': '69.65', 'top5': '88.71'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 845, "text": "An AI company wants to build a bird species identifier given an image of bird. Give me an API that can classify bird species from an input image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Fine-grained image classifier', 'api_name': 'ntsnet', 'api_call': \"torch.hub.load(repo_or_dir='nicolalandro/ntsnet-cub200', model='ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\", 'api_arguments': {'pretrained': 'True', 'topN': '6', 'device': 'cpu', 'num_classes': '200'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': \"from torchvision import transforms\\nimport torch\\nimport urllib\\nfrom PIL import Image\\n\\ntransform_test = transforms.Compose([\\n transforms.Resize((600, 600), Image.BILINEAR),\\n transforms.CenterCrop((448, 448)),\\n transforms.ToTensor(),\\n transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\\n])\\n\\nmodel = torch.hub.load('nicolalandro/ntsnet-cub200', 'ntsnet', pretrained=True, **{'topN': 6, 'device':'cpu', 'num_classes': 200})\\nmodel.eval()\\n\\nurl = 'https://raw.githubusercontent.com/nicolalandro/ntsnet-cub200/master/images/nts-net.png'\\nimg = Image.open(urllib.request.urlopen(url))\\nscaled_img = transform_test(img)\\ntorch_images = scaled_img.unsqueeze(0)\\n\\nwith torch.no_grad():\\n top_n_coordinates, concat_out, raw_logits, concat_logits, part_logits, top_n_index, top_n_prob = model(torch_images)\\n\\n_, predict = torch.max(concat_logits, 1)\\npred_id = predict.item()\\nprint('bird class:', model.bird_classes[pred_id])\", 'performance': {'dataset': 'CUB200 2011', 'accuracy': 'Not provided'}, 'description': 'This is an nts-net pretrained with CUB200 2011 dataset, which is a fine-grained dataset of birds species.'}", "category": "generic"}
{"question_id": 846, "text": "I'm working on a project that involves transcribing voice recordings. Recommend an API that can convert speech to text. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Speech-To-Text', 'api_name': 'Silero Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_stt', 'language': ['en', 'de', 'es'], 'device': 'device'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf soundfile'], 'example_code': ['import torch', 'import zipfile', 'import torchaudio', 'from glob import glob', \"device = torch.device('cpu')\", \"model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', language='en', device=device)\", '(read_batch, split_into_batches, read_audio, prepare_model_input) = utils', \"torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav', dst ='speech_orig.wav', progress=True)\", \"test_files = glob('speech_orig.wav')\", 'batches = split_into_batches(test_files, batch_size=10)', 'input = prepare_model_input(read_batch(batches[0]), device=device)', 'output = model(input)', 'for example in output:', ' print(decoder(example.cpu()))'], 'performance': {'dataset': 'Open-STT', 'accuracy': 'See the wiki for quality and performance benchmarks'}, 'description': 'Silero Speech-To-Text models provide enterprise grade STT in a compact form-factor for several commonly spoken languages. The models are robust to a variety of dialects, codecs, domains, noises, and lower sampling rates. They consume a normalized audio in the form of samples and output frames with token probabilities. A decoder utility is provided for simplicity.'}", "category": "generic"}
{"question_id": 847, "text": "Based upon a traffic camera, San Francisco Traffic Authority wants to identify the segmented boundaries for everything the camera captures. Provide an API that can help them perform this task. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet50', 'Mean IOU': 66.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 848, "text": "Recommend an API that can detect if there is a speech or silence segments in an audio file. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Voice Activity Detection', 'api_name': 'Silero Voice Activity Detector', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-vad', 'model': 'silero_vad', 'force_reload': 'True'}, 'python_environment_requirements': {'torchaudio': 'pip install -q torchaudio'}, 'example_code': {'import': ['import torch', 'torch.set_num_threads(1)', 'from IPython.display import Audio', 'from pprint import pprint'], 'download_example': \"torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\", 'load_model': \"model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\", 'load_utils': '(get_speech_timestamps, _, read_audio, _) = utils', 'set_sampling_rate': 'sampling_rate = 16000', 'read_audio': \"wav = read_audio('en_example.wav', sampling_rate=sampling_rate)\", 'get_speech_timestamps': 'speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sampling_rate)', 'print_speech_timestamps': 'pprint(speech_timestamps)'}, 'performance': {'dataset': '', 'accuracy': ''}, 'description': 'Silero VAD is a pre-trained enterprise-grade Voice Activity Detector (VAD) that aims to provide a high-quality and modern alternative to the WebRTC Voice Activity Detector. The model is optimized for performance on 1 CPU thread and is quantized.'}", "category": "generic"}
{"question_id": 849, "text": "Tell me about an API that is capable of segmenting objects in images based on their semantics, like identifying a car or a person. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_resnet101', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_resnet101', 'Mean IOU': 67.4, 'Global Pixelwise Accuracy': 92.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 850, "text": "Can you recommend an API that can detect different types of animals in a picture? \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'YOLOv5', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='ultralytics/yolov5', model='yolov5s', pretrained=True)\", 'api_arguments': [\"'ultralytics/yolov5'\", \"'yolov5s'\", 'pretrained=True'], 'python_environment_requirements': 'Python>=3.8, PyTorch>=1.7', 'example_code': ['import torch', \"model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\", \"imgs = ['https://ultralytics.com/images/zidane.jpg']\", 'results = model(imgs)', 'results.print()', 'results.save()', 'results.xyxy[0]', 'results.pandas().xyxy[0]'], 'performance': {'dataset': 'COCO', 'accuracy': {'YOLOv5s6': {'mAPval0.5:0.95': 43.3, 'mAPtest0.5:0.95': 43.3, 'mAPval0.5': 61.9}, 'YOLOv5m6': {'mAPval0.5:0.95': 50.5, 'mAPtest0.5:0.95': 50.5, 'mAPval0.5': 68.7}, 'YOLOv5l6': {'mAPval0.5:0.95': 53.4, 'mAPtest0.5:0.95': 53.4, 'mAPval0.5': 71.1}, 'YOLOv5x6': {'mAPval0.5:0.95': 54.4, 'mAPtest0.5:0.95': 54.4, 'mAPval0.5': 72.0}, 'YOLOv5x6 TTA': {'mAPval0.5:0.95': 55.0, 'mAPtest0.5:0.95': 55.0, 'mAPval0.5': 72.0}}}, 'description': 'YOLOv5 is a family of compound-scaled object detection models trained on the COCO dataset, and includes simple functionality for Test Time Augmentation (TTA), model ensembling, hyperparameter evolution, and export to ONNX, CoreML and TFLite.'}", "category": "generic"}
{"question_id": 851, "text": "I want to perform semantic segmentation on an image to differentiate the foreground objects from the background. Recommend an API that can accomplish this. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'DeepLabV3', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='deeplabv3_mobilenet_v3_large', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest', 'PIL': 'latest', 'matplotlib': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', \"input_image = input_image.convert('RGB')\", 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': [{'model': 'deeplabv3_mobilenet_v3_large', 'Mean IOU': 60.3, 'Global Pixelwise Accuracy': 91.4}]}, 'description': 'DeepLabV3 models with ResNet-50, ResNet-101 and MobileNet-V3 backbones for semantic segmentation. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 852, "text": "Help me to convert this text to speech: \"The weather is great today\" with an API call., 'Input': 'The weather is great today' \n Use this API documentation for reference: {'domain': 'Text-To-Speech', 'framework': 'PyTorch', 'functionality': 'Text-To-Speech', 'api_name': 'Silero Text-To-Speech Models', 'api_call': \"torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'snakers4/silero-models', 'model': 'silero_tts', 'language': 'language', 'speaker': 'speaker'}, 'python_environment_requirements': ['pip install -q torchaudio omegaconf'], 'example_code': \"import torch\\nlanguage = 'en'\\nspeaker = 'lj_16khz'\\ndevice = torch.device('cpu')\\nmodel, symbols, sample_rate, example_text, apply_tts = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', language=language, speaker=speaker)\\nmodel = model.to(device)\\naudio = apply_tts(texts=[example_text], model=model, sample_rate=sample_rate, symbols=symbols, device=device)\", 'performance': {'dataset': [{'language': 'Russian', 'speakers': 6}, {'language': 'English', 'speakers': 1}, {'language': 'German', 'speakers': 1}, {'language': 'Spanish', 'speakers': 1}, {'language': 'French', 'speakers': 1}], 'accuracy': 'High throughput on slow hardware. Decent performance on one CPU thread'}, 'description': 'Silero Text-To-Speech models provide enterprise grade TTS in a compact form-factor for several commonly spoken languages. They offer one-line usage, naturally sounding speech, no GPU or training required, minimalism and lack of dependencies, a library of voices in many languages, support for 16kHz and 8kHz out of the box.'}", "category": "generic"}
{"question_id": 853, "text": "I want to make a video game and I need randomly generated low resolution images for background. Can you suggest an API that can create images as per my requirement? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks', 'api_name': 'DCGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='DCGAN', pretrained=True, useGPU=use_gpu)\", 'api_arguments': {'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': ['import torch', 'import matplotlib.pyplot as plt', 'import torchvision'], 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'generate_images': 'with torch.no_grad(): generated_images = model.test(noise)', 'plot_images': ['plt.imshow(torchvision.utils.make_grid(generated_images).permute(1, 2, 0).cpu().numpy())', 'plt.show()']}, 'performance': {'dataset': 'FashionGen', 'accuracy': 'N/A'}, 'description': 'DCGAN is a model designed in 2015 by Radford et. al. in the paper Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. It is a GAN architecture both very simple and efficient for low resolution image generation (up to 64x64).'}", "category": "generic"}
{"question_id": 854, "text": "I need an API to classify an image according to the ImageNet dataset. Tell me which API to use and how. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x8d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x8d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x8d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x8d': {'Top-1 Acc.': '82.2', 'Top-5 Acc.': '96.4'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 855, "text": "Some friends and I want to organize a competition where people send us images of their pets and the photos are sorted into categories based on the type of pet in the image. Provide a deep learning API that can meet this goal. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x16d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x16d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x16d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x16d': {'Top-1 Acc.': '84.2', 'Top-5 Acc.': '97.2'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 856, "text": "Help me discover an API suitable for classifying images in a custom dataset using Instagram users' preferences. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x32d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x32d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x32d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x32d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x32d': {'Top-1 Acc.': '85.1', 'Top-5 Acc.': '97.5'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 857, "text": "A marketing company needs to clasify images of different catagories for a client. Can you provide an API to achive this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext WSL', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/WSL-Images', model='resnext101_32x48d_wsl', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_32x48d_wsl', 'type': 'str', 'description': 'ResNeXt-101 32x48d WSL model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x48d_wsl')\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(output[0])', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeXt-101 32x48d': {'Top-1 Acc.': '85.4', 'Top-5 Acc.': '97.6'}}}, 'description': 'The provided ResNeXt models are pre-trained in weakly-supervised fashion on 940 million public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. The models significantly improve the training accuracy on ImageNet compared to training from scratch. They achieve state-of-the-art accuracy of 85.4% on ImageNet with the ResNext-101 32x48d model.'}", "category": "generic"}
{"question_id": 858, "text": "We are building a comic generator software that creates new comic images by mixing scenes of other comics. Suggest a relevant API for generating such new comic images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Generative Adversarial Networks (GANs)', 'api_name': 'PGAN', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorch_GAN_zoo:hub', model='PGAN', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'facebookresearch/pytorch_GAN_zoo:hub', 'model': 'PGAN', 'model_name': 'celebAHQ-512', 'pretrained': 'True', 'useGPU': 'use_gpu'}, 'python_environment_requirements': 'Python 3', 'example_code': {'import': 'import torch', 'use_gpu': 'use_gpu = True if torch.cuda.is_available() else False', 'load_model': \"model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'PGAN', model_name='celebAHQ-512', pretrained=True, useGPU=use_gpu)\", 'build_noise_data': 'noise, _ = model.buildNoiseData(num_images)', 'test': 'generated_images = model.test(noise)', 'plot_images': {'import_matplotlib': 'import matplotlib.pyplot as plt', 'import_torchvision': 'import torchvision', 'make_grid': 'grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1), scale_each=True, normalize=True)', 'imshow': 'plt.imshow(grid.permute(1, 2, 0).cpu().numpy())', 'show': 'plt.show()'}}, 'performance': {'dataset': 'celebA', 'accuracy': 'High-quality celebrity faces'}, 'description': \"Progressive Growing of GANs (PGAN) is a method for generating high-resolution images using generative adversarial networks. The model is trained progressively, starting with low-resolution images and gradually increasing the resolution until the desired output is achieved. This implementation is based on the paper by Tero Karras et al., 'Progressive Growing of GANs for Improved Quality, Stability, and Variation'.\"}", "category": "generic"}
{"question_id": 859, "text": "Teach me how to operate an API that can segment abnormalities in brain MRI images. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Biomedical Image Segmentation', 'api_name': 'U-Net for brain MRI', 'api_call': \"torch.hub.load(repo_or_dir='mateuszbuda/brain-segmentation-pytorch', model='unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'api_arguments': {'in_channels': 3, 'out_channels': 1, 'init_features': 32, 'pretrained': True}, 'python_environment_requirements': ['torch', 'torchvision', 'numpy', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\", 'import numpy as np', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'm, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))', 'preprocess = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=m, std=s)])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model = model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.round(output[0]))'], 'performance': {'dataset': 'kaggle.com/mateuszbuda/lgg-mri-segmentation'}, 'description': 'U-Net with batch normalization for biomedical image segmentation with pretrained weights for abnormality segmentation in brain MRI. The model comprises four levels of blocks containing two convolutional layers with batch normalization and ReLU activation function, and one max pooling layer in the encoding part and up-convolutional layers instead in the decoding part. The number of convolutional filters in each block is 32, 64, 128, and 256. The bottleneck layer has 512 convolutional filters. From the encoding layers, skip connections are used to the corresponding layers in the decoding part. Input image is a 3-channel brain MRI slice from pre-contrast, FLAIR, and post-contrast sequences, respectively. Output is a one-channel probability map of abnormality regions with the same size as the input image.'}", "category": "generic"}
{"question_id": 860, "text": "A company is looking for an image recognition API to help them categorize their products. Suggest an API that could do this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNet50', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resnet50', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['pip install validators matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", \"print(f'Using {device} for inference')\", \"resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resnet50.eval().to(device)', 'uris = [...]', 'batch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resnet50(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'ImageNet', 'accuracy': '~0.5% top1 improvement over ResNet50 v1'}, 'description': 'The ResNet50 v1.5 model is a modified version of the original ResNet50 v1 model. The difference between v1 and v1.5 is that, in the bottleneck blocks which requires downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate (~0.5% top1) than v1, but comes with a small performance drawback (~5% imgs/sec). The model is initialized as described in Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures.'}", "category": "generic"}
{"question_id": 861, "text": "Share an image classification API that can recognize objects in real-world images, including 1,000 categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeXt101-32x4d', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_resneXt', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'validators', 'matplotlib'], 'example_code': ['import torch', 'from PIL import Image', 'import torchvision.transforms as transforms', 'import numpy as np', 'import json', 'import requests', 'import matplotlib.pyplot as plt', 'import warnings', \"warnings.filterwarnings('ignore')\", '%matplotlib inline', 'device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")', \"print(f'Using {device} for inference')\", \"resneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resneXt')\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\", 'resneXt.eval().to(device)', 'uris = [', \" 'http://images.cocodataset.org/test-stuff2017/000000024309.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000028117.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000006149.jpg',\", \" 'http://images.cocodataset.org/test-stuff2017/000000004954.jpg',\", ']', 'batch = torch.cat(', ' [utils.prepare_input_from_uri(uri) for uri in uris]', ').to(device)', 'with torch.no_grad():', ' output = torch.nn.functional.softmax(resneXt(batch), dim=1)', 'results = utils.pick_n_best(predictions=output, n=5)', 'for uri, result in zip(uris, results):', ' img = Image.open(requests.get(uri, stream=True).raw)', ' img.thumbnail((256,256), Image.ANTIALIAS)', ' plt.imshow(img)', ' plt.show()', ' print(result)'], 'performance': {'dataset': 'IMAGENET', 'accuracy': 'Not provided'}, 'description': 'ResNeXt101-32x4d is a model introduced in the Aggregated Residual Transformations for Deep Neural Networks paper. It is based on regular ResNet model, substituting 3x3 convolutions inside the bottleneck block for 3x3 grouped convolutions. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures. It can be deployed for inference on the NVIDIA Triton Inference Server using TorchScript, ONNX Runtime or TensorRT as an execution backend.'}", "category": "generic"}
{"question_id": 862, "text": "A Facebook user wants to classify images from their vacation album. Recommend an AI-based solution that can classify images into different categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SE-ResNeXt101', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_se_resnext101_32x4d', pretrained=True)\", 'api_arguments': 'N/A', 'python_environment_requirements': 'validators, matplotlib', 'example_code': \"import torch\\nfrom PIL import Image\\nimport torchvision.transforms as transforms\\nimport numpy as np\\nimport json\\nimport requests\\nimport matplotlib.pyplot as plt\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n%matplotlib inline\\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\nprint(f'Using {device} for inference')\\nresneXt = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_se_resnext101_32x4d')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\nresneXt.eval().to(device)\\nuris = ['http://images.cocodataset.org/test-stuff2017/000000024309.jpg','http://images.cocodataset.org/test-stuff2017/000000028117.jpg','http://images.cocodataset.org/test-stuff2017/000000006149.jpg','http://images.cocodataset.org/test-stuff2017/000000004954.jpg']\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(resneXt(batch), dim=1)\\nresults = utils.pick_n_best(predictions=output, n=5)\\nfor uri, result in zip(uris, results):\\n img = Image.open(requests.get(uri, stream=True).raw)\\n img.thumbnail((256,256), Image.ANTIALIAS)\\n plt.imshow(img)\\n plt.show()\\n print(result)\", 'performance': {'dataset': 'IMAGENET', 'accuracy': 'N/A'}, 'description': 'The SE-ResNeXt101-32x4d is a ResNeXt101-32x4d model with added Squeeze-and-Excitation module. This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures, which allows researchers to get results 3x faster than training without Tensor Cores while experiencing the benefits of mixed precision training.'}", "category": "generic"}
{"question_id": 863, "text": "I need a suggestion for an API that can classify images of birds and flowers. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet121', pretrained=True)\", 'api_arguments': [{'name': 'densenet121', 'type': 'str', 'description': 'Densenet-121 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet121': {'Top-1 error': 25.35, 'Top-5 error': 7.83}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 864, "text": "Identify the breed of a dog in a given image using an API. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'AlexNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='alexnet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 43.45, 'top-5_error': 20.91}}, 'description': 'AlexNet is a deep convolutional neural network that achieved a top-5 error of 15.3% in the 2012 ImageNet Large Scale Visual Recognition Challenge. The main contribution of the original paper was the depth of the model, which was computationally expensive but made feasible through the use of GPUs during training. The pretrained AlexNet model in PyTorch can be used for image classification tasks.'}", "category": "generic"}
{"question_id": 865, "text": "Recommend me an API that can create synthesized speech from text input. \n Use this API documentation for reference: {'domain': 'Text-to-Speech', 'framework': 'PyTorch', 'functionality': 'Speech Synthesis', 'api_name': 'WaveGlow', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_waveglow', pretrained=True)\", 'api_arguments': {'repo_or_dir': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_waveglow', 'model_math': 'fp32'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': {'load_waveglow_model': \"waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp32')\", 'prepare_waveglow_model': ['waveglow = waveglow.remove_weightnorm(waveglow)', \"waveglow = waveglow.to('cuda')\", 'waveglow.eval()'], 'load_tacotron2_model': \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp32')\", 'prepare_tacotron2_model': [\"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()'], 'synthesize_speech': ['text = \"hello world, I missed you so much\"', \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'save_audio': 'write(\"audio.wav\", rate, audio_numpy)', 'play_audio': 'Audio(audio_numpy, rate=rate)'}, 'performance': {'dataset': 'LJ Speech', 'accuracy': None}, 'description': 'The Tacotron 2 and WaveGlow model form a text-to-speech system that enables users to synthesize natural-sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 866, "text": "'Suppose there is an English teaching website and the website wants to help students check the similarity between two given sentences. Suggest an API for that purpose.' \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'RoBERTa', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq', model='roberta.large', pretrained=True)\", 'api_arguments': [\"'pytorch/fairseq'\", \"'roberta.large'\"], 'python_environment_requirements': ['regex', 'requests', 'hydra-core', 'omegaconf'], 'example_code': ['import torch', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\", 'roberta.eval()', \"tokens = roberta.encode('Hello world!')\", 'last_layer_features = roberta.extract_features(tokens)', 'all_layers = roberta.extract_features(tokens, return_all_hiddens=True)', \"roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\", 'roberta.eval()', \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is not very optimized.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is based on BERT.')\", \"prediction = roberta.predict('mnli', tokens).argmax().item()\", \"roberta.register_classification_head('new_task', num_classes=3)\", \"logprobs = roberta.predict('new_task', tokens)\"], 'performance': {'dataset': 'MNLI', 'accuracy': 'N/A'}, 'description': \"RoBERTa is a robustly optimized version of BERT, a revolutionary self-supervised pretraining technique that learns to predict intentionally hidden (masked) sections of text. RoBERTa builds on BERT's language masking strategy and modifies key hyperparameters, including removing BERT's next-sentence pretraining objective, and training with much larger mini-batches and learning rates. RoBERTa was also trained on an order of magnitude more data than BERT, for a longer amount of time, allowing it to generalize even better to downstream tasks.\"}", "category": "generic"}
{"question_id": 867, "text": "Recommend me an API that can classify images of different types of food. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet169', pretrained=True)\", 'api_arguments': [{'name': 'densenet169', 'type': 'str', 'description': 'Densenet-169 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet169': {'Top-1 error': 24.0, 'Top-5 error': 7.0}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 868, "text": "Design a food recognition system that can identify different kinds of food given photos. Recommend an API that can help achieve this. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet201', pretrained=True)\", 'api_arguments': [{'name': 'densenet201', 'type': 'str', 'description': 'Densenet-201 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet201': {'Top-1 error': 22.8, 'Top-5 error': 6.43}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 869, "text": "Recommend a neural network API for semantic segmentation of images containing objects like cars, airplanes, and people. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet50', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet50': {'Mean IOU': 60.5, 'Global Pixelwise Accuracy': 91.4}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 870, "text": "A social media platform is building an image classifier to identify and tag the content of images. Suggest an API that can help with this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Dense Convolutional Network', 'api_name': 'Densenet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='densenet161', pretrained=True)\", 'api_arguments': [{'name': 'densenet161', 'type': 'str', 'description': 'Densenet-161 model'}], 'python_environment_requirements': {'torch': 'latest', 'torchvision': 'latest'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet161', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'densenet161': {'Top-1 error': 22.35, 'Top-5 error': 6.2}}}, 'description': 'Dense Convolutional Network (DenseNet) connects each layer to every other layer in a feed-forward fashion. It alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters.'}", "category": "generic"}
{"question_id": 871, "text": "Help me find an API that can perform semantic segmentation on an image of San Francisco streets. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Fully-Convolutional Network', 'api_name': 'fcn_resnet101', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='fcn_resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'boolean', 'description': 'If True, returns a model pre-trained on COCO train2017'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'matplotlib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'input_image = input_image.convert(\"RGB\")', 'preprocess = transforms.Compose([', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', \" output = model(input_batch)['out'][0]\", 'output_predictions = output.argmax(0)'], 'performance': {'dataset': 'COCO val2017', 'accuracy': {'fcn_resnet101': {'Mean IOU': 63.7, 'Global Pixelwise Accuracy': 91.9}}}, 'description': 'FCN-ResNet is a Fully-Convolutional Network model using a ResNet-50 or a ResNet-101 backbone. The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.'}", "category": "generic"}
{"question_id": 872, "text": "Find me an API that can efficiently classify an image with low computational cost and memory access. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet39ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet39ds', 'type': 'str', 'description': 'HarDNet-39DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet39ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet39ds': {'Top-1 error': 27.92, 'Top-5 error': 9.57}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 873, "text": "Design a recommendation system for your video upload platform. Suggest an API that can detect and classify the subject from the image of the first frame. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68ds', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68ds', 'type': 'str', 'description': 'HarDNet-68DS model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68ds', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68ds': {'Top-1 error': 25.71, 'Top-5 error': 8.13}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 874, "text": "Suggest an API specialized in image classification which can efficiently perform the task while consuming less memory and computational resources. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet68', pretrained=True)\", 'api_arguments': [{'name': 'hardnet68', 'type': 'str', 'description': 'HarDNet-68 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet68', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet68': {'Top-1 error': 23.52, 'Top-5 error': 6.99}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory trafficCNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 875, "text": "Imagine you are creating an image recognition app. Select an API well-suited for this task, that is both fast and efficient. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'HarDNet', 'api_call': \"torch.hub.load(repo_or_dir='PingoLH/Pytorch-HarDNet', model='hardnet85', pretrained=True)\", 'api_arguments': [{'name': 'hardnet85', 'type': 'str', 'description': 'HarDNet-85 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('PingoLH/Pytorch-HarDNet', 'hardnet85', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'hardnet85': {'Top-1 error': 21.96, 'Top-5 error': 6.11}}}, 'description': 'Harmonic DenseNet (HarDNet) is a low memory traffic CNN model, which is fast and efficient. The basic concept is to minimize both computational cost and memory access cost at the same time, such that the HarDNet models are 35% faster than ResNet running on GPU comparing to models with the same accuracy (except the two DS models that were designed for comparing with MobileNet).'}", "category": "generic"}
{"question_id": 876, "text": "A sports federation needs an AI-powered app that can recognize logos of soccer teams in a stadium. Give me an API that can output the name of the team, given a photo of its logo. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Efficient networks by generating more features from cheap operations', 'api_name': 'GhostNet', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/ghostnet', model='ghostnet_1x', pretrained=True)\", 'api_arguments': ['pretrained'], 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/ghostnet', 'ghostnet_1x', pretrained=True)\", 'model.eval()', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 acc': '73.98', 'Top-5 acc': '91.46'}}, 'description': 'The GhostNet architecture is based on an Ghost module structure which generates more features from cheap operations. Based on a set of intrinsic feature maps, a series of cheap operations are applied to generate many ghost feature maps that could fully reveal information underlying intrinsic features. Experiments conducted on benchmarks demonstrate the superiority of GhostNet in terms of speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 877, "text": "I want to create a website that allows users to upload images and classify what's in the image. Tell me an API that can perform image classification. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'GoogLeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='googlenet', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.0.0', 'torchvision': '>=0.2.2'}, 'example_code': {'import': ['import torch', 'import urllib', 'from PIL import Image', 'from torchvision import transforms'], 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\", 'model_eval': 'model.eval()', 'image_preprocessing': ['input_image = Image.open(filename)', 'preprocess = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'model_execution': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'output_processing': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'top5_prob, top5_catid = torch.topk(probabilities, 5)']}, 'performance': {'dataset': 'ImageNet', 'accuracy': {'Top-1 error': '30.22', 'Top-5 error': '10.47'}}, 'description': \"GoogLeNet is based on a deep convolutional neural network architecture codenamed 'Inception', which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014).\"}", "category": "generic"}
{"question_id": 878, "text": "Advise an API for classifying images into their correct domain or appearance using PyTorch. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet101_ibn_a', 'type': 'str', 'description': 'ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet101_ibn_a': {'Top-1 acc': 78.61, 'Top-5 acc': 94.41}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 879, "text": "I want to implement real-time face identification and facial recognition using the ResNet-50 model with IBN-Net. Recommend an appropriate API for the task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnet50_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnet50_ibn_a', 'type': 'str', 'description': 'ResNet-50-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnet50_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnet50_ibn_a': {'Top-1 acc': 77.46, 'Top-5 acc': 93.68}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 880, "text": "Can you identify an API for classifying images based on visual semantics and style for an art curating service? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='resnext101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'resnext101_ibn_a', 'type': 'str', 'description': 'ResNeXt-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'resnext101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext101_ibn_a': {'Top-1 acc': 79.12, 'Top-5 acc': 94.58}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 881, "text": "I need an API that can classify pedestrian and vehicle images into their respective categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'IBN-Net', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='XingangPan/IBN-Net', model='se_resnet101_ibn_a', pretrained=True)\", 'api_arguments': [{'name': 'se_resnet101_ibn_a', 'type': 'str', 'description': 'SE-ResNet-101-IBN-a model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('XingangPan/IBN-Net', 'se_resnet101_ibn_a', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'se_resnet101_ibn_a': {'Top-1 acc': 78.75, 'Top-5 acc': 94.49}}}, 'description': 'IBN-Net is a CNN model with domain/appearance invariance. Motivated by style transfer works, IBN-Net carefully unifies instance normalization and batch normalization in a single deep network. It provides a simple way to increase both modeling and generalization capacities without adding model complexity. IBN-Net is especially suitable for cross domain or person/vehicle re-identification tasks.'}", "category": "generic"}
{"question_id": 882, "text": "A company wants to classify images for their AI application, provide an API that can classify images based on the ImageNet dataset. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'Inception_v3', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='inception_v3', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': '1.9.0', 'torchvision': '0.10.0'}, 'example_code': {'import_libraries': 'import torch', 'load_model': \"model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\", 'model_evaluation': 'model.eval()'}, 'performance': {'dataset': 'imagenet', 'accuracy': {'top-1_error': 22.55, 'top-5_error': 6.44}}, 'description': 'Inception v3, also called GoogleNetv3, is a famous Convolutional Neural Network trained on the ImageNet dataset from 2015. It is based on the exploration of ways to scale up networks to utilize the added computation as efficiently as possible by using suitably factorized convolutions and aggressive regularization. The model achieves a top-1 error of 22.55% and a top-5 error of 6.44% on the ImageNet dataset.'}", "category": "generic"}
{"question_id": 883, "text": "A developer at Microsoft is looking for an API that can classify various objects in an image. Find the API for the task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest50', pretrained=True)\", 'api_arguments': 'resnest50', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-50': 81.03}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 884, "text": "Provide me an API that can help in classifying objects in a given real-world image with high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest200', pretrained=True)\", 'api_arguments': 'resnest200', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest200', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-200': 83.84}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 885, "text": "A wildlife conservatory organization wants to classify different species of birds using image recognition. Suggest an API that can classify high-resolution bird images. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest101', pretrained=True)\", 'api_arguments': 'resnest101', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-101': 82.83}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 886, "text": "Can you suggest an API that can classify images into different categories like animals, objects, etc.? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNeSt', 'api_call': \"torch.hub.load(repo_or_dir='zhanghang1989/ResNeSt', model='resnest269', pretrained=True)\", 'api_arguments': 'resnest269', 'python_environment_requirements': {'torch': '1.0.0', 'torchvision': '0.2.2'}, 'example_code': ['import torch', \"model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest269', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'ResNeSt-269': 84.54}}, 'description': 'ResNeSt models are from the ResNeSt: Split-Attention Networks paper. They are a new ResNet variant that enables attention across feature-map groups. By stacking Split-Attention blocks ResNet-style, ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation, and semantic segmentation.'}", "category": "generic"}
{"question_id": 887, "text": "Recommend me an API that can optimize image classification for varying hardware platforms. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_cpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_cpu', 'type': 'str', 'description': 'ProxylessNAS optimized for CPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_cpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_cpu', 'accuracy': 75.3}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 888, "text": "I work at a company that needs an optimized model for image classification on GPU with high accuracy. Can you suggest a suitable API for me? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_gpu', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_gpu', 'type': 'str', 'description': 'ProxylessNAS optimized for GPU'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_gpu'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_gpu', 'accuracy': 75.1}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 889, "text": "I want an API that can handle object detection on mobile devices. It should be light-weight and efficient. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'ProxylessNAS', 'api_name': 'mit-han-lab/ProxylessNAS', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/ProxylessNAS', model='proxylessnas_mobile', pretrained=True)\", 'api_arguments': [{'name': 'proxylessnas_mobile', 'type': 'str', 'description': 'ProxylessNAS optimized for Mobile'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"target_platform = 'proxyless_mobile'\", \"model = torch.hub.load('mit-han-lab/ProxylessNAS', target_platform, pretrained=True)\", 'model.eval()'], 'performance': {'dataset': [{'model_structure': 'proxylessnas_mobile', 'accuracy': 74.6}]}, 'description': 'ProxylessNAS models are from the ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware paper. They specialize CNN architectures for different hardware platforms, offering free yet significant performance boost on all three platforms (CPU, GPU, and Mobile) with similar accuracy.'}", "category": "generic"}
{"question_id": 890, "text": "Can you suggest me an API that can classify objects from images? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet50', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet50', 'top-1_error': 23.85, 'top-5_error': 7.13}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 891, "text": "A software engineer at TikTok is developing a recommendation system for videos. He needs an API that can recognize content of an image associated with a video. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet18', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet18', 'top-1_error': 30.24, 'top-5_error': 10.92}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 892, "text": "I am building an image identification service that recognizes objects in images. I need an API suitable for this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet34', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet34', 'top-1_error': 26.7, 'top-5_error': 8.58}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 893, "text": "Build an API to identify the object in the image by its class. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet152', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet152', 'top-1_error': 21.69, 'top-5_error': 5.94}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 894, "text": "I want an API to label which type of object is in a given picture: car, dog, tree or house. Provide an API that can do this assignment. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Deep Residual Networks', 'api_name': 'ResNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnet101', pretrained=True)\", 'api_arguments': [{'name': 'pretrained', 'type': 'bool', 'default': 'False', 'description': 'If True, returns a model pre-trained on ImageNet'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'resnet101', 'top-1_error': 22.63, 'top-5_error': 6.44}}, 'description': \"ResNet models are deep residual networks pre-trained on ImageNet. They were proposed in the paper 'Deep Residual Learning for Image Recognition'. Available model variants include ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152.\"}", "category": "generic"}
{"question_id": 895, "text": "An image classification tool needs to be integrated into a real time webcam application that can detect different objects. Suggest me an API that can do this with low latency for a real time application. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MobileNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='mobilenet_v2', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'top-1_error': 28.12, 'top-5_error': 9.71}}, 'description': 'The MobileNet v2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input. MobileNet v2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, non-linearities in the narrow layers were removed in order to maintain representational power.'}", "category": "generic"}
{"question_id": 896, "text": "A startup, running a social platform for animals, is looking for an API to recognize their user's pet's breed, given a photo. Provide me with a suitable API. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext50_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'resnext50_32x4d': {'top-1': 22.38, 'top-5': 6.3}}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 897, "text": "We are developing an image-based plant disease identification system. Give me an image classification API that yields high accuracy and can be fine-tuned to our task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ResNext', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='resnext101_32x4d', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'PIL'], 'example_code': ['import torch', 'from PIL import Image', 'from torchvision import transforms', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext101_32x4d', pretrained=True)\", 'model.eval()', \"input_image = Image.open('dog.jpg')\", 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'performance': {'dataset': 'ImageNet', 'resnext101_32x8d': {'top-1': 20.69, 'top-5': 5.47}}, 'description': 'ResNext is a next-generation ResNet architecture for image classification. It is more efficient and accurate than the original ResNet. This implementation includes two versions of the model, resnext50_32x4d and resnext101_32x8d, with 50 and 101 layers respectively.'}", "category": "generic"}
{"question_id": 898, "text": "Suggest me a powerful image classification API for efficient image classification with decent accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_s', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_s', 'type': 'str', 'description': 'SNNMLP Small model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_s', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Small', 'top-1': 83.3}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 899, "text": "We're at Huawei Labs and building an image classification model that does not have extra floating-point operations. Suggest an API that does this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_b', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_b', 'type': 'str', 'description': 'SNNMLP Base model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_b', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Base', 'top-1': 85.59}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 900, "text": "Recommend me a model that can classify objects within images without increasing computational complexity considerably. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SNNMLP', 'api_call': \"torch.hub.load(repo_or_dir='huawei-noah/Efficient-AI-Backbones', model='snnmlp_t', pretrained=True)\", 'api_arguments': [{'name': 'snnmlp_t', 'type': 'str', 'description': 'SNNMLP Tiny model'}], 'python_environment_requirements': ['torch', 'torchvision', 'PIL', 'urllib'], 'example_code': ['import torch', \"model = torch.hub.load('huawei-noah/Efficient-AI-Backbones', 'snnmlp_t', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'print(torch.nn.functional.softmax(output[0], dim=0))'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'model': 'SNNMLP Tiny', 'top-1': 81.88}}, 'description': 'SNNMLP incorporates the mechanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We propose a full-precision LIF operation to communicate between patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our SNNMLP model achieves 81.9%, 83.3% and 83.6% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively.'}", "category": "generic"}
{"question_id": 901, "text": "Find me an AI model capable of classifying images efficiently with fewer parameters but still maintaining high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_0', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_0'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_0': {'Top-1 error': 41.9, 'Top-5 error': 19.58}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 902, "text": "Can you recommend an API that can classify images based on their content and requires less computational resources compared to AlexNet? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'SqueezeNet', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='squeezenet1_1', pretrained=True)\", 'api_arguments': {'version': 'v0.10.0', 'model': ['squeezenet1_1'], 'pretrained': 'True'}, 'python_environment_requirements': {'torch': '>=1.9.0', 'torchvision': '>=0.10.0'}, 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained=True)\", 'model.eval()', 'from PIL import Image', 'from torchvision import transforms', 'input_image = Image.open(filename)', 'preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)', 'if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)', 'probabilities = torch.nn.functional.softmax(output[0], dim=0)', 'print(probabilities)'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'squeezenet1_1': {'Top-1 error': 41.81, 'Top-5 error': 19.38}}}, 'description': 'SqueezeNet is an image classification model that achieves AlexNet-level accuracy with 50x fewer parameters. It has two versions: squeezenet1_0 and squeezenet1_1, with squeezenet1_1 having 2.4x less computation and slightly fewer parameters than squeezenet1_0, without sacrificing accuracy.'}", "category": "generic"}
{"question_id": 903, "text": "Provide me an API that can efficiently classify images into different categories. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'ShuffleNet v2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='shufflenet_v2_x1_0', pretrained=True)\", 'api_arguments': {'pretrained': 'True'}, 'python_environment_requirements': {'torch': 'torch', 'torchvision': 'torchvision', 'PIL': 'Image', 'urllib': 'urllib'}, 'example_code': {'import_libraries': ['import torch', 'from PIL import Image', 'from torchvision import transforms', 'import urllib'], 'load_model': [\"model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\", 'model.eval()'], 'load_image': [\"url, filename = ('https://github.com/pytorch/hub/raw/master/images/dog.jpg', 'dog.jpg')\", 'try: urllib.URLopener().retrieve(url, filename)', 'except: urllib.request.urlretrieve(url, filename)', 'input_image = Image.open(filename)'], 'preprocess_image': ['preprocess = transforms.Compose([', ' transforms.Resize(256),', ' transforms.CenterCrop(224),', ' transforms.ToTensor(),', ' transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),', '])', 'input_tensor = preprocess(input_image)', 'input_batch = input_tensor.unsqueeze(0)'], 'run_inference': ['if torch.cuda.is_available():', \" input_batch = input_batch.to('cuda')\", \" model.to('cuda')\", 'with torch.no_grad():', ' output = model(input_batch)'], 'get_probabilities': ['probabilities = torch.nn.functional.softmax(output[0], dim=0)'], 'top_categories': ['top5_prob, top5_catid = torch.topk(probabilities, 5)', 'for i in range(top5_prob.size(0)):', ' print(categories[top5_catid[i]], top5_prob[i].item())']}, 'performance': {'dataset': 'Imagenet', 'accuracy': {'top-1_error': 30.64, 'top-5_error': 11.68}}, 'description': 'ShuffleNet V2 is an efficient ConvNet optimized for speed and memory, pre-trained on Imagenet. It is designed based on practical guidelines for efficient network design, including speed and accuracy tradeoff.'}", "category": "generic"}
{"question_id": 904, "text": "Recommend an API to classify artwork images into categories like Impressionism, Cubism, and Surrealism. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11', pretrained=True)\", 'api_arguments': [{'name': 'vgg11', 'type': 'str', 'description': 'VGG11 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11': {'Top-1 error': 30.98, 'Top-5 error': 11.37}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 905, "text": "\"A client wants to recognize different types of plant diseases from an image. Suggest an appropriate machine learning API that can accomplish this.\" \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg11_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg11_bn', 'type': 'str', 'description': 'VGG11 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg11_bn': {'Top-1 error': 26.7, 'Top-5 error': 8.58}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 906, "text": "What is an API that I can use to identify what kind of food is in an image? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg13_bn', 'type': 'str', 'description': 'VGG13 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13_bn': {'Top-1 error': 28.45, 'Top-5 error': 9.63}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 907, "text": "Describe an API that can identify different breeds of dogs in a given image. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19', pretrained=True)\", 'api_arguments': [{'name': 'vgg19', 'type': 'str', 'description': 'VGG19 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19': {'Top-1 error': 27.62, 'Top-5 error': 9.12}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 908, "text": "An art gallery is interested in recognizing artwork styles in photographs. Advise them an API to accomplish this task. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg19_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg19_bn', 'type': 'str', 'description': 'VGG19 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg19_bn': {'Top-1 error': 25.76, 'Top-5 error': 8.15}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 909, "text": "I need to find an API to recognize objects in photos, what would you suggest? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16', pretrained=True)\", 'api_arguments': [{'name': 'vgg16', 'type': 'str', 'description': 'VGG16 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16': {'Top-1 error': 28.41, 'Top-5 error': 9.62}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 910, "text": "An online glasses store needs an AI tool to categorize thousands of glasses into their different styles. Provide a suitable image recognition API for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg13', pretrained=True)\", 'api_arguments': [{'name': 'vgg13', 'type': 'str', 'description': 'VGG13 model'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg13', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg13': {'Top-1 error': 30.07, 'Top-5 error': 10.75}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn,vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 911, "text": "Find me a deep learning API that can recognize images of cars and their types from large datasets like Imagenet. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Recognition', 'api_name': 'vgg-nets', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='vgg16_bn', pretrained=True)\", 'api_arguments': [{'name': 'vgg16_bn', 'type': 'str', 'description': 'VGG16 model with batch normalization'}], 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'vgg16_bn': {'Top-1 error': 26.63, 'Top-5 error': 8.5}}}, 'description': 'vgg-nets are award-winning ConvNets from the 2014 Imagenet ILSVRC challenge. They are used for large-scale image recognition tasks. The available models are vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, and vgg19_bn.'}", "category": "generic"}
{"question_id": 912, "text": "Suggest an optimal API for building an image recognition system for a company that demands high accuracy. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet50_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet50_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet50_2': {'Top-1 error': 21.49, 'Top-5 error': 5.91}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 913, "text": "What API should I use for my drone's object detertion that classify objects from images using Wide Residual Networks? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Wide Residual Networks', 'api_name': 'wide_resnet101_2', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/vision', model='wide_resnet101_2', pretrained=True)\", 'api_arguments': 'pretrained', 'python_environment_requirements': 'torch, torchvision', 'example_code': ['import torch', \"model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet101_2', pretrained=True)\", 'model.eval()'], 'performance': {'dataset': 'ImageNet', 'accuracy': {'wide_resnet101_2': {'Top-1 error': 21.16, 'Top-5 error': 5.72}}}, 'description': 'Wide Residual networks simply have increased number of channels compared to ResNet. Otherwise the architecture is the same. Deeper ImageNet models with bottleneck block have increased number of channels in the inner 3x3 convolution. The wide_resnet50_2 and wide_resnet101_2 models were trained in FP16 with mixed precision training using SGD with warm restarts. Checkpoints have weights in half precision (except batch norm) for smaller size, and can be used in FP32 models too.'}", "category": "generic"}
{"question_id": 914, "text": "A video analyst is working on recognizing sports clips to create a promotional video. Which API should they use to classify actions in the video? \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'SlowFast Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='slowfast_r50', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'slowfast_r50', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 76.94, 'top5': 92.69}, 'flops': 65.71, 'params': 34.57}, 'description': \"Slow Fast model architectures are based on the paper 'SlowFast Networks for Video Recognition' by Christoph Feichtenhofer et al. They are pretrained on the Kinetics 400 dataset using the 8x8 setting. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 915, "text": "I want to create a program that analyzes CCTV footage and classifies suspicious activities. Help me with an API that can do this. \n Use this API documentation for reference: {'domain': 'Video Classification', 'framework': 'PyTorchVideo', 'functionality': 'X3D Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/pytorchvideo', model='x3d_s', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/pytorchvideo', 'model': 'x3d_s', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision', 'pytorchvideo'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_s', pretrained=True)\", \"device = 'cpu'\", 'model = model.eval()', 'model = model.to(device)'], 'performance': {'dataset': 'Kinetics 400', 'accuracy': {'top1': 73.33, 'top5': 91.27}, 'flops': 2.96, 'params': 3.79}, 'description': \"X3D model architectures are based on the paper 'X3D: Expanding Architectures for Efficient Video Recognition' by Christoph Feichtenhofer. They are pretrained on the Kinetics 400 dataset. This model is capable of classifying video clips into different action categories. It is provided by the FAIR PyTorchVideo library.\"}", "category": "generic"}
{"question_id": 916, "text": "Find me an API that helps in classifying images based on their content using models trained with limited labeled data. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Semi-supervised and semi-weakly supervised ImageNet Models', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='facebookresearch/semi-supervised-ImageNet1K-models', model='resnet18_swsl', pretrained=True)\", 'api_arguments': {'repository': 'facebookresearch/semi-supervised-ImageNet1K-models', 'model': 'resnet18_swsl', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl', pretrained=True)\", 'model.eval()'], 'performance': {'description': 'Semi-supervised and semi-weakly supervised ImageNet models achieve state-of-the-art accuracy of 81.2% on ImageNet for the widely used/adopted ResNet-50 model architecture.'}, 'description': \"Semi-supervised and semi-weakly supervised ImageNet Models are introduced in the 'Billion scale semi-supervised learning for image classification' paper. These models are pretrained on a subset of unlabeled YFCC100M public image dataset and fine-tuned with the ImageNet1K training dataset. They are capable of classifying images into different categories and are provided by the Facebook Research library.\"}", "category": "generic"}
{"question_id": 917, "text": "I am building an app for classifying pet images into dog breeds using neural networks. Can you recommend a suitable API to use? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Once-for-all (OFA) Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='mit-han-lab/once-for-all', model='ofa_supernet_mbv3_w10', pretrained=True)\", 'api_arguments': {'repository': 'mit-han-lab/once-for-all', 'model': 'ofa_supernet_mbv3_w10', 'pretrained': 'True'}, 'python_environment_requirements': ['torch', 'torchvision'], 'example_code': ['import torch', \"super_net_name = 'ofa_supernet_mbv3_w10'\", \"super_net = torch.hub.load('mit-han-lab/once-for-all', super_net_name, pretrained=True).eval()\"], 'performance': {'description': 'OFA networks outperform state-of-the-art NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x faster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency) while reducing many orders of magnitude GPU hours and CO2 emission.'}, 'description': 'Once-for-all (OFA) networks are a family of neural networks designed by MIT Han Lab. They decouple training and search, achieving efficient inference across various edge devices and resource constraints. OFA networks are pretrained on the IMAGENET dataset and are capable of classifying images into different categories.'}", "category": "generic"}
{"question_id": 918, "text": "I work at NVIDIA and want to find an API which can help me classify images based on their content using a GPU-optimized neural network. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'GPUNet Networks', 'api_name': 'torch.hub.load', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", 'api_arguments': {'repository': 'NVIDIA/DeepLearningExamples:torchhub', 'model': 'nvidia_gpunet', 'pretrained': 'True', 'model_type': 'GPUNet-0', 'model_math': 'fp32'}, 'python_environment_requirements': ['torch', 'validators', 'matplotlib', 'timm==0.5.4'], 'example_code': ['import torch', \"model_type = 'GPUNet-0'\", \"precision = 'fp32'\", \"gpunet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\", \"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\", 'gpunet.to(device)', 'gpunet.eval()'], 'performance': {'dataset': 'IMAGENET', 'description': 'GPUNet demonstrates state-of-the-art inference performance up to 2x faster than EfficientNet-X and FBNet-V3.'}, 'description': 'GPUNet is a family of Convolutional Neural Networks designed by NVIDIA using novel Neural Architecture Search (NAS) methods. They are optimized for NVIDIA GPU and TensorRT performance. GPUNet models are pretrained on the IMAGENET dataset and are capable of classifying images into different categories. The models are provided by the NVIDIA Deep Learning Examples library.'}", "category": "generic"}
{"question_id": 919, "text": "Find me an API that can tokenize English text and perform NLP tasks like text summarization, translation, or question answering. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Natural Language Processing', 'api_name': 'PyTorch-Transformers', 'api_call': \"torch.hub.load(repo_or_dir='huggingface/pytorch-transformers')\", 'api_arguments': ['pretrained_model_or_path', 'output_attention', 'output_hidden_states', 'config', 'from_tf'], 'python_environment_requirements': ['tqdm', 'boto3', 'requests', 'regex', 'sentencepiece', 'sacremoses'], 'example_code': 'import torch\\ntokenizer = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'tokenizer\\', \\'bert-base-cased\\')\\n\\ntext_1 = \"Jim Henson was a puppeteer\"\\ntext_2 = \"Who was Jim Henson ?\"\\n\\nindexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\\n\\nmodel = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'model\\', \\'bert-base-cased\\')\\n\\nwith torch.no_grad():\\n encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)', 'performance': {'dataset': [{'name': 'MRPC', 'accuracy': 'Not provided'}]}, 'description': 'PyTorch-Transformers is a library of state-of-the-art pre-trained models for Natural Language Processing (NLP) including BERT, GPT, GPT-2, Transformer-XL, XLNet, XLM, RoBERTa, and DistilBERT. The library provides functionality for tokenization, configuration, and various model architectures for different tasks such as causal language modeling, sequence classification, question answering, and masked language modeling.'}", "category": "generic"}
{"question_id": 920, "text": "A language teacher wants to check the grammar of some sentences by translating them back and forth between languages. Provide an API that can handle neural machine translation for this purpose. \n Use this API documentation for reference: {'domain': 'Semantic Segmentation', 'framework': 'PyTorch', 'functionality': 'Neural Machine Translation', 'api_name': 'Transformer (NMT)', 'api_call': \"torch.hub.load(repo_or_dir='pytorch/fairseq')\", 'api_arguments': ['model_name', 'tokenizer', 'bpe', 'beam', 'sampling', 'sampling_topk'], 'python_environment_requirements': ['bitarray', 'fastBPE', 'hydra-core', 'omegaconf', 'regex', 'requests', 'sacremoses', 'subword_nmt'], 'example_code': \"import torch\\n\\nen2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\\n\\nen2fr.cuda()\\n\\nfr = en2fr.translate('Hello world!', beam=5)\\nassert fr == 'Bonjour \u00e0 tous !'\", 'performance': {'dataset': [{'name': \"WMT'14\", 'accuracy': 'Not provided'}, {'name': \"WMT'18\", 'accuracy': 'Not provided'}, {'name': \"WMT'19\", 'accuracy': 'Not provided'}]}, 'description': \"Transformer (NMT) is a powerful sequence-to-sequence modeling architecture that produces state-of-the-art neural machine translation systems. It is based on the paper 'Attention Is All You Need' and has been improved using techniques such as large-scale semi-supervised training, back-translation, and noisy-channel reranking. It supports English-French and English-German translation as well as round-trip translation for paraphrasing.\"}", "category": "generic"}
{"question_id": 921, "text": "I'm looking for an API that can quickly classify images with high accuracy. What do you suggest? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'EfficientNet', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_efficientnet_b0', pretrained=True)\", 'api_arguments': ['model_name', 'pretrained'], 'python_environment_requirements': ['validators', 'matplotlib'], 'example_code': \"import torch\\n\\nefficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\\n\\nefficientnet.eval().to(device)\\n\\nbatch = torch.cat([utils.prepare_input_from_uri(uri) for uri in uris]).to(device)\\n\\nwith torch.no_grad():\\n output = torch.nn.functional.softmax(efficientnet(batch), dim=1)\\n \\nresults = utils.pick_n_best(predictions=output, n=5)\", 'performance': {'dataset': {'name': 'IMAGENET', 'accuracy': 'Not provided'}}, 'description': 'EfficientNet is a family of image classification models that achieve state-of-the-art accuracy while being smaller and faster. The models are trained with mixed precision using Tensor Cores on the NVIDIA Volta and Ampere GPU architectures. The EfficientNet models include EfficientNet-B0, EfficientNet-B4, EfficientNet-WideSE-B0, and EfficientNet-WideSE-B4. The WideSE models use wider Squeeze-and-Excitation layers than the original EfficientNet models, resulting in slightly better accuracy.'}", "category": "generic"}
{"question_id": 922, "text": "Can you recommend an API to ensure the safety of autonomous cars by detecting pedestrians, cars and other objects in a timely manner? \n Use this API documentation for reference: {'domain': 'Object Detection', 'framework': 'PyTorch', 'functionality': 'Single Shot MultiBox Detector', 'api_name': 'SSD', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_ssd', pretrained=True)\", 'api_arguments': ['model_name'], 'python_environment_requirements': ['numpy', 'scipy', 'scikit-image', 'matplotlib'], 'example_code': \"import torch\\n\\nssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\\n\\nssd_model.to('cuda')\\nssd_model.eval()\\n\\ninputs = [utils.prepare_input(uri) for uri in uris]\\ntensor = utils.prepare_tensor(inputs)\\n\\nwith torch.no_grad():\\n detections_batch = ssd_model(tensor)\\n\\nresults_per_input = utils.decode_results(detections_batch)\\nbest_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\", 'performance': {'dataset': {'name': 'COCO', 'accuracy': 'Not provided'}}, 'description': \"The SSD (Single Shot MultiBox Detector) model is an object detection model based on the paper 'SSD: Single Shot MultiBox Detector'. It uses a deep neural network for detecting objects in images. This implementation replaces the obsolete VGG model backbone with the more modern ResNet-50 model. The SSD model is trained on the COCO dataset and can be used to detect objects in images with high accuracy and efficiency.\"}", "category": "generic"}
{"question_id": 923, "text": "I'm looking for an API that can provide me a deep learning model to convert text to speech with human-like voice quality. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Text-to-Speech', 'api_name': 'Tacotron 2', 'api_call': \"torch.hub.load(repo_or_dir='NVIDIA/DeepLearningExamples:torchhub', model='nvidia_tacotron2', model_math='fp16')\", 'api_arguments': {'model_math': 'fp16'}, 'python_environment_requirements': ['numpy', 'scipy', 'librosa', 'unidecode', 'inflect', 'libsndfile1'], 'example_code': ['import torch', \"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\", \"tacotron2 = tacotron2.to('cuda')\", 'tacotron2.eval()', \"text = 'Hello world, I missed you so much.'\", \"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\", 'sequences, lengths = utils.prepare_input_sequence([text])', 'with torch.no_grad():', ' mel, _, _ = tacotron2.infer(sequences, lengths)', ' audio = waveglow.infer(mel)', 'audio_numpy = audio[0].data.cpu().numpy()', 'rate = 22050'], 'performance': {'dataset': 'LJ Speech', 'accuracy': 'Not specified'}, 'description': 'The Tacotron 2 model generates mel spectrograms from input text using an encoder-decoder architecture, and it is designed for generating natural-sounding speech from raw transcripts without any additional prosody information. This implementation uses Dropout instead of Zoneout to regularize the LSTM layers. The WaveGlow model (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech.'}", "category": "generic"}
{"question_id": 924, "text": "I desire a robust image classifier for my online art school. Can you provide me with an API that can classify images? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.67', 'top5': '95.09'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 925, "text": "I want to identify the main object in a given image. Which API would help me in doing this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V1', model='mealv1_resnest50', pretrained=True)\", 'api_arguments': {'model_name': 'mealv1_resnest50'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V1 w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '78.21', 'top5': '94.01'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 927, "text": "I need an API to classify images on the ImageNet dataset without using any additional tricks. Please suggest a suitable one. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_cutmix', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_cutmix'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 + CutMix w/ ResNet50', 'resolution': '224', 'parameters': '25.6M', 'top1': '80.98', 'top5': '95.35'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 928, "text": "My company is building a tool to automatically classify images using AI. Tell me about an API that can be used for this purpose. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_075', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_075'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 0.75', 'resolution': '224', 'parameters': '2.04M', 'top1': '67.60', 'top5': '87.23'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 929, "text": "Recommend an image classifier API to develop a phone app that can identify and tag objects in photos. \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenet_v3_large_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenet_v3_large_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Large 1.0', 'resolution': '224', 'parameters': '5.48M', 'top1': '76.92', 'top5': '93.32'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 930, "text": "I want to classify an image of a dog for a contest. Can you recommend me an API for accurately doing this task? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_resnest50_380x380', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_resnest50_380x380'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ ResNet50', 'resolution': '380', 'parameters': '25.6M', 'top1': '81.72', 'top5': '95.81'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
{"question_id": 931, "text": "I need to classify images with high accuracy without any additional training. Can you recommend an API that can do this? \n Use this API documentation for reference: {'domain': 'Classification', 'framework': 'PyTorch', 'functionality': 'Image Classification', 'api_name': 'MEAL_V2', 'api_call': \"torch.hub.load(repo_or_dir='szq0214/MEAL-V2', 'meal_v2', model='mealv2_mobilenetv3_small_100', pretrained=True)\", 'api_arguments': {'model_name': 'mealv2_mobilenetv3_small_100'}, 'python_environment_requirements': '!pip install timm', 'example_code': \"import torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\nmodel = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\\nmodel.eval()\\n\\ninput_image = Image.open('dog.jpg')\\npreprocess = transforms.Compose([\\n transforms.Resize(256),\\n transforms.CenterCrop(224),\\n transforms.ToTensor(),\\n transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\ninput_tensor = preprocess(input_image)\\ninput_batch = input_tensor.unsqueeze(0)\\n\\nif torch.cuda.is_available():\\n input_batch = input_batch.to('cuda')\\n model.to('cuda')\\n\\nwith torch.no_grad():\\n output = model(input_batch)\\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\\nprint(probabilities)\", 'performance': [{'dataset': 'ImageNet', 'accuracy': {'model': 'MEAL-V2 w/ MobileNet V3-Small 1.0', 'resolution': '224', 'parameters': '2.54M', 'top1': '69.65', 'top5': '88.71'}}], 'description': 'MEAL V2 models are from the MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks paper. The method is based on ensemble knowledge distillation via discriminators, and it achieves state-of-the-art results without using common tricks such as architecture modification, outside training data, autoaug/randaug, cosine learning rate, mixup/cutmix training, or label smoothing.'}", "category": "generic"}
